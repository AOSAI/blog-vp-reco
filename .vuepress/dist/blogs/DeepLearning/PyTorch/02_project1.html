<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.19">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <title>实战1-离散分类问题 | AoSaiX</title><meta name="description" content="Blog for study, life and hobby.">
    <link rel="preload" href="/blog-vp-reco/assets/style-CO2hMFE6.css" as="style"><link rel="stylesheet" href="/blog-vp-reco/assets/style-CO2hMFE6.css">
    <link rel="modulepreload" href="/blog-vp-reco/assets/app-P8O63--9.js"><link rel="modulepreload" href="/blog-vp-reco/assets/02_project1.html-CwBq-a0v.js">
    <link rel="prefetch" href="/blog-vp-reco/assets/timeline.html-BdJQ0mvw.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/posts.html-Bc1E7R2o.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/friendship-link.html-By2dk8OB.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/custom-page.html-BYkYIePG.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BSOTAWV7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DjHZ-0VC.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BTBDoDs7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DRSq8j_f.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-atztc-iS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-B9QKNHuH.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BpFG0qSD.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BvXlC1IN.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DAi-M6x6.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-B0wFdafP.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DKnc07sy.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-PaUmAeQt.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BxM40LCl.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-nsXZ1qjR.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C4LuENmB.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DuCOthnw.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C3ZuT9tS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C9jv4Sqb.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-5ZgsUq_f.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-2tLWhxKw.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BPf6exi_.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CG2Q8c6h.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-D1uTAsCH.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-XVWLnc_N.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-OUQfsSMe.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-TUvA1hOb.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CayeZCAz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C-Ul7X7h.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-34oRPQBX.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-EZsB9NLR.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-5Aif7w_k.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BvWu308X.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-gS_C1Hww.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-75Kg7CII.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-bxyAmrVV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-1NGbAeoz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BzooenBi.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-99kYxV7U.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-sSfTUfCP.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Dp_NTCIN.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CmGgfcYm.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Db6WyAY-.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BfF2chF0.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DWVEDDG8.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DfgO2xSb.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-COOrpJu_.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DfrZOlEf.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C0cP1kmh.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Cxb7w7Pz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DONY0Bd6.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Bsba4raH.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CNt-XijK.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DRnczId7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-CzOfFiqN.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/3.html-CyknjLjZ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/4.html-DkJdTfG3.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/5.html-CHImye19.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-BcwoWC7x.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/update_record.html-C1V8svZR.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/vuepress-recojiaocheng.html-Doq0mU0A.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_compress_photo.html-kAsnudyJ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_file_packaging.html-qB8raCfR.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_pyqt5_recording.html-DMCu8s1P.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_spider_for_ticket.html-CQ5Jovzn.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-XWkzsVHn.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Introduction.html-GSwY785t.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Introduction.html--BI5al3m.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_xxx.html-bg7OYjge.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_xxx.html-PYvRvZBM.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_bairuzongmen.html-B_LWPzht.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_aolianjingu.html-Cy4AVlr1.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html-X4Vqf4sR.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_tuxiangxiufurumen.html-IfRoIR6X.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_xxx.html-Cdfdtr8M.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html-C7cZwQIU.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_jichucaozuo.html-lbqclcG0.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_zaoshengyulvbo.html-rnYC7_MK.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_xinhaoyutuxiang.html-DglmsVZ7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/05_xingtaixueyutezheng.html-BDpX9bhS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/06_yasuoyubianma.html-DHv7A7FM.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html-suXj987-.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_xxx.html-Dj6lQ5Ac.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_xxx.html-CbcscO3s.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_fargoing.html-Cf0aCvEQ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_shanxi.html-DgfFZMMr.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_sichuan.html-C1z1N4e8.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/00.html-DWFxMFLA.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01.html-enhPGKIS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_base.html-ySCK6V26.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_project2.html-i5I9XEqk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_project1.html-DPc66BQ-.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-D0hKYeWN.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_introduction.html-B9Of61s1.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_linear_regression.html-B5B0AESm.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_linear_regression.html-vbH4E1uw.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_classification.html-BwnEU7im.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/05_deep_learning.html-CTox31z_.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/06_tensorflow.html-KDo33jSy.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/07_model_evaluation.html-dQAuxDEM.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/08_decision_tree.html-UBUXlGpt.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/09_unsupervised_learning.html-CbLl92H7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/10_recommendation_system.html-BuWKv7Rs.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/11_reinforcement_learning.html-QFrspMNL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/00_introduction.html-ZZbrmaDB.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_recommend_model.html-dXnSIzAW.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA1.html-DYiAebD6.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA2.html-D71k2RQQ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA3.html-e3LtLxps.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA4.html-Damo6x8r.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/ML1.html-BrOk26DW.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/404.html-CRo86Wkf.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Valine.min-_LyT3bfY.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/giscus-aTimukGI-DWEKOTfS.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container show-series show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/blog-vp-reco/logo1.svg" alt="AoSaiX"><a href="/blog-vp-reco/" class="site-name can-hide">AoSaiX</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="机器学习"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="机器学习"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/MachineLearning/MachineLearning/01_introduction" class="link" aria-label="机器学习(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习(未整理)<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/MachineLearning/recommendationSystem/00_introduction" class="link" aria-label="推荐系统(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->推荐系统(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="数据锻造坊"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->数据锻造坊<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="数据锻造坊"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->数据锻造坊<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DataFoundry/Numpy/01_拜入宗门" class="link" aria-label="Numpy"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Numpy<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DataFoundry/Matplotlib/01_xxx" class="link" aria-label="Matplotlib"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Matplotlib<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="深度学习"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->深度学习<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="深度学习"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->深度学习<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/README.md" class="link" aria-label="PyTorch(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->PyTorch(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="计算机视觉"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->计算机视觉<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="计算机视觉"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->计算机视觉<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/ImageProcessing/01_综述" class="link" aria-label="图像处理"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->图像处理<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/ImageGeneration/01_综述" class="link" aria-label="图像生成"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->图像生成<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/TargetDetection/01_综述" class="link" aria-label="目标检测"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->目标检测<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="每日一题"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->每日一题<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="每日一题"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->每日一题<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/CodeExam/AI/Introduction" class="link" aria-label="AI算法篇"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AI算法篇<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="书院二层楼"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->书院二层楼<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="书院二层楼"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->书院二层楼<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><!--[--><h5 class="dropdown-link__subtitle"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Reco内置<!--]--></span></span></h5><ul class="dropdown-link__subcontainer"><!--[--><li class="dropdown-link__subitem"><a href="/blog-vp-reco/timeline" class="link" aria-label="时间轴"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->时间轴<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__subitem"><a href="/blog-vp-reco/friendship-link" class="link" aria-label="友情链接"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->友情链接<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-link__item"><!--[--><h5 class="dropdown-link__subtitle"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->个人手札<!--]--></span></span></h5><ul class="dropdown-link__subcontainer"><!--[--><li class="dropdown-link__subitem"><a href="/blog-vp-reco/docs/update_record" class="link" aria-label="更新日志"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->更新日志<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__subitem"><a href="/blog-vp-reco/docs/desktop_app/README.md" class="link" aria-label="桌面软件开发(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->桌面软件开发(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="逐趣成章"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->逐趣成章<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="逐趣成章"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->逐趣成章<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/Hobbies/mahjong/01_fargoing" class="link" aria-label="雀神之路(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->雀神之路(未整理)<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/Hobbies/musictheroy/00" class="link" aria-label="音乐科学(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->音乐科学(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--><!----><span class="xicon-container btn-toggle-dark-mode btn--dark-mode navbar-links__item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><ul class="social-links navbar-links__item"><!--[--><li class="social-item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:25px;height:25px;"><path d="M16 2a14 14 0 0 0-4.43 27.28c.7.13 1-.3 1-.67v-2.38c-3.89.84-4.71-1.88-4.71-1.88a3.71 3.71 0 0 0-1.62-2.05c-1.27-.86.1-.85.1-.85a2.94 2.94 0 0 1 2.14 1.45a3 3 0 0 0 4.08 1.16a2.93 2.93 0 0 1 .88-1.87c-3.1-.36-6.37-1.56-6.37-6.92a5.4 5.4 0 0 1 1.44-3.76a5 5 0 0 1 .14-3.7s1.17-.38 3.85 1.43a13.3 13.3 0 0 1 7 0c2.67-1.81 3.84-1.43 3.84-1.43a5 5 0 0 1 .14 3.7a5.4 5.4 0 0 1 1.44 3.76c0 5.38-3.27 6.56-6.39 6.91a3.33 3.33 0 0 1 .95 2.59v3.84c0 .46.25.81 1 .67A14 14 0 0 0 16 2z" fill-rule="evenodd" fill="currentColor"></path></svg></li><!--]--></ul></nav><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><header class="sub-navbar-container not-open"><span class="nav-item"><div class="toggle-series-button" aria-expanded="false" role="button" tabindex="0"><span></span><span></span><span></span></div> Series </span></header><!----><!----><div class="theme-main" style=""><aside class="series-container"><!--[--><!--[--><section class="series-group series-item"><h5 class="series-heading series-level-1 active"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:16px;"><!--[-->机器学习<!--]--></span></span><span class="arrow down"></span></h5><ul style="display:block;"><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html" class="link series-item series-item" aria-label="PyTorch基础知识"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->PyTorch基础知识<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html" class="router-link-active router-link-exact-active link router-link-active series-item series-item" aria-label="实战1-离散分类问题"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战1-离散分类问题<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project2.html" class="link series-item series-item" aria-label="实战1-参考答案"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战1-参考答案<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/03_project1.html" class="link series-item series-item" aria-label="实战2-线性拟合问题"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战2-线性拟合问题<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/README.html" class="link series-item series-item" aria-label="/blogs/DeepLearning/PyTorch/README.html"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->/blogs/DeepLearning/PyTorch/README.html<!--]--></span></span><!--[--><!--]--></a><!--]--></li></ul></section><!--]--><!--]--></aside><!--[--><main class="page-container"><div class="page-content"><h1 class="page-title">实战1-离散分类问题</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AoSaiX<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2025-02-23<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/blog-vp-reco/categories/PyTorch/1.html" class="">PyTorch</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M10 14a4 4 0 1 1 4-4a4.005 4.005 0 0 1-4 4zm0-6a2 2 0 1 0 1.998 2.004A2.002 2.002 0 0 0 10 8z" fill="currentColor"></path><path d="M16.644 29.415L2.586 15.354A2 2 0 0 1 2 13.941V4a2 2 0 0 1 2-2h9.941a2 2 0 0 1 1.414.586l14.06 14.058a2 2 0 0 1 0 2.828l-9.943 9.943a2 2 0 0 1-2.829 0zM4 4v9.942L18.058 28L28 18.058L13.942 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/blog-vp-reco/tags/PyTorchshizhan/1.html" class="">PyTorch实战</a><a href="/blog-vp-reco/tags/luojihuigui/1.html" class="">逻辑回归</a><a href="/blog-vp-reco/tags/fenleiwenti/1.html" class="">分类问题</a><a href="/blog-vp-reco/tags/jianduxuexi/1.html" class="">监督学习</a><!--]--><!--]--></span></span><!----></div><div class="theme-reco-md-content"><div><h2 id="_1-实战练习" tabindex="-1"><a class="header-anchor" href="#_1-实战练习"><span>1. 实战练习</span></a></h2><p>手写数字识别项目可以视为机器学习中的“Hello World”，因为它涉及到数据收集、特征提取、模型选择、训练和评估等机器学习中的基本步骤。所以这个项目经常被当作机器学习的入门练习。</p><p>该项目的前身是 National Institute of Standards and Technology(美国国家标准技术研究所，简称 NIST)于 1998 年发布的一篇论文。该数据集的论文想要证明在模式识别问题上，基于 CNN 的方法可以取代之前的基于手工特征的方法，所以作者创建了一个手写数字的数据集，以手写数字识别作为例子证明 CNN 在模式识别问题上的优越性。</p><p>MNIST 数据集是从 NIST 的两个手写数字数据集：Special Database 3 和 Special Database 1 中分别取出部分图像，并经过一些图像处理后得到的。MNIST 数据集共有 70000 张图像，其中训练集 60000 张，测试集 10000 张。所有图像都是 28×28 的灰度图像，每张图像包含一个手写数字。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">dataset_compressed<span class="token operator">/</span></span>
<span class="line">├── t10k<span class="token operator">-</span>images<span class="token operator">-</span>idx3<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz             <span class="token comment">#测试集图像压缩包(1648877 bytes)</span></span>
<span class="line">├── t10k<span class="token operator">-</span>labels<span class="token operator">-</span>idx1<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz             <span class="token comment">#测试集标签压缩包(4542 bytes)</span></span>
<span class="line">├── train<span class="token operator">-</span>images<span class="token operator">-</span>idx3<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz            <span class="token comment">#训练集图像压缩包(9912422 bytes)</span></span>
<span class="line">└── train<span class="token operator">-</span>labels<span class="token operator">-</span>idx1<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz            <span class="token comment">#训练集标签压缩包(28881 bytes)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>.gz 是压缩后的文件格式，解压后会变成一种叫做 idx 格式的二进制文件，它将图像和标签都以矩阵的形式储存下来。以训练集的标签数据/图像数据为例子：</p><ul><li>训练集标签数据（train-labels-idx1-ubyte）</li></ul><table><thead><tr><th>偏移量(bytes)</th><th>值类型</th><th>数值</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>32 位整形</td><td>0x00000801</td><td>magic number</td></tr><tr><td>4</td><td>32 位整型</td><td>60000</td><td>有效标签的数量</td></tr><tr><td>8</td><td>8 位无符号整型</td><td>不定(0~9 之间)</td><td>标签</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>xxxx</td><td>8 位无符号整型</td><td>不定(0~9 之间)</td><td>标签</td></tr></tbody></table><ul><li>训练集图像数据（train-images-idx3-ubyte）</li></ul><table><thead><tr><th>偏移量(bytes)</th><th>值类型</th><th>数值</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>32 位整形</td><td>0x00000803</td><td>magic number</td></tr><tr><td>4</td><td>32 位整型</td><td>60000</td><td>有效图像的数量</td></tr><tr><td>8</td><td>32 位整型</td><td>28</td><td>图像的高(rows)</td></tr><tr><td>12</td><td>32 位整型</td><td>28</td><td>图像的宽(columns)</td></tr><tr><td>16</td><td>8 位无符号整型</td><td>不定(0~255 之间)</td><td>图像内容</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>xxxx</td><td>8 位无符号整型</td><td>不定(0~255 之间)</td><td>图像内容</td></tr></tbody></table><p>每个 idx 文件都以 magic number 开头，magic number 是一个 4 个字节，32 位的整数，用于说明该 idx 文件的 data 字段存储的数据类型。</p><p>前两个字节都是 0，第三个字节 0x08 表示 data 部分的数值类型都是“8 位无符号整型”，第四个字节 0x01 表示向量的维度。</p><p>标签只有一个维度，所以是 0x01，而图像数据，宽和高就占了两个维度，第三个维度就是所有图像叠在一起（想象一踏 A4 纸），每一个值都指向一张图像，所以是 0x03。</p><h3 id="_1-1-数据集的使用" tabindex="-1"><a class="header-anchor" href="#_1-1-数据集的使用"><span>1.1 数据集的使用</span></a></h3><p>（1）通过 torchvision 下载数据集</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms</span>
<span class="line"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> MNIST</span>
<span class="line"></span>
<span class="line"><span class="token comment"># define transform of data</span></span>
<span class="line">transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></span>
<span class="line">    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># download training dataset / testing dataset</span></span>
<span class="line">train_dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">test_dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>root 表示存储路径。它会检查文件是否已经存在，存在的话就不会再次下载。</li><li>train 表示数据集属于训练集还是测试集。</li><li>transform 属性对应上方自定义的预处理方式，这段代码中的预处理表示，先将其转换为 tensor 格式的向量，然后进行归一化处理。</li><li>download 属性表示 root 路径下不存在对应文件时，是否进行下载。</li></ul><p>（2）通过 scikit-learn 使用数据集</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml</span>
<span class="line"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</span>
<span class="line"></span>
<span class="line">mnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&#39;mnist_784&#39;</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> as_frame<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">X<span class="token punctuation">,</span> y <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">&#39;data&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mnist<span class="token punctuation">[</span><span class="token string">&#39;target&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 数据的类型：&lt;class &#39;numpy.ndarray&#39;&gt;，标签的类型：&lt;class &#39;numpy.ndarray&#39;&gt;</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;数据的类型：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">type</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">，标签的类型：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">type</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># data shape: (70000, 784)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;data shape:&#39;</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># label shape: (70000,)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;label shape:&#39;</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># show image</span></span>
<span class="line">image <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">&#39;gray&#39;</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Label:</span><span class="token interpolation"><span class="token punctuation">{</span>y<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>sklearn 是一个扁平化的数据集，一个图像存为一个向量，图像的大小 28*28=784，所以命名为 mnist_784。</p><ul><li>as_frame 属性是指：false 返回 numpy 数组；true 返回 pandas DataFrame 和 Series，可以直接通过 pandas 语言进行处理（预处理、分析、可视化等等）。</li><li>cache 属性是指是否缓存到本地。false，不缓存，每次使用从网络下载；true，缓存，优先从缓存路径读取。</li></ul><p>结尾是一个解构成图像的操作，使用 numpy 操作对索引为 1 的向量恢复成 28*28 的图像格式，然后用 matplotlib 显示。</p><p>（3）通过官网下载数据集</p><p>下载下来的文件和 torchvision 是一样的，但是现在官网的文件好像没有了，所以就不贴链接了，这里仅仅写一下怎么以文件的方式读取数据集。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token keyword">import</span> gzip</span>
<span class="line"><span class="token keyword">import</span> struct</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 读取图片文件</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">read_images</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token comment"># 通过 gzip 解压，并读取 ‘rb’ 二进制格式文件</span></span>
<span class="line">    <span class="token comment"># 如果已经在本地解压了，去掉 gzip 直接 open 就行了</span></span>
<span class="line">    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># struct.unpack() 用于解压二进制头部文件，格式是固定的前 16 字节</span></span>
<span class="line">        <span class="token comment"># 解构的四个类型的数值，在前面表格里已经介绍过了</span></span>
<span class="line">        magic<span class="token punctuation">,</span> num_images<span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols <span class="token operator">=</span> struct<span class="token punctuation">.</span>unpack<span class="token punctuation">(</span><span class="token string">&#39;&gt;IIII&#39;</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># f.read() 会读取文件剩余的所有字节</span></span>
<span class="line">        <span class="token comment"># np.frombuffer() 将字节串转换成一个 Numpy 数组</span></span>
<span class="line">        <span class="token comment"># np.uint8 是指定数据类型为 无符号8位整数，不是 utf-8！</span></span>
<span class="line">        image_data <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 重塑为 (num_images, rows * cols) 的矩阵，每行是一个扁平化的图像</span></span>
<span class="line">        images <span class="token operator">=</span> image_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>num_images<span class="token punctuation">,</span> rows <span class="token operator">*</span> cols<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 归一化处理</span></span>
<span class="line">        images <span class="token operator">=</span> images <span class="token operator">/</span> <span class="token number">255.0</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> images</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 读取标签文件</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">read_labels</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># 文件头是固定的，前 8 字节为文件头信息</span></span>
<span class="line">        magic<span class="token punctuation">,</span> num_labels <span class="token operator">=</span> struct<span class="token punctuation">.</span>unpack<span class="token punctuation">(</span><span class="token string">&#39;&gt;II&#39;</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 读取标签数据</span></span>
<span class="line">        labels <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> labels</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 示例：读取训练集和测试集</span></span>
<span class="line">train_images <span class="token operator">=</span> read_images<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/train-images-idx3-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">train_labels <span class="token operator">=</span> read_labels<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/train-labels-idx1-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">test_images <span class="token operator">=</span> read_images<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/t10k-images-idx3-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">test_labels <span class="token operator">=</span> read_labels<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/t10k-labels-idx1-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 打印一些信息，确保数据加载正常</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;训练集图像形状：</span><span class="token interpolation"><span class="token punctuation">{</span>train_images<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, 训练集标签形状：</span><span class="token interpolation"><span class="token punctuation">{</span>train_labels<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;测试集图像形状：</span><span class="token interpolation"><span class="token punctuation">{</span>test_images<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, 测试集标签形状：</span><span class="token interpolation"><span class="token punctuation">{</span>test_labels<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-数学题的解法" tabindex="-1"><a class="header-anchor" href="#_1-2-数学题的解法"><span>1.2 数学题的解法</span></a></h3><p>还记得在初中、高中做数学题的时候，一个问题，可能有很多种解法。但这并不意味着学霸的方法就一定好，学渣的方法就一定差，对于初学者而言，适合自己的，能够解决问题的方法就是好方法。</p><p>对于“手写数字识别”这个问题，常见的几种解法有：</p><ol><li>归一化指数函数 Softmax（用于多分类任务，是逻辑回归中二分类函数 Sigmoid 的推广）</li><li>卷积神经网络（CNN, Convolutional Neural Network）</li><li>支持向量机（SVM, Support Vector Machine）</li><li>K-近邻算法（KNN，K-Nearest Neighbor Classification）</li><li>随机森林（Random Forest）</li></ol><p><strong>（1）单层神经网络实现逻辑回归</strong></p><p>逻辑回归狭义上的讲，仅用于二分类问题，通过 Sigmoid 函数将输出映射到 [0, 1] 区间，表示概率。Softmax 是逻辑回归的推广，用于多分类问题，将输出映射为概率分布，所有类别的概率之和为 1。手写数字识别有十个输出值，0 ～ 9，它是一个多分类问题。</p><p>这里使用 torchvision 调用 MNIST 数据集，内容和 1.1 小节一样，不再赘述。接下来使用 DataLoader 函数加载数据：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</span>
<span class="line"></span>
<span class="line">batch_size <span class="token operator">=</span> <span class="token number">64</span></span>
<span class="line">train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>DataLoader 是 PyTorch 中用于加载数据的工具，它可以将数据集分成小批量（batches），并支持多线程加载数据。以下是它的核心功能和用法：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">DataLoader<span class="token punctuation">(</span></span>
<span class="line">    dataset<span class="token punctuation">,</span>           <span class="token comment"># 数据集（如 MNIST）</span></span>
<span class="line">    batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>     <span class="token comment"># 每批数据的大小（将数据集分成小批量（batches），方便训练）</span></span>
<span class="line">    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>     <span class="token comment"># 是否打乱数据（在每个 epoch 开始时打乱数据，避免模型过拟合）</span></span>
<span class="line">    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>     <span class="token comment"># 加载数据的线程数（通过多线程加速数据加载，减少训练时间）</span></span>
<span class="line">    drop_last<span class="token operator">=</span><span class="token boolean">False</span>    <span class="token comment"># 是否丢弃最后不足一个 batch 的数据</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>接着，通过继承 nn.Module 这个类，自定义逻辑回归的类和方法。torch.nn.Module 是 PyTorch 中所有神经网络模块的基类，它提供标准接口，自动管理参数，支持模型保存和加载等强大功能。</p><p>这里还有一个细节需要说明，为什么明明是多分类问题，不写 Sigmoid 函数或 Softmax 函数，反而用了一个 nn.Linear() 线性变换。回忆一下，逻辑回归的基础是线性回归，线性回归 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mo>⋅</mo><mi>x</mi><mo>+</mo><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">z=\vec{w}\cdot{x}+\vec{b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.714em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1522em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9774em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9774em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">b</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2355em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span></span></span></span> 作为逻辑回归 e 的指数形式存在。</p><p>损失函数是在模型的输出和真实标签之间计算的，通常都是输出层。因为本次没有使用隐藏层，只有输入层和输出层，并且使用的是交叉熵损失函数，它在运算时，会先计算 Softmax，再计算交叉熵。所以，在本次定义神经网络时，我们不需要显式的添加激活函数，仅仅只用 nn.Linear() 做线性变换即可。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Logistic model</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegression<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下一步，设置我们的超参数，实例化模型、损失函数、优化器。众所周知，英伟达系列显卡可以通过 cuda 进行加速运算，苹果 M 芯片系列的 MacBook 可以通过 MPS 进行加速。写这篇 blog 时，我用的 mac，所以是 mps。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"></span>
<span class="line"><span class="token comment"># check if mps can be use</span></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&#39;mps&#39;</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>mps<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&#39;cpu&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Using device: </span><span class="token interpolation"><span class="token punctuation">{</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># hyper parameters</span></span>
<span class="line"><span class="token builtin">input</span> <span class="token operator">=</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span>         <span class="token comment"># 输入的维度，也就是输入层神经元数量</span></span>
<span class="line">output <span class="token operator">=</span> <span class="token number">10</span>             <span class="token comment"># 输出层维度，输出层神经元数量</span></span>
<span class="line">learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>   <span class="token comment"># 学习率</span></span>
<span class="line">num_epochs <span class="token operator">=</span> <span class="token number">5</span>         <span class="token comment"># 训练多少轮</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化 模型、损失函数、优化器</span></span>
<span class="line"><span class="token comment"># 将自定义逻辑回归类初始化给 model 对象，然后发送给运算的硬件载体 mps 或 cpu</span></span>
<span class="line">model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 使用交叉熵作为损失函数</span></span>
<span class="line">criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># Adam优化器</span></span>
<span class="line">optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将训练模块和测试模块封装成函数。我个人觉得这样写挺优雅的，模块化、结构化，方便调用和扩展。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># training function</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    total_loss <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># images.view() 是 pytorch 的标准方法，用于改变张量的形状</span></span>
<span class="line">        <span class="token comment"># 但它并不改变数据本身，会返回一个新的张量，共享原始张量的数据存储</span></span>
<span class="line">        <span class="token comment"># 它要求张量的内存布局是连续的，如果不连续，需要先调用 .contiguous()</span></span>
<span class="line">        <span class="token comment"># 即 images.contiguous().view()</span></span>
<span class="line">        images <span class="token operator">=</span> images<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 向前传播 forward</span></span>
<span class="line">        <span class="token comment"># model(images) = model.forward(images)</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 交叉熵损失函数API标准参数：带有梯度信息的输出数据和标签</span></span>
<span class="line">        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 反向传播 backward</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 清空梯度</span></span>
<span class="line">        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 计算梯度</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 更新参数</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># loss.item() 当前批次的损失值</span></span>
<span class="line">        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># 计算平均损失并返回</span></span>
<span class="line">    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>model 是自定义 LogisticRegression 函数的实例，而该函数继承自 nn.Module，其中的 .train()方法和 .eval()方法用来切换模型的模式，训练模式需要引入随机性和动态调整，评估模式则不需要：</p><ul><li><p>model.train()为训练模式，会启用 Dropout 和 Batch Normalization 等层的训练行为。Dropout 会随机丢弃一些神经元，Batch Normalization 会使用当前批次的统计量。</p></li><li><p>model.eval()为评估模式，禁用 Dropout 和 Batch Normalization 等层的训练行为。Dropout 不会丢弃神经元，Batch Normalization 会使用训练时计算的全局统计量。</p></li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># testing function</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    correct <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    total <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># 禁用梯度计算，通常用于推理阶段（如测试和验证），以减少内存消耗并加速计算。</span></span>
<span class="line">    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span></span>
<span class="line">            <span class="token comment"># images 的形状是 [batch_size, 1, 28, 28]，1 表示单通道（灰度）图像</span></span>
<span class="line">            <span class="token comment"># 经过 .view() 扁平化为 [batch_size, 784]</span></span>
<span class="line">            images <span class="token operator">=</span> images<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span></span>
<span class="line">            <span class="token comment"># torch.max() 找到模型输出中每个样本的最大值（最高评分）及其对应的类别索引。</span></span>
<span class="line">            <span class="token comment"># 最大值（最高评分）我们不关心，所以用 _ 忽略，predicted 表示索引。</span></span>
<span class="line">            <span class="token comment"># outputs.data 表示模型输出的纯数据部分，形状为 [batch_size, num_classes]</span></span>
<span class="line">            <span class="token comment"># 训练函数中使用的 outputs 是一个包含梯度信息的张量</span></span>
<span class="line">            <span class="token comment"># 1 表示在第 1 维度上求最大值。</span></span>
<span class="line">            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">            <span class="token comment"># labels.size(0) 返回当前批次的样本数</span></span>
<span class="line">            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> correct <span class="token operator">/</span> total</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后就是训练函数与测试函数的调用，以及模型参数的保存。首先需要说明几个混淆概念，Epoch、Batch Size 和 Batch（批次）：</p><ul><li>Epoch：1 个 epoch 表示模型遍历整个训练/测试数据集一次。</li><li>Batch Size：每次训练时同时计算的样本数量。</li><li>Batch（批次）：将整个数据集分成若干个小块，每个小块就是一个 batch。就比如训练集 60000 张图像，我设置的 batch_size = 64，Batch = 训练集大小 / batch_size = 937。训练函数中的 loss.item() 当前批次的损失，以及测试函数中的 labels.size(0) 当前批次的样本数，指的就是这个批次。</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># training and testing</span></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, Test Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>test_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># save model</span></span>
<span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;mnist_model.pth&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;model saved to mnist_model.pth&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>torch.nn.Module 提供了 state_dict() 方法，可以方便地保存模型参数:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;model.pth&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 保存模型</span></span>
<span class="line">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&#39;model.pth&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 加载模型</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>（2）卷积神经网络</strong></p><p>经过刚才 softmax 的代码案例，我们已经学会了一种构建神经网络的方法。转换成神经网络 CNN，仅需要修改少数几个部分，首先是自定义 CNN 模型：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 在 softmax 中叫做 LogisticRegression</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 输入通道 1，MNIST 是灰度图像，通道数为 1</span></span>
<span class="line">        <span class="token comment"># 输出通道 32，卷积核的数量，即提取 32 种特征</span></span>
<span class="line">        <span class="token comment"># 卷积核大小 3*3；步长（stride）1，卷积核每次移动 1 像素；</span></span>
<span class="line">        <span class="token comment"># padding，表示在图像边缘填充 1 圈 0，防止图像边缘信息学习不充分</span></span>
<span class="line">        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 同理，输入 32个低级特征，输出 64个高级特征，其余参数未变</span></span>
<span class="line">        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化层，降低特征图的尺寸，减少计算量，同时增强特征的鲁棒性</span></span>
<span class="line">        <span class="token comment"># 池化核大小 2*2；步长（stride）为 2，表示池化核每次移动 2个像素；不填充像素</span></span>
<span class="line">        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 全连接层 1，将 3136 维特征映射到 128 维空间，学习特征之间的复杂关系</span></span>
<span class="line">        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 全连接层 2，也是输出层，将 128 维特征映射到 10 个类别空间</span></span>
<span class="line">        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 激活函数，引入非线性，是模型能够学习复杂的模式</span></span>
<span class="line">        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># 第一层卷积 + ReLU，输出形状 [batch_size, 32, 28, 28]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化，输出形状 [batch_size, 32, 14, 14]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 第二层卷积 + ReLU，输出形状 [batch_size, 64, 14, 14]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化，输出形状 [batch_size, 64, 7, 7]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 展平，两层卷积后特征数量为64，两次池化后特征图维度降低为 7*7</span></span>
<span class="line">        <span class="token comment"># 因此输出形状展平后变为 [batch_size, 3136（64 * 7 * 7）]</span></span>
<span class="line">        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">)</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 全连接层</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                 <span class="token comment"># 输出层</span></span>
<span class="line">        <span class="token keyword">return</span> x</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为什么设置两层卷积？第一层卷积提取低级特征（如边缘、纹理、线条等），第二层卷积在低级特征的基础上，提取更高级的特征（如形状、结构等）。通过多层卷积，模型可以逐步提取更复杂、更抽象的特征，从而提高分类性能。如果不记得，请翻阅《机器学习》中《2-1 神经网络初探》的 4.3 小节。</p><p>Conv2d 和 MaxPool2d 的使用方法已经在注释中说明了，相同类型的处理函数还有 1d 和 3d：</p><ul><li>Conv1d 和 MaxPool1d：用于 1D（1 维）数据，如时间序列、文本</li><li>Conv2d 和 MaxPool2d：用于 2D（2 维）数据，如图像</li><li>Conv3d 和 MaxPool3d：用于 3D（3 维）数据，如视频、医学图像</li></ul><p>其余就是一些小细节的变动：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 实例化模型的名称需要更名为 CNN</span></span>
<span class="line">model <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 训练函数和测试函数中不需要对数据扁平化了，直接发送给 device</span></span>
<span class="line">images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 保存模型的文件名需要修改一下</span></span>
<span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;mnist_cnn.pth&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>（3）SoftMax 与 CNN 的结果对比</p><p>除了准确度，运算时间我们也大概的计算一下，导入 time 模块，在 epoch 循环训练的前后加入时间记录代码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> time</span>
<span class="line"></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># training and testing</span></span>
<span class="line"><span class="token comment"># ......</span></span>
<span class="line">end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;xxx 模型5个Epoch的运算时间: </span><span class="token interpolation"><span class="token punctuation">{</span>softmax_time<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从结果可以看到出，卷积神经网络对于手写数字识别问题，准确度要比 SoftMax 高很多，99%的测试正确率。我们的运算时间是 5 轮训练加测试的时间，这个看不出什么。在实际的应用中，只会应用推理而不是训练，只要测试时间和 Softmax 差不多，应用时必定首选 CNN。有兴趣可以自己重写 time 计算，对比一下单次推理时间。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># SoftMax</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.4670</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9108</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3269</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9162</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3106</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9180</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">4</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3029</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9185</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.2939</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9187</span></span>
<span class="line">Softmax 模型<span class="token number">5</span>个Epoch的运算时间<span class="token punctuation">:</span> <span class="token number">18.785970</span> 秒</span>
<span class="line"></span>
<span class="line"><span class="token comment"># CNN</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.1567</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9859</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0446</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9875</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0314</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9864</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">4</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0228</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9871</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0172</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9905</span></span>
<span class="line">CNN 模型<span class="token number">5</span>个Epoch的运算时间<span class="token punctuation">:</span> <span class="token number">61.244848</span> 秒</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-3-补充-其余三种算法" tabindex="-1"><a class="header-anchor" href="#_1-3-补充-其余三种算法"><span>1.3 补充 - 其余三种算法</span></a></h3><p>支持向量机（SVM）、K 近邻算法（KNN）、随机森林这三种算法的实现相对简单，并且都用的 scikit-learn 这个库，所以就放在一起写了。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</span>
<span class="line"><span class="token keyword">import</span> time</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 加载完整的 MNIST 数据集</span></span>
<span class="line">mnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span><span class="token string">&#39;mnist_784&#39;</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">X <span class="token operator">=</span> mnist<span class="token punctuation">.</span>data  <span class="token comment"># 特征</span></span>
<span class="line">y <span class="token operator">=</span> mnist<span class="token punctuation">.</span>target<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>  <span class="token comment"># 标签</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># random_state 随机种子，控制着数据集划分的随机性，每次拆分都按这个拆分，保证了结果的可重复性</span></span>
<span class="line">X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span></span>
<span class="line">    X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> train_size<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># SVM前置工作，标准化数据，和使用 PCA 降维</span></span>
<span class="line">scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">X_train_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span></span>
<span class="line">X_test_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span></span>
<span class="line">X_train_pca <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train_scaled<span class="token punctuation">)</span></span>
<span class="line">X_test_pca <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test_scaled<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># SVM</span></span>
<span class="line">svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">&#39;linear&#39;</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">svm_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_pca<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> svm_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_pca<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;SVM 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># KNN</span></span>
<span class="line"><span class="token comment"># n_neighbors 表示选择三个最邻近进行评分； n_jobs = -1 表示使用所有 CPU 核心</span></span>
<span class="line">knn_model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">knn_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> knn_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;KNN 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 随机森林</span></span>
<span class="line"><span class="token comment"># n_estimators = 10：使用 10 棵树</span></span>
<span class="line">rf_model <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">rf_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> rf_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;随机森林 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练的时候 SVM 模块遇到了点问题，因为 sklearn 使用的是扁平化数据，一共 28*28 = 784 维，并且它是使用 CPU 进行计算的。一方面数据量大了之后，特征计算成指数级增长，另一个方面就是运算慢，我训练集数据降到 30% 才能正常运行。为了使用全部数据，我采用了 PCA 降维的方法处理。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">SVM 准确率<span class="token punctuation">:</span> <span class="token number">0.9349</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">45.4076</span> 秒</span>
<span class="line">KNN 准确率<span class="token punctuation">:</span> <span class="token number">0.9713</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">0.0592</span> 秒</span>
<span class="line">随机森林准确率<span class="token punctuation">:</span> <span class="token number">0.9458</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">0.5464</span> 秒</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到 KNN 和随机森林的训练时间非常短，准确率虽然比不过 CNN，但是也还不错。</p><p>sklearn 中还有一个 8*8 的小型手写数字识别的数据集，包含 1797 个数据，每张图像展平后是 64 维，这个数据集 SVM 就可以不进行 PCA 降维。 8*8 图像虽然分辨率较低，但仍然有一些应用价值，比如:</p><ul><li>快速原型开发：用于验证模型的基本功能；或者在计算资源有限的环境中测试模型。</li><li>嵌入式设备：单片机、嵌入式摄像头……</li><li>数据增强：作为高分辨率图像的缩略图，用于数据增强或快速筛选。</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 加载 8*8 的小型 MNIST 数据集</span></span>
<span class="line">digits <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_digits<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">X <span class="token operator">=</span> digits<span class="token punctuation">.</span>data  <span class="token comment"># 特征</span></span>
<span class="line">y <span class="token operator">=</span> digits<span class="token punctuation">.</span>target  <span class="token comment"># 标签</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-实战测验" tabindex="-1"><a class="header-anchor" href="#_2-实战测验"><span>2. 实战测验</span></a></h2><p>实践是检验真理的唯一标准。</p><h3 id="_2-1-ai-模型练习平台" tabindex="-1"><a class="header-anchor" href="#_2-1-ai-模型练习平台"><span>2.1 AI 模型练习平台</span></a></h3><p>AI 模型的练习和比赛，同样也有类似 Leetcode（算法） 或 CTF（网络攻防） 这种专门的平台。从使用人数、科研应用、就业机会三个方面，我挑选了 5 个最常用的机器学习平台。</p><ol><li><p>Kaggle：全球最大的机器学习竞赛平台，提供各种真实数据集，适用于各个领域的科研实践。需要数据科学和机器学习公司在招聘时，都会关注求职者在 Kaggle 上的成绩。</p></li><li><p>DrivenData：相较于 Kaggle 较小，主要集中在解决社会问题，如健康、教育等领域。</p></li><li><p>AI Challenger：在国内较为出名，尤其是在中文 NLP 和语音识别等方面有较强的影响力。国内公司（百度、阿里、腾讯等）会比较关注优胜者，相关比赛成绩有助于就业。</p></li><li><p>Zindi：用户社群相对活跃，特别是在非洲。Zindi 提供与全球社会和企业相关的多种挑战，特别适合需要解决大规模数据问题的科研人员。</p></li><li><p>Hackerearth：使用人数相对较多，尤其是在印度等地有广泛的影响力。提供了多种 机器学习 和 数据科学 相关的挑战，适合研究人员提升实际应用能力。</p></li></ol><h3 id="_2-2-经典分类问题" tabindex="-1"><a class="header-anchor" href="#_2-2-经典分类问题"><span>2.2 经典分类问题</span></a></h3><p><strong>1. 二分类问题：肿瘤分类（Breast Cancer Dataset）</strong></p><p>目标：判断乳腺肿瘤是良性还是恶性。数据来源：<a href="https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic" target="_blank" rel="noopener noreferrer">UCI ML Repository - Breast Cancer Wisconsin (Diagnostic)<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>该数据集包含 30 个特征，如肿瘤的大小、形状、纹理等，用于判断肿瘤的类型。属于医疗领域（医学图像处理）的经典案例。难度指数 2 颗星。</p><p><strong>2. 二分类问题：泰坦尼克号幸存者预测</strong></p><p>目标：构建一个预测模型，回答“什么样的人更有可能生存”这个问题。数据来源：<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener noreferrer">Kaggle - Titanic<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>该问题是 Kaggle 中的一个长期公开的挑战练习题：虽然生存下来有一些运气因素，但似乎某些群体比其他人更有可能生存下来。该数据集包含各种关于乘客的特征，比如年龄、性别、票价、船舱等信息。难度指数 3 颗星。</p><p><strong>3. 多分类问题：鸢尾花分类（Iris Dataset）</strong></p><p>目标：区分三种不同类型的鸢尾花（Setosa、Versicolor 和 Virginica）。数据来源：<a href="https://archive.ics.uci.edu/dataset/53/iris" target="_blank" rel="noopener noreferrer">UCI ML Repository - Iris<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。该数据集包含四个特征，比手写数字识别更适合多分类问题的入门。难度指数 1 颗星。</p><p><strong>4. 多分类问题：猫狗图像区分（Dogs vs Cats）</strong></p><p>简单来看，是个二分问题，区分猫和狗；复杂来看，可以扩展到多分类问题，区分猫和狗，并且区分猫的品种和狗的品种。适合用卷积神经网络等深度学习模型来练手。</p><p>数据来源：<a href="https://www.kaggle.com/c/dogs-vs-cats" target="_blank" rel="noopener noreferrer">Kaggle - Dogs vs. Cats<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。难度指数 3 颗星。前面的链接是比赛链接，该比赛已经结束且并未公开，但是可以从 Kaggle 的数据集仓库中找到相关数据集：<a href="https://www.kaggle.com/c/dogs-vs-cats" target="_blank" rel="noopener noreferrer">Kaggle - Cat and Dog<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。</p><p><strong>5. 多标签分类问题：情感分析（Sentiment Analysis）</strong></p><p>情感分析是一个典型的“多标签分类”问题，通常对文本进行情感分类，如正面、负面、中性等标签。数据集包含一系列社交媒体评论、产品评价等文本，每个文本可能有多个情感标签（例如“正面”和“中性”）。</p><p>数据来源：<a href="https://www.kaggle.com/datasets/kazanova/sentiment140" target="_blank" rel="noopener noreferrer">Kaggle - Sentiment140 dataset with 1.6 million tweets<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。难度指数 4 颗星。</p><h3 id="_2-3-参考答案" tabindex="-1"><a class="header-anchor" href="#_2-3-参考答案"><span>2.3 参考答案</span></a></h3><p>我并不知道我写的是否就是当前最佳的解决方案，也许有比我更好的方法，希望各位跑完自己的代码，和我的代码以及网络博客中大佬们的代码，相互做做比较。取其精华，去其糟粕。</p><table><thead><tr><th>任务</th><th>SVM</th><th>KNN</th><th>Random Forest</th><th>Softmax</th><th>CNN</th></tr></thead><tbody><tr><td>肿瘤分类</td><td><mark>✓</mark></td><td>✓</td><td><mark>✓</mark></td><td>✗</td><td>✗</td></tr><tr><td>鸢尾花分类</td><td>✓</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td>✗</td></tr><tr><td>幸存者预测</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td>✗</td><td>✗</td></tr><tr><td>猫狗分类</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td><td><mark>✓</mark></td></tr><tr><td>情感分析</td><td>✓</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td><mark>✓</mark></td></tr></tbody></table><p>❌ 号表示不合适，✅ 号表示可以做，标黄的 ✅ 号表示推荐方法。请翻阅下一章《实战 1-参考答案》</p></div></div><footer class="page-meta"><div class="meta-item edit-link"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M2 26h28v2H2z" fill="currentColor"></path><path d="M25.4 9c.8-.8.8-2 0-2.8l-3.6-3.6c-.8-.8-2-.8-2.8 0l-15 15V24h6.4l15-15zm-5-5L24 7.6l-3 3L17.4 7l3-3zM6 22v-3.6l10-10l3.6 3.6l-10 10H6z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Edit this page<!--]--></span></span></div><div class="meta-item last-updated"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Git仓库提交时间 2025/9/21 01:39:30<!--]--></span></span></div></footer><nav class="page-nav"><p class="hasPrev hasNext inner"><span class="page-nav-item prev"> ← PyTorch基础知识</span><span class="page-nav-item next">实战1-参考答案 → </span></p></nav><!----></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_1-实战练习" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1. 实战练习"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1. 实战练习<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_1-1-数据集的使用" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.1 数据集的使用"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.1 数据集的使用<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_1-2-数学题的解法" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.2 数学题的解法"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.2 数学题的解法<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_1-3-补充-其余三种算法" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.3 补充 - 其余三种算法"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.3 补充 - 其余三种算法<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_2-实战测验" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2. 实战测验"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2. 实战测验<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_2-1-ai-模型练习平台" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.1 AI 模型练习平台"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.1 AI 模型练习平台<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_2-2-经典分类问题" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.2 经典分类问题"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.2 经典分类问题<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html#_2-3-参考答案" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.3 参考答案"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.3 参考答案<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--]--></ul></div></main><!--]--></div></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/blog-vp-reco/assets/app-P8O63--9.js" defer></script>
  </body>
</html>
