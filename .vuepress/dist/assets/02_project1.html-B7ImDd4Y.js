import{_ as c,c as l,a as t,b as s,d as a,e,r as i,o}from"./app-Ccl-ihA3.js";const u={},r={class:"katex"},d={class:"katex-html","aria-hidden":"true"},k={class:"base"},m={class:"mord accent"},v={class:"vlist-t"},b={class:"vlist-r"},g={class:"vlist",style:{height:"0.714em"}},h={style:{top:"-3em"}},y={class:"accent-body",style:{left:"-0.1522em"}},_={class:"overlay",style:{height:"0.714em",width:"0.471em"}},f={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},w={class:"base"},x={class:"mord accent"},N={class:"vlist-t"},S={class:"vlist-r"},z={class:"vlist",style:{height:"0.9774em"}},M={style:{top:"-3.2634em"}},C={class:"accent-body",style:{left:"-0.2355em"}},T={class:"overlay",style:{height:"0.714em",width:"0.471em"}},L={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},I={href:"https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic",target:"_blank",rel:"noopener noreferrer"},A={href:"https://www.kaggle.com/c/titanic",target:"_blank",rel:"noopener noreferrer"},j={href:"https://archive.ics.uci.edu/dataset/53/iris",target:"_blank",rel:"noopener noreferrer"},D={href:"https://www.kaggle.com/c/dogs-vs-cats",target:"_blank",rel:"noopener noreferrer"},X={href:"https://www.kaggle.com/c/dogs-vs-cats",target:"_blank",rel:"noopener noreferrer"},q={href:"https://www.kaggle.com/datasets/kazanova/sentiment140",target:"_blank",rel:"noopener noreferrer"};function P(K,n){const p=i("ExternalLinkIcon");return o(),l("div",null,[n[31]||(n[31]=t(`<h2 id="_1-实战练习" tabindex="-1"><a class="header-anchor" href="#_1-实战练习"><span>1. 实战练习</span></a></h2><p>手写数字识别项目可以视为机器学习中的“Hello World”，因为它涉及到数据收集、特征提取、模型选择、训练和评估等机器学习中的基本步骤。所以这个项目经常被当作机器学习的入门练习。</p><p>该项目的前身是 National Institute of Standards and Technology(美国国家标准技术研究所，简称 NIST)于 1998 年发布的一篇论文。该数据集的论文想要证明在模式识别问题上，基于 CNN 的方法可以取代之前的基于手工特征的方法，所以作者创建了一个手写数字的数据集，以手写数字识别作为例子证明 CNN 在模式识别问题上的优越性。</p><p>MNIST 数据集是从 NIST 的两个手写数字数据集：Special Database 3 和 Special Database 1 中分别取出部分图像，并经过一些图像处理后得到的。MNIST 数据集共有 70000 张图像，其中训练集 60000 张，测试集 10000 张。所有图像都是 28×28 的灰度图像，每张图像包含一个手写数字。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">dataset_compressed<span class="token operator">/</span></span>
<span class="line">├── t10k<span class="token operator">-</span>images<span class="token operator">-</span>idx3<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz             <span class="token comment">#测试集图像压缩包(1648877 bytes)</span></span>
<span class="line">├── t10k<span class="token operator">-</span>labels<span class="token operator">-</span>idx1<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz             <span class="token comment">#测试集标签压缩包(4542 bytes)</span></span>
<span class="line">├── train<span class="token operator">-</span>images<span class="token operator">-</span>idx3<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz            <span class="token comment">#训练集图像压缩包(9912422 bytes)</span></span>
<span class="line">└── train<span class="token operator">-</span>labels<span class="token operator">-</span>idx1<span class="token operator">-</span>ubyte<span class="token punctuation">.</span>gz            <span class="token comment">#训练集标签压缩包(28881 bytes)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>.gz 是压缩后的文件格式，解压后会变成一种叫做 idx 格式的二进制文件，它将图像和标签都以矩阵的形式储存下来。以训练集的标签数据/图像数据为例子：</p><ul><li>训练集标签数据（train-labels-idx1-ubyte）</li></ul><table><thead><tr><th>偏移量(bytes)</th><th>值类型</th><th>数值</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>32 位整形</td><td>0x00000801</td><td>magic number</td></tr><tr><td>4</td><td>32 位整型</td><td>60000</td><td>有效标签的数量</td></tr><tr><td>8</td><td>8 位无符号整型</td><td>不定(0~9 之间)</td><td>标签</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>xxxx</td><td>8 位无符号整型</td><td>不定(0~9 之间)</td><td>标签</td></tr></tbody></table><ul><li>训练集图像数据（train-images-idx3-ubyte）</li></ul><table><thead><tr><th>偏移量(bytes)</th><th>值类型</th><th>数值</th><th>含义</th></tr></thead><tbody><tr><td>0</td><td>32 位整形</td><td>0x00000803</td><td>magic number</td></tr><tr><td>4</td><td>32 位整型</td><td>60000</td><td>有效图像的数量</td></tr><tr><td>8</td><td>32 位整型</td><td>28</td><td>图像的高(rows)</td></tr><tr><td>12</td><td>32 位整型</td><td>28</td><td>图像的宽(columns)</td></tr><tr><td>16</td><td>8 位无符号整型</td><td>不定(0~255 之间)</td><td>图像内容</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>xxxx</td><td>8 位无符号整型</td><td>不定(0~255 之间)</td><td>图像内容</td></tr></tbody></table><p>每个 idx 文件都以 magic number 开头，magic number 是一个 4 个字节，32 位的整数，用于说明该 idx 文件的 data 字段存储的数据类型。</p><p>前两个字节都是 0，第三个字节 0x08 表示 data 部分的数值类型都是“8 位无符号整型”，第四个字节 0x01 表示向量的维度。</p><p>标签只有一个维度，所以是 0x01，而图像数据，宽和高就占了两个维度，第三个维度就是所有图像叠在一起（想象一踏 A4 纸），每一个值都指向一张图像，所以是 0x03。</p><h3 id="_1-1-数据集的使用" tabindex="-1"><a class="header-anchor" href="#_1-1-数据集的使用"><span>1.1 数据集的使用</span></a></h3><p>（1）通过 torchvision 下载数据集</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms</span>
<span class="line"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> MNIST</span>
<span class="line"></span>
<span class="line"><span class="token comment"># define transform of data</span></span>
<span class="line">transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></span>
<span class="line">    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># download training dataset / testing dataset</span></span>
<span class="line">train_dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">test_dataset <span class="token operator">=</span> MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>root 表示存储路径。它会检查文件是否已经存在，存在的话就不会再次下载。</li><li>train 表示数据集属于训练集还是测试集。</li><li>transform 属性对应上方自定义的预处理方式，这段代码中的预处理表示，先将其转换为 tensor 格式的向量，然后进行归一化处理。</li><li>download 属性表示 root 路径下不存在对应文件时，是否进行下载。</li></ul><p>（2）通过 scikit-learn 使用数据集</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml</span>
<span class="line"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</span>
<span class="line"></span>
<span class="line">mnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&#39;mnist_784&#39;</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> as_frame<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">X<span class="token punctuation">,</span> y <span class="token operator">=</span> mnist<span class="token punctuation">[</span><span class="token string">&#39;data&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mnist<span class="token punctuation">[</span><span class="token string">&#39;target&#39;</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 数据的类型：&lt;class &#39;numpy.ndarray&#39;&gt;，标签的类型：&lt;class &#39;numpy.ndarray&#39;&gt;</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;数据的类型：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">type</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">，标签的类型：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">type</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># data shape: (70000, 784)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;data shape:&#39;</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># label shape: (70000,)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;label shape:&#39;</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># show image</span></span>
<span class="line">image <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">&#39;gray&#39;</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Label:</span><span class="token interpolation"><span class="token punctuation">{</span>y<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>sklearn 是一个扁平化的数据集，一个图像存为一个向量，图像的大小 28*28=784，所以命名为 mnist_784。</p><ul><li>as_frame 属性是指：false 返回 numpy 数组；true 返回 pandas DataFrame 和 Series，可以直接通过 pandas 语言进行处理（预处理、分析、可视化等等）。</li><li>cache 属性是指是否缓存到本地。false，不缓存，每次使用从网络下载；true，缓存，优先从缓存路径读取。</li></ul><p>结尾是一个解构成图像的操作，使用 numpy 操作对索引为 1 的向量恢复成 28*28 的图像格式，然后用 matplotlib 显示。</p><p>（3）通过官网下载数据集</p><p>下载下来的文件和 torchvision 是一样的，但是现在官网的文件好像没有了，所以就不贴链接了，这里仅仅写一下怎么以文件的方式读取数据集。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token keyword">import</span> gzip</span>
<span class="line"><span class="token keyword">import</span> struct</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 读取图片文件</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">read_images</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token comment"># 通过 gzip 解压，并读取 ‘rb’ 二进制格式文件</span></span>
<span class="line">    <span class="token comment"># 如果已经在本地解压了，去掉 gzip 直接 open 就行了</span></span>
<span class="line">    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># struct.unpack() 用于解压二进制头部文件，格式是固定的前 16 字节</span></span>
<span class="line">        <span class="token comment"># 解构的四个类型的数值，在前面表格里已经介绍过了</span></span>
<span class="line">        magic<span class="token punctuation">,</span> num_images<span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols <span class="token operator">=</span> struct<span class="token punctuation">.</span>unpack<span class="token punctuation">(</span><span class="token string">&#39;&gt;IIII&#39;</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># f.read() 会读取文件剩余的所有字节</span></span>
<span class="line">        <span class="token comment"># np.frombuffer() 将字节串转换成一个 Numpy 数组</span></span>
<span class="line">        <span class="token comment"># np.uint8 是指定数据类型为 无符号8位整数，不是 utf-8！</span></span>
<span class="line">        image_data <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 重塑为 (num_images, rows * cols) 的矩阵，每行是一个扁平化的图像</span></span>
<span class="line">        images <span class="token operator">=</span> image_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>num_images<span class="token punctuation">,</span> rows <span class="token operator">*</span> cols<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 归一化处理</span></span>
<span class="line">        images <span class="token operator">=</span> images <span class="token operator">/</span> <span class="token number">255.0</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> images</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 读取标签文件</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">read_labels</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># 文件头是固定的，前 8 字节为文件头信息</span></span>
<span class="line">        magic<span class="token punctuation">,</span> num_labels <span class="token operator">=</span> struct<span class="token punctuation">.</span>unpack<span class="token punctuation">(</span><span class="token string">&#39;&gt;II&#39;</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 读取标签数据</span></span>
<span class="line">        labels <span class="token operator">=</span> np<span class="token punctuation">.</span>frombuffer<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> labels</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 示例：读取训练集和测试集</span></span>
<span class="line">train_images <span class="token operator">=</span> read_images<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/train-images-idx3-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">train_labels <span class="token operator">=</span> read_labels<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/train-labels-idx1-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">test_images <span class="token operator">=</span> read_images<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/t10k-images-idx3-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line">test_labels <span class="token operator">=</span> read_labels<span class="token punctuation">(</span><span class="token string">&#39;./data/MNIST/raw/t10k-labels-idx1-ubyte.gz&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 打印一些信息，确保数据加载正常</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;训练集图像形状：</span><span class="token interpolation"><span class="token punctuation">{</span>train_images<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, 训练集标签形状：</span><span class="token interpolation"><span class="token punctuation">{</span>train_labels<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;测试集图像形状：</span><span class="token interpolation"><span class="token punctuation">{</span>test_images<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">, 测试集标签形状：</span><span class="token interpolation"><span class="token punctuation">{</span>test_labels<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-数学题的解法" tabindex="-1"><a class="header-anchor" href="#_1-2-数学题的解法"><span>1.2 数学题的解法</span></a></h3><p>还记得在初中、高中做数学题的时候，一个问题，可能有很多种解法。但这并不意味着学霸的方法就一定好，学渣的方法就一定差，对于初学者而言，适合自己的，能够解决问题的方法就是好方法。</p><p>对于“手写数字识别”这个问题，常见的几种解法有：</p><ol><li>归一化指数函数 Softmax（用于多分类任务，是逻辑回归中二分类函数 Sigmoid 的推广）</li><li>卷积神经网络（CNN, Convolutional Neural Network）</li><li>支持向量机（SVM, Support Vector Machine）</li><li>K-近邻算法（KNN，K-Nearest Neighbor Classification）</li><li>随机森林（Random Forest）</li></ol><p><strong>（1）单层神经网络实现逻辑回归</strong></p><p>逻辑回归狭义上的讲，仅用于二分类问题，通过 Sigmoid 函数将输出映射到 [0, 1] 区间，表示概率。Softmax 是逻辑回归的推广，用于多分类问题，将输出映射为概率分布，所有类别的概率之和为 1。手写数字识别有十个输出值，0 ～ 9，它是一个多分类问题。</p><p>这里使用 torchvision 调用 MNIST 数据集，内容和 1.1 小节一样，不再赘述。接下来使用 DataLoader 函数加载数据：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</span>
<span class="line"></span>
<span class="line">batch_size <span class="token operator">=</span> <span class="token number">64</span></span>
<span class="line">train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>DataLoader 是 PyTorch 中用于加载数据的工具，它可以将数据集分成小批量（batches），并支持多线程加载数据。以下是它的核心功能和用法：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">DataLoader<span class="token punctuation">(</span></span>
<span class="line">    dataset<span class="token punctuation">,</span>           <span class="token comment"># 数据集（如 MNIST）</span></span>
<span class="line">    batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>     <span class="token comment"># 每批数据的大小（将数据集分成小批量（batches），方便训练）</span></span>
<span class="line">    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>     <span class="token comment"># 是否打乱数据（在每个 epoch 开始时打乱数据，避免模型过拟合）</span></span>
<span class="line">    num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>     <span class="token comment"># 加载数据的线程数（通过多线程加速数据加载，减少训练时间）</span></span>
<span class="line">    drop_last<span class="token operator">=</span><span class="token boolean">False</span>    <span class="token comment"># 是否丢弃最后不足一个 batch 的数据</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>接着，通过继承 nn.Module 这个类，自定义逻辑回归的类和方法。torch.nn.Module 是 PyTorch 中所有神经网络模块的基类，它提供标准接口，自动管理参数，支持模型保存和加载等强大功能。</p>`,36)),s("p",null,[n[14]||(n[14]=a("这里还有一个细节需要说明，为什么明明是多分类问题，不写 Sigmoid 函数或 Softmax 函数，反而用了一个 nn.Linear() 线性变换。回忆一下，逻辑回归的基础是线性回归，线性回归 ",-1)),s("span",r,[n[13]||(n[13]=t('<span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mo>⋅</mo><mi>x</mi><mo>+</mo><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">z=\\vec{w}\\cdot{x}+\\vec{b}</annotation></semantics></math></span>',1)),s("span",d,[n[11]||(n[11]=t('<span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span>',1)),s("span",k,[n[3]||(n[3]=s("span",{class:"strut",style:{height:"0.714em"}},null,-1)),s("span",m,[s("span",v,[s("span",b,[s("span",g,[n[2]||(n[2]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w")],-1)),s("span",h,[n[1]||(n[1]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",y,[s("span",_,[(o(),l("svg",f,n[0]||(n[0]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])]),n[4]||(n[4]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1)),n[5]||(n[5]=s("span",{class:"mbin"},"⋅",-1)),n[6]||(n[6]=s("span",{class:"mspace",style:{"margin-right":"0.2222em"}},null,-1))]),n[12]||(n[12]=t('<span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span>',1)),s("span",w,[n[10]||(n[10]=s("span",{class:"strut",style:{height:"0.9774em"}},null,-1)),s("span",x,[s("span",N,[s("span",S,[s("span",z,[n[9]||(n[9]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"b")],-1)),s("span",M,[n[8]||(n[8]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",C,[s("span",T,[(o(),l("svg",L,n[7]||(n[7]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])])])])]),n[15]||(n[15]=a(" 作为逻辑回归 e 的指数形式存在。",-1))]),n[32]||(n[32]=t(`<p>损失函数是在模型的输出和真实标签之间计算的，通常都是输出层。因为本次没有使用隐藏层，只有输入层和输出层，并且使用的是交叉熵损失函数，它在运算时，会先计算 Softmax，再计算交叉熵。所以，在本次定义神经网络时，我们不需要显式的添加激活函数，仅仅只用 nn.Linear() 做线性变换即可。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Logistic model</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegression<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下一步，设置我们的超参数，实例化模型、损失函数、优化器。众所周知，英伟达系列显卡可以通过 cuda 进行加速运算，苹果 M 芯片系列的 MacBook 可以通过 MPS 进行加速。写这篇 blog 时，我用的 mac，所以是 mps。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"></span>
<span class="line"><span class="token comment"># check if mps can be use</span></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&#39;mps&#39;</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>mps<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&#39;cpu&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Using device: </span><span class="token interpolation"><span class="token punctuation">{</span>device<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># hyper parameters</span></span>
<span class="line"><span class="token builtin">input</span> <span class="token operator">=</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span>         <span class="token comment"># 输入的维度，也就是输入层神经元数量</span></span>
<span class="line">output <span class="token operator">=</span> <span class="token number">10</span>             <span class="token comment"># 输出层维度，输出层神经元数量</span></span>
<span class="line">learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>   <span class="token comment"># 学习率</span></span>
<span class="line">num_epochs <span class="token operator">=</span> <span class="token number">5</span>         <span class="token comment"># 训练多少轮</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 初始化 模型、损失函数、优化器</span></span>
<span class="line"><span class="token comment"># 将自定义逻辑回归类初始化给 model 对象，然后发送给运算的硬件载体 mps 或 cpu</span></span>
<span class="line">model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> output<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># 使用交叉熵作为损失函数</span></span>
<span class="line">criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># Adam优化器</span></span>
<span class="line">optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将训练模块和测试模块封装成函数。我个人觉得这样写挺优雅的，模块化、结构化，方便调用和扩展。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># training function</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    total_loss <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># images.view() 是 pytorch 的标准方法，用于改变张量的形状</span></span>
<span class="line">        <span class="token comment"># 但它并不改变数据本身，会返回一个新的张量，共享原始张量的数据存储</span></span>
<span class="line">        <span class="token comment"># 它要求张量的内存布局是连续的，如果不连续，需要先调用 .contiguous()</span></span>
<span class="line">        <span class="token comment"># 即 images.contiguous().view()</span></span>
<span class="line">        images <span class="token operator">=</span> images<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 向前传播 forward</span></span>
<span class="line">        <span class="token comment"># model(images) = model.forward(images)</span></span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 交叉熵损失函数API标准参数：带有梯度信息的输出数据和标签</span></span>
<span class="line">        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># 反向传播 backward</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 清空梯度</span></span>
<span class="line">        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 计算梯度</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 更新参数</span></span>
<span class="line"></span>
<span class="line">        <span class="token comment"># loss.item() 当前批次的损失值</span></span>
<span class="line">        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># 计算平均损失并返回</span></span>
<span class="line">    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>model 是自定义 LogisticRegression 函数的实例，而该函数继承自 nn.Module，其中的 .train()方法和 .eval()方法用来切换模型的模式，训练模式需要引入随机性和动态调整，评估模式则不需要：</p><ul><li><p>model.train()为训练模式，会启用 Dropout 和 Batch Normalization 等层的训练行为。Dropout 会随机丢弃一些神经元，Batch Normalization 会使用当前批次的统计量。</p></li><li><p>model.eval()为评估模式，禁用 Dropout 和 Batch Normalization 等层的训练行为。Dropout 不会丢弃神经元，Batch Normalization 会使用训练时计算的全局统计量。</p></li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># testing function</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    correct <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    total <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment"># 禁用梯度计算，通常用于推理阶段（如测试和验证），以减少内存消耗并加速计算。</span></span>
<span class="line">    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span></span>
<span class="line">            <span class="token comment"># images 的形状是 [batch_size, 1, 28, 28]，1 表示单通道（灰度）图像</span></span>
<span class="line">            <span class="token comment"># 经过 .view() 扁平化为 [batch_size, 784]</span></span>
<span class="line">            images <span class="token operator">=</span> images<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line">            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span></span>
<span class="line">            <span class="token comment"># torch.max() 找到模型输出中每个样本的最大值（最高评分）及其对应的类别索引。</span></span>
<span class="line">            <span class="token comment"># 最大值（最高评分）我们不关心，所以用 _ 忽略，predicted 表示索引。</span></span>
<span class="line">            <span class="token comment"># outputs.data 表示模型输出的纯数据部分，形状为 [batch_size, num_classes]</span></span>
<span class="line">            <span class="token comment"># 训练函数中使用的 outputs 是一个包含梯度信息的张量</span></span>
<span class="line">            <span class="token comment"># 1 表示在第 1 维度上求最大值。</span></span>
<span class="line">            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">            <span class="token comment"># labels.size(0) 返回当前批次的样本数</span></span>
<span class="line">            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> correct <span class="token operator">/</span> total</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后就是训练函数与测试函数的调用，以及模型参数的保存。首先需要说明几个混淆概念，Epoch、Batch Size 和 Batch（批次）：</p><ul><li>Epoch：1 个 epoch 表示模型遍历整个训练/测试数据集一次。</li><li>Batch Size：每次训练时同时计算的样本数量。</li><li>Batch（批次）：将整个数据集分成若干个小块，每个小块就是一个 batch。就比如训练集 60000 张图像，我设置的 batch_size = 64，Batch = 训练集大小 / batch_size = 937。训练函数中的 loss.item() 当前批次的损失，以及测试函数中的 labels.size(0) 当前批次的样本数，指的就是这个批次。</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># training and testing</span></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    test_acc <span class="token operator">=</span> test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">,</span> device<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, Test Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span>test_acc<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># save model</span></span>
<span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;mnist_model.pth&#39;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;model saved to mnist_model.pth&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>torch.nn.Module 提供了 state_dict() 方法，可以方便地保存模型参数:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;model.pth&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 保存模型</span></span>
<span class="line">model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&#39;model.pth&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 加载模型</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>（2）卷积神经网络</strong></p><p>经过刚才 softmax 的代码案例，我们已经学会了一种构建神经网络的方法。转换成神经网络 CNN，仅需要修改少数几个部分，首先是自定义 CNN 模型：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 在 softmax 中叫做 LogisticRegression</span></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 输入通道 1，MNIST 是灰度图像，通道数为 1</span></span>
<span class="line">        <span class="token comment"># 输出通道 32，卷积核的数量，即提取 32 种特征</span></span>
<span class="line">        <span class="token comment"># 卷积核大小 3*3；步长（stride）1，卷积核每次移动 1 像素；</span></span>
<span class="line">        <span class="token comment"># padding，表示在图像边缘填充 1 圈 0，防止图像边缘信息学习不充分</span></span>
<span class="line">        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 同理，输入 32个低级特征，输出 64个高级特征，其余参数未变</span></span>
<span class="line">        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化层，降低特征图的尺寸，减少计算量，同时增强特征的鲁棒性</span></span>
<span class="line">        <span class="token comment"># 池化核大小 2*2；步长（stride）为 2，表示池化核每次移动 2个像素；不填充像素</span></span>
<span class="line">        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 全连接层 1，将 3136 维特征映射到 128 维空间，学习特征之间的复杂关系</span></span>
<span class="line">        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 全连接层 2，也是输出层，将 128 维特征映射到 10 个类别空间</span></span>
<span class="line">        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 激活函数，引入非线性，是模型能够学习复杂的模式</span></span>
<span class="line">        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># 第一层卷积 + ReLU，输出形状 [batch_size, 32, 28, 28]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化，输出形状 [batch_size, 32, 14, 14]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 第二层卷积 + ReLU，输出形状 [batch_size, 64, 14, 14]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 池化，输出形状 [batch_size, 64, 7, 7]</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># 展平，两层卷积后特征数量为64，两次池化后特征图维度降低为 7*7</span></span>
<span class="line">        <span class="token comment"># 因此输出形状展平后变为 [batch_size, 3136（64 * 7 * 7）]</span></span>
<span class="line">        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">)</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 全连接层</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                 <span class="token comment"># 输出层</span></span>
<span class="line">        <span class="token keyword">return</span> x</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>为什么设置两层卷积？第一层卷积提取低级特征（如边缘、纹理、线条等），第二层卷积在低级特征的基础上，提取更高级的特征（如形状、结构等）。通过多层卷积，模型可以逐步提取更复杂、更抽象的特征，从而提高分类性能。如果不记得，请翻阅《机器学习》中《2-1 神经网络初探》的 4.3 小节。</p><p>Conv2d 和 MaxPool2d 的使用方法已经在注释中说明了，相同类型的处理函数还有 1d 和 3d：</p><ul><li>Conv1d 和 MaxPool1d：用于 1D（1 维）数据，如时间序列、文本</li><li>Conv2d 和 MaxPool2d：用于 2D（2 维）数据，如图像</li><li>Conv3d 和 MaxPool3d：用于 3D（3 维）数据，如视频、医学图像</li></ul><p>其余就是一些小细节的变动：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 实例化模型的名称需要更名为 CNN</span></span>
<span class="line">model <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 训练函数和测试函数中不需要对数据扁平化了，直接发送给 device</span></span>
<span class="line">images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 保存模型的文件名需要修改一下</span></span>
<span class="line">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;mnist_cnn.pth&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>（3）SoftMax 与 CNN 的结果对比</p><p>除了准确度，运算时间我们也大概的计算一下，导入 time 模块，在 epoch 循环训练的前后加入时间记录代码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> time</span>
<span class="line"></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token comment"># training and testing</span></span>
<span class="line"><span class="token comment"># ......</span></span>
<span class="line">end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;xxx 模型5个Epoch的运算时间: </span><span class="token interpolation"><span class="token punctuation">{</span>softmax_time<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从结果可以看到出，卷积神经网络对于手写数字识别问题，准确度要比 SoftMax 高很多，99%的测试正确率。我们的运算时间是 5 轮训练加测试的时间，这个看不出什么。在实际的应用中，只会应用推理而不是训练，只要测试时间和 Softmax 差不多，应用时必定首选 CNN。有兴趣可以自己重写 time 计算，对比一下单次推理时间。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># SoftMax</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.4670</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9108</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3269</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9162</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3106</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9180</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">4</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.3029</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9185</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.2939</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9187</span></span>
<span class="line">Softmax 模型<span class="token number">5</span>个Epoch的运算时间<span class="token punctuation">:</span> <span class="token number">18.785970</span> 秒</span>
<span class="line"></span>
<span class="line"><span class="token comment"># CNN</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.1567</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9859</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0446</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9875</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0314</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9864</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">4</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0228</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9871</span></span>
<span class="line">Epoch <span class="token punctuation">[</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> Loss<span class="token punctuation">:</span> <span class="token number">0.0172</span><span class="token punctuation">,</span> Test Accuracy<span class="token punctuation">:</span> <span class="token number">0.9905</span></span>
<span class="line">CNN 模型<span class="token number">5</span>个Epoch的运算时间<span class="token punctuation">:</span> <span class="token number">61.244848</span> 秒</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-3-补充-其余三种算法" tabindex="-1"><a class="header-anchor" href="#_1-3-补充-其余三种算法"><span>1.3 补充 - 其余三种算法</span></a></h3><p>支持向量机（SVM）、K 近邻算法（KNN）、随机森林这三种算法的实现相对简单，并且都用的 scikit-learn 这个库，所以就放在一起写了。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA</span>
<span class="line"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler</span>
<span class="line"><span class="token keyword">import</span> time</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 加载完整的 MNIST 数据集</span></span>
<span class="line">mnist <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span><span class="token string">&#39;mnist_784&#39;</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">X <span class="token operator">=</span> mnist<span class="token punctuation">.</span>data  <span class="token comment"># 特征</span></span>
<span class="line">y <span class="token operator">=</span> mnist<span class="token punctuation">.</span>target<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>  <span class="token comment"># 标签</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># random_state 随机种子，控制着数据集划分的随机性，每次拆分都按这个拆分，保证了结果的可重复性</span></span>
<span class="line">X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span></span>
<span class="line">    X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> train_size<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># SVM前置工作，标准化数据，和使用 PCA 降维</span></span>
<span class="line">scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">X_train_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span></span>
<span class="line">X_test_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span></span>
<span class="line">X_train_pca <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train_scaled<span class="token punctuation">)</span></span>
<span class="line">X_test_pca <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test_scaled<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># SVM</span></span>
<span class="line">svm_model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">&#39;linear&#39;</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">svm_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_pca<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> svm_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_pca<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;SVM 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># KNN</span></span>
<span class="line"><span class="token comment"># n_neighbors 表示选择三个最邻近进行评分； n_jobs = -1 表示使用所有 CPU 核心</span></span>
<span class="line">knn_model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">knn_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> knn_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;KNN 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 随机森林</span></span>
<span class="line"><span class="token comment"># n_estimators = 10：使用 10 棵树</span></span>
<span class="line">rf_model <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span></span>
<span class="line">start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">rf_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></span>
<span class="line">train_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time</span>
<span class="line">y_pred <span class="token operator">=</span> rf_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></span>
<span class="line">accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;随机森林 准确率: </span><span class="token interpolation"><span class="token punctuation">{</span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, 训练时间: </span><span class="token interpolation"><span class="token punctuation">{</span>train_time<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string"> 秒&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练的时候 SVM 模块遇到了点问题，因为 sklearn 使用的是扁平化数据，一共 28*28 = 784 维，并且它是使用 CPU 进行计算的。一方面数据量大了之后，特征计算成指数级增长，另一个方面就是运算慢，我训练集数据降到 30% 才能正常运行。为了使用全部数据，我采用了 PCA 降维的方法处理。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">SVM 准确率<span class="token punctuation">:</span> <span class="token number">0.9349</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">45.4076</span> 秒</span>
<span class="line">KNN 准确率<span class="token punctuation">:</span> <span class="token number">0.9713</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">0.0592</span> 秒</span>
<span class="line">随机森林准确率<span class="token punctuation">:</span> <span class="token number">0.9458</span><span class="token punctuation">,</span> 训练时间<span class="token punctuation">:</span> <span class="token number">0.5464</span> 秒</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到 KNN 和随机森林的训练时间非常短，准确率虽然比不过 CNN，但是也还不错。</p><p>sklearn 中还有一个 8*8 的小型手写数字识别的数据集，包含 1797 个数据，每张图像展平后是 64 维，这个数据集 SVM 就可以不进行 PCA 降维。 8*8 图像虽然分辨率较低，但仍然有一些应用价值，比如:</p><ul><li>快速原型开发：用于验证模型的基本功能；或者在计算资源有限的环境中测试模型。</li><li>嵌入式设备：单片机、嵌入式摄像头……</li><li>数据增强：作为高分辨率图像的缩略图，用于数据增强或快速筛选。</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 加载 8*8 的小型 MNIST 数据集</span></span>
<span class="line">digits <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_digits<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">X <span class="token operator">=</span> digits<span class="token punctuation">.</span>data  <span class="token comment"># 特征</span></span>
<span class="line">y <span class="token operator">=</span> digits<span class="token punctuation">.</span>target  <span class="token comment"># 标签</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-实战测验" tabindex="-1"><a class="header-anchor" href="#_2-实战测验"><span>2. 实战测验</span></a></h2><p>实践是检验真理的唯一标准。</p><h3 id="_2-1-ai-模型练习平台" tabindex="-1"><a class="header-anchor" href="#_2-1-ai-模型练习平台"><span>2.1 AI 模型练习平台</span></a></h3><p>AI 模型的练习和比赛，同样也有类似 Leetcode（算法） 或 CTF（网络攻防） 这种专门的平台。从使用人数、科研应用、就业机会三个方面，我挑选了 5 个最常用的机器学习平台。</p><ol><li><p>Kaggle：全球最大的机器学习竞赛平台，提供各种真实数据集，适用于各个领域的科研实践。需要数据科学和机器学习公司在招聘时，都会关注求职者在 Kaggle 上的成绩。</p></li><li><p>DrivenData：相较于 Kaggle 较小，主要集中在解决社会问题，如健康、教育等领域。</p></li><li><p>AI Challenger：在国内较为出名，尤其是在中文 NLP 和语音识别等方面有较强的影响力。国内公司（百度、阿里、腾讯等）会比较关注优胜者，相关比赛成绩有助于就业。</p></li><li><p>Zindi：用户社群相对活跃，特别是在非洲。Zindi 提供与全球社会和企业相关的多种挑战，特别适合需要解决大规模数据问题的科研人员。</p></li><li><p>Hackerearth：使用人数相对较多，尤其是在印度等地有广泛的影响力。提供了多种 机器学习 和 数据科学 相关的挑战，适合研究人员提升实际应用能力。</p></li></ol><h3 id="_2-2-经典分类问题" tabindex="-1"><a class="header-anchor" href="#_2-2-经典分类问题"><span>2.2 经典分类问题</span></a></h3><p><strong>1. 二分类问题：肿瘤分类（Breast Cancer Dataset）</strong></p>`,43)),s("p",null,[n[17]||(n[17]=a("目标：判断乳腺肿瘤是良性还是恶性。数据来源：",-1)),s("a",I,[n[16]||(n[16]=a("UCI ML Repository - Breast Cancer Wisconsin (Diagnostic)",-1)),e(p)])]),n[33]||(n[33]=s("p",null,"该数据集包含 30 个特征，如肿瘤的大小、形状、纹理等，用于判断肿瘤的类型。属于医疗领域（医学图像处理）的经典案例。难度指数 2 颗星。",-1)),n[34]||(n[34]=s("p",null,[s("strong",null,"2. 二分类问题：泰坦尼克号幸存者预测")],-1)),s("p",null,[n[19]||(n[19]=a("目标：构建一个预测模型，回答“什么样的人更有可能生存”这个问题。数据来源：",-1)),s("a",A,[n[18]||(n[18]=a("Kaggle - Titanic",-1)),e(p)])]),n[35]||(n[35]=s("p",null,"该问题是 Kaggle 中的一个长期公开的挑战练习题：虽然生存下来有一些运气因素，但似乎某些群体比其他人更有可能生存下来。该数据集包含各种关于乘客的特征，比如年龄、性别、票价、船舱等信息。难度指数 3 颗星。",-1)),n[36]||(n[36]=s("p",null,[s("strong",null,"3. 多分类问题：鸢尾花分类（Iris Dataset）")],-1)),s("p",null,[n[21]||(n[21]=a("目标：区分三种不同类型的鸢尾花（Setosa、Versicolor 和 Virginica）。数据来源：",-1)),s("a",j,[n[20]||(n[20]=a("UCI ML Repository - Iris",-1)),e(p)]),n[22]||(n[22]=a("。该数据集包含四个特征，比手写数字识别更适合多分类问题的入门。难度指数 1 颗星。",-1))]),n[37]||(n[37]=s("p",null,[s("strong",null,"4. 多分类问题：猫狗图像区分（Dogs vs Cats）")],-1)),n[38]||(n[38]=s("p",null,"简单来看，是个二分问题，区分猫和狗；复杂来看，可以扩展到多分类问题，区分猫和狗，并且区分猫的品种和狗的品种。适合用卷积神经网络等深度学习模型来练手。",-1)),s("p",null,[n[25]||(n[25]=a("数据来源：",-1)),s("a",D,[n[23]||(n[23]=a("Kaggle - Dogs vs. Cats",-1)),e(p)]),n[26]||(n[26]=a("。难度指数 3 颗星。前面的链接是比赛链接，该比赛已经结束且并未公开，但是可以从 Kaggle 的数据集仓库中找到相关数据集：",-1)),s("a",X,[n[24]||(n[24]=a("Kaggle - Cat and Dog",-1)),e(p)]),n[27]||(n[27]=a("。",-1))]),n[39]||(n[39]=s("p",null,[s("strong",null,"5. 多标签分类问题：情感分析（Sentiment Analysis）")],-1)),n[40]||(n[40]=s("p",null,"情感分析是一个典型的“多标签分类”问题，通常对文本进行情感分类，如正面、负面、中性等标签。数据集包含一系列社交媒体评论、产品评价等文本，每个文本可能有多个情感标签（例如“正面”和“中性”）。",-1)),s("p",null,[n[29]||(n[29]=a("数据来源：",-1)),s("a",q,[n[28]||(n[28]=a("Kaggle - Sentiment140 dataset with 1.6 million tweets",-1)),e(p)]),n[30]||(n[30]=a("。难度指数 4 颗星。",-1))]),n[41]||(n[41]=t('<h3 id="_2-3-参考答案" tabindex="-1"><a class="header-anchor" href="#_2-3-参考答案"><span>2.3 参考答案</span></a></h3><p>我并不知道我写的是否就是当前最佳的解决方案，也许有比我更好的方法，希望各位跑完自己的代码，和我的代码以及网络博客中大佬们的代码，相互做做比较。取其精华，去其糟粕。</p><table><thead><tr><th>任务</th><th>SVM</th><th>KNN</th><th>Random Forest</th><th>Softmax</th><th>CNN</th></tr></thead><tbody><tr><td>肿瘤分类</td><td><mark>✓</mark></td><td>✓</td><td><mark>✓</mark></td><td>✗</td><td>✗</td></tr><tr><td>鸢尾花分类</td><td>✓</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td>✗</td></tr><tr><td>幸存者预测</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td>✗</td><td>✗</td></tr><tr><td>猫狗分类</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td><td><mark>✓</mark></td></tr><tr><td>情感分析</td><td>✓</td><td>✓</td><td>✓</td><td><mark>✓</mark></td><td><mark>✓</mark></td></tr></tbody></table><p>❌ 号表示不合适，✅ 号表示可以做，标黄的 ✅ 号表示推荐方法。请翻阅下一章《实战 1-参考答案》</p>',4))])}const V=c(u,[["render",P]]),B=JSON.parse('{"path":"/blogs/intelligence/PyTorch/02_project1.html","title":"实战1-离散分类问题","lang":"en-US","frontmatter":{"title":"实战1-离散分类问题","order":2,"author":"AOSAI","date":"2025-02-23T00:00:00.000Z","category":["PyTorch"],"tag":["PyTorch实战","逻辑回归","分类问题","监督学习"]},"headers":[{"level":2,"title":"1. 实战练习","slug":"_1-实战练习","link":"#_1-实战练习","children":[{"level":3,"title":"1.1 数据集的使用","slug":"_1-1-数据集的使用","link":"#_1-1-数据集的使用","children":[]},{"level":3,"title":"1.2 数学题的解法","slug":"_1-2-数学题的解法","link":"#_1-2-数学题的解法","children":[]},{"level":3,"title":"1.3 补充 - 其余三种算法","slug":"_1-3-补充-其余三种算法","link":"#_1-3-补充-其余三种算法","children":[]}]},{"level":2,"title":"2. 实战测验","slug":"_2-实战测验","link":"#_2-实战测验","children":[{"level":3,"title":"2.1 AI 模型练习平台","slug":"_2-1-ai-模型练习平台","link":"#_2-1-ai-模型练习平台","children":[]},{"level":3,"title":"2.2 经典分类问题","slug":"_2-2-经典分类问题","link":"#_2-2-经典分类问题","children":[]},{"level":3,"title":"2.3 参考答案","slug":"_2-3-参考答案","link":"#_2-3-参考答案","children":[]}]}],"git":{},"filePathRelative":"blogs/intelligence/PyTorch/02_project1.md"}');export{V as comp,B as data};
