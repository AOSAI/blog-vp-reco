import{_ as o,c as l,a as t,b as s,d as n,e,r as h,o as p}from"./app-knK7nh4Q.js";const g="/blog-vp-reco/machinelearning/five/11-01.png",d="/blog-vp-reco/machinelearning/five/11-02.png",i="/blog-vp-reco/machinelearning/five/11-03.png",r="/blog-vp-reco/machinelearning/five/11-04.png",y="/blog-vp-reco/machinelearning/five/11-05.png",u="/blog-vp-reco/machinelearning/five/11-06.png",v="/blog-vp-reco/machinelearning/five/11-07.png",b="/blog-vp-reco/machinelearning/five/11-08.png",x="/blog-vp-reco/machinelearning/five/11-09.png",w="/blog-vp-reco/machinelearning/five/11-10.png",f="/blog-vp-reco/machinelearning/five/11-11.png",c="/blog-vp-reco/machinelearning/five/11-12.png",_="/blog-vp-reco/machinelearning/five/11-13.png",k="/blog-vp-reco/machinelearning/five/11-14.png",z="/blog-vp-reco/machinelearning/five/11-15.png",R="/blog-vp-reco/machinelearning/five/11-16.png",M="/blog-vp-reco/machinelearning/five/11-17.png",Q="/blog-vp-reco/machinelearning/five/11-18.png",L={},q={href:"http://heli.stanford.edu",target:"_blank",rel:"noopener noreferrer"},E={href:"/machinelearning/five/utils.py",target:"_blank",rel:"noopener noreferrer"},T={class:"katex"},S={class:"katex-html","aria-hidden":"true"},B={class:"base"},N={class:"mord accent"},D={class:"vlist-t"},P={class:"vlist-r"},A={class:"vlist",style:{height:"0.714em"}},G={style:{top:"-3em"}},V={class:"accent-body",style:{left:"-0.2077em"}},j={class:"overlay",style:{height:"0.714em",width:"0.471em"}},I={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},H={class:"katex"},O={class:"katex-html","aria-hidden":"true"},Y={class:"base"},C={class:"mord accent"},J={class:"vlist-t"},U={class:"vlist-r"},Z={class:"vlist",style:{height:"0.714em"}},F={style:{top:"-3em"}},K={class:"accent-body",style:{left:"-0.2077em"}},W={class:"overlay",style:{height:"0.714em",width:"0.471em"}},X={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"};function $(ss,a){const m=h("ExternalLinkIcon");return p(),l("div",null,[a[20]||(a[20]=t('<p>强化学习（Reinforcement Learning）</p><h2 id="_1-强化学习概述" tabindex="-1"><a class="header-anchor" href="#_1-强化学习概述"><span>1. 强化学习概述</span></a></h2><p>在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 <strong>贪心、动态规划、分治、回溯</strong> 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。</p><p>我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他遥感直升机一样，它配备了机载计算机、GPS、加速度计、陀螺仪和磁罗盘，因此它可以随时非常准确的知道自己的位置。</p><div class="layout"><figure><img src="'+g+'" alt="11.1 强化学习-遥感直升机1" width="360" tabindex="0" loading="lazy"><figcaption>11.1 强化学习-遥感直升机1</figcaption></figure><figure><img src="'+d+'" alt="11.2 强化学习-遥感直升机2" width="360" tabindex="0" loading="lazy"><figcaption>11.2 强化学习-遥感直升机2</figcaption></figure></div><p>遥感直升机的正常操作，就像 90 年代用手柄打卡带游戏一样，通过操作两个摇杆，以及不同的功能按钮，保持直升机在空中的平衡和飞行。</p>',6)),s("p",null,[a[1]||(a[1]=n("图 11.2 是吴恩达教授驾驶摇杆直升机的图像，仔细观察会发现，这个直升机它在倒着飞，有点像空中杂技。没错，它就是用强化学习做到的。如果你有兴趣看更多的视频，可以 ",-1)),s("a",q,[a[0]||(a[0]=n("点击此处",-1)),e(m)]),a[2]||(a[2]=n("。",-1))]),a[21]||(a[21]=t('<p>那么问题来了，如果给你一架摇杆直升机的密钥，让你来编写一个程序去自主驾驶它，你会怎么做？</p><h3 id="_1-1-什么是强化学习" tabindex="-1"><a class="header-anchor" href="#_1-1-什么是强化学习"><span>1.1 什么是强化学习</span></a></h3><p>假设我们给定一个任务：通过直升机的位置来决定如何移动驾驶杆。</p><p>我们将直升机的位置、方向、速度等称为状态 s。目标任务是找到一个函数，将直升机的状态映射到动作 a，即将两个操作杆推多远，以保证直升机在空中飞行时保持平衡不会坠毁。</p><p>这个任务也许能通过监督学习完成。比如我们有大量的状态观察结果，并且有一位专业的人类飞行员告诉我们应该采取的最佳行动是什么。然后你就可以使用监督学习训练神经网络，以直接学习 x（s）到标签 y（动作 a）的映射。</p><p>但事实证明，当直升机在空中移动时，“应该采取什么正确的行动”这个问题是很模糊的。比如向左倾斜时是一点还是很大？或者增加直升机压力是稍微还是很多？得到 x 和理想动作 y 的数据集是非常困难的。</p><p>这就是为什么对于很多控制机器人的任务，监督学习方法效果不佳，从而改为使用强化学习。<strong>强化学习的一个关键输入，叫做奖励（函数），它会告诉算法什么时候做的好，什么时候做的不好。</strong></p><p>对于奖励函数，在吴恩达教授看来就像是训练小狗。如何让小狗表现良好呢？你不能向小狗展示太多东西，相反，你只是让它做自己的事情，如果做的好，就鼓励夸夸，如果做了坏事，就凶它骂它。然后希望它自己学习如何做更多好的事情，做更少坏的事情。</p><p>强化学习算法也是这样，做的好的时候夸你，做的不好的时候骂你。比如直升机飞的好的时候，奖励它多飞 1 秒（+1）；飞的不好的时候，给一个负奖励，少飞 1 秒（-1）；如果坠毁，给一个非常大的负奖励，比如（-1000）。</p><h3 id="_1-2-形式-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-2-形式-火星探测器"><span>1.2 形式（火星探测器）</span></a></h3><figure><img src="'+i+'" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>在这个简化的例子中，探测器有 6 个可能会移动的位置（状态）。假设探测器一开始在状态 4，它可以去不同的地方用它的传感器（探头、雷达、光谱仪等等）来分析火星上不同地方的岩石，或者拍摄有趣的照片供科学家们观看。</p><p>状态 1 和状态 6 都有非常有趣的地质结构，科学家们希望探测器对其采样，但状态 1 的有趣程度为 100 分，状态 6 的有趣程度为 40 分。其余的状态奖励为 0。</p><p>在每一步的决策中，探测器都可以选择向左走或者向右走。我们可以模拟几种情况来做说明：</p><ul><li>一直往左走，奖励为 [0, 0, 0, 100]</li><li>一直往右走，奖励为 [0, 0, 40]</li><li>先往右走一次，再往左走，奖励为 [0, 0, 0, 0, 0, 100]</li></ul><p>第三种情况很明显不太好，但是它也有可能会发生。</p><p>总而言之，每一个阶段，探测机器人都会处于某种状态（称为 s），它可以选择一个动作（称为 a），并且它还有一些从状态中获得的奖励（称为 R(s)），以及因为动作而产生的新的状态（称为 s&#39;）。</p><p>强化学习的核心要素就是这四件事：<strong>状态、动作、奖励、下一个状态</strong>，记录为：（s, a, R(s), s&#39;）。比如探测器从状态 4 往左走一次：（4, left, 0, 3）。</p><p>对于这个应用程序，假设它进入状态 1 或 6 时，这一天就结束了。这种情况在强化学习中被称为<strong>终端状态</strong>，意味着一旦到达终端状态之一后，获得奖励后就结束后续的动作。</p><h3 id="_1-3-回报-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-3-回报-火星探测器"><span>1.3 回报（火星探测器）</span></a></h3><p>回报这个概念，是强化学习中如何实施动作，做决策的关键。</p><p>做个有意思的类比：假设你站在分叉路口，往左走 5 分钟可以捡到一张 5 美元的钞票，往右走 30 分钟可以捡到一张 10 美元的钞票，你会往哪里走？</p><p>虽然 10 美元看起来比 5 美元好多了，但是如果要你花 30 分钟去拿那张 10 美元，也许你会觉得没有 5 美元来的更方便。</p><p>所以，在这个例子中，回报的概念抓住了你“更快获得奖励”可能比“需要更长时间才能获得奖励”更有吸引力。</p><p><strong>回报被定义为这些奖励的总和，但其中需要一个叫做“折扣因子（Gamma）”的东西加权。</strong> 还是火星探测器的图例：</p><figure><img src="'+i+'" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>假设折扣因子为 0.9，我们从状态 4 一直向左移动到状态 1，它的回报是：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi><mo>=</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><mo stretchy="false">)</mo><mo>⋅</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>⋅</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><msup><mo stretchy="false">)</mo><mn>3</mn></msup><mo>⋅</mo><mn>100</mn><mo>=</mo><mn>72.9</mn></mrow><annotation encoding="application/x-tex">Return=0+(0.9)\\cdot{0}+(0.9)^{2}\\cdot{0}+(0.9)^{3}\\cdot{100}=72.9 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord"><span class="mord">100</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">72.9</span></span></span></span></span></p><p>我们可以看到，折扣因子 Gamma 是指数型增长，越到后面越小。吴恩达教授的解释很有趣，他说：Gamma 的作用是让强化学习有点不耐烦。这样它就会往奖励越大的、越靠近的状态上靠。</p><p>用符号归纳一下回报的函数，它可以写为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi><mo>=</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo></mrow><annotation encoding="application/x-tex">Return=R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0585em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.313em;"></span><span class="minner">⋯</span></span></span></span></span></p><p>在许多强化学习算法中，折扣因子的选择是非常接近 1 的数字，比如 0.9，0.99，甚至 0.999。但是为了能从另一个角度，更好的理解回报的原理，这里 Gamma 选择了 0.5。</p><figure><img src="'+r+'" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>图中的三行数据，每一行里红色的数字表示回报，黄色的箭头表示在该状态下往哪边走，黑色的数字代表奖励。三种不同的移动模式所带来的回报，差别是很明显的。</p><h3 id="_1-4-决策-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-4-决策-火星探测器"><span>1.4 决策（火星探测器）</span></a></h3><p>如同前几个小节所讲，强化学习中可以采取多种不同的方式，去决定下一个动作该做什么，比如在火星探测器中：</p><ol><li>总是追求更接近的奖励。靠近左边就往左边走，靠近右边就往右边走。</li><li>总是追求更大的奖励。状态 1 奖励最大，所以总是往左走。</li><li>总是追求更小的奖励。总是往右走，虽然看起来不是一个好主意，但也是一种选择。</li><li>往更大的奖励走，除非距离较小的奖励仅一步之遥。状态 234 往左走，状态 5 往右走。</li></ol><figure><img src="'+y+'" alt="11.5 火星探测器3" width="560" tabindex="0" loading="lazy"><figcaption>11.5 火星探测器3</figcaption></figure><p>在强化学习中，我们的目标是提出一个称为 策略 Pi 的函数，将任何状态 s 作为输入并将其映射到它希望我们采取的某个动作 a。比如策略 Pi 选择了第 4 种方式，那么探测机器人就会按照第 4 种方式去移动。</p><p>强化学习的目标是找到一个策略 Pi，告诉你在不同的状态下，采取什么行动可以获得最大化的回报。</p><h3 id="_1-5-回顾总结" tabindex="-1"><a class="header-anchor" href="#_1-5-回顾总结"><span>1.5 回顾总结</span></a></h3><p>我们用 6 种状态的火星探测器示例初步讲解了强化学习的形式，让我们快速回顾一下关键概念，并了解如何将这组概念应用于其他的程序。</p><figure><img src="'+u+'" alt="11.6 回顾小结" width="560" tabindex="0" loading="lazy"><figcaption>11.6 回顾小结</figcaption></figure><p>火星探测器和遥感直升机已经在前面说过了，第三个是国际象棋。假设你想使用强化学习来学习下棋：</p><ul><li><strong>状态</strong>：棋盘上所有棋子的位置（简化版）。</li><li><strong>动作</strong>：游戏中合法的移动。</li><li><strong>奖励</strong>：常见方式为，赢了奖励+1，输了负奖励-1，零奖励可能与游戏有关。</li><li><strong>折扣因子</strong>：国际象棋通常 Gamma 为接近 1 的数字，比如 0.99。</li><li><strong>回报</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}} ...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mord">...</span></span></span></span></li><li><strong>决策</strong>：目标棋子被赋予了一个棋盘位置，使用策略 Pi 选择一个好的动作。</li></ul><p>这种强化学习应用程序的形式实际上有一个名字，叫做：<strong>马尔可夫决策过程（Markov Decision Process，MDP）</strong>。它是指：未来仅取决于当前的状态，而不是取决于到达当前状态之前可能发生的任何事情。</p><h2 id="_2-状态-动作价值函数" tabindex="-1"><a class="header-anchor" href="#_2-状态-动作价值函数"><span>2. 状态-动作价值函数</span></a></h2><p>状态-动作价值函数（State-action value function）的目的是为了寻找当前状态下，回报最大的动作。也就是让回报最大化，它的形式可以写为循环：</p><p>Q(s, a) = Return if you</p><ul><li>start in state s.</li><li>take action a (just once).</li><li>then behave optimally after that.</li></ul><figure><img src="'+r+'" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>这是 1.3 小节中讲回报的图，第一行是火星探测车全向左走，第二行是全向右走。我们将这两行的回报结合起来，对比大小来看，第三行其实就是最大回报的动作决策。</p><p>另外，因为这个函数总是被写作 Q 函数，或者 Q*函数（optimal Q function），所以如果你在很多文献里看到了它们，不要惊讶，它们就表示状态-动作价值函数。</p><h3 id="_2-1-代码示例" tabindex="-1"><a class="header-anchor" href="#_2-1-代码示例"><span>2.1 代码示例</span></a></h3>',54)),s("p",null,[a[4]||(a[4]=n("这是吴恩达教授简化的代码（",-1)),s("a",E,[a[3]||(a[3]=n("utils.py 文件可以从此处打开",-1)),e(m)]),a[5]||(a[5]=n("），他希望我们通过自己修改一些参数，比如更改两边的奖励数值、更改折扣因子的大小等等，看看自动策略会如何根据这些不同的值而变化。",-1))]),a[22]||(a[22]=t(`<p>::: tabs</p><p>@tab 简化版代码</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token keyword">from</span> utils <span class="token keyword">import</span> <span class="token operator">*</span></span>
<span class="line"></span>
<span class="line">num_states <span class="token operator">=</span> <span class="token number">6</span></span>
<span class="line">num_actions <span class="token operator">=</span> <span class="token number">2</span></span>
<span class="line"></span>
<span class="line">terminal_left_reward <span class="token operator">=</span> <span class="token number">100</span></span>
<span class="line">terminal_right_reward <span class="token operator">=</span> <span class="token number">40</span></span>
<span class="line">each_step_reward <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Discount factor</span></span>
<span class="line">gamma <span class="token operator">=</span> <span class="token number">0.5</span></span>
<span class="line"><span class="token comment">#probability of going in the wrong direction</span></span>
<span class="line">misstep_prob <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"></span>
<span class="line">generate_visualization<span class="token punctuation">(</span>terminal_left_reward<span class="token punctuation">,</span> terminal_right_reward<span class="token punctuation">,</span> each_step_reward<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> misstep_prob<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>@tab 运行结果</p><figure><img src="`+v+'" alt="11.7 状态-动作价值函数" width="560" tabindex="0" loading="lazy"><figcaption>11.7 状态-动作价值函数</figcaption></figure><p>:::</p><p>有的同学可能看了运行结果会问，为什么状态 2 和状态 3 向右走的回报，不是 2.5 和 5，反而是 12.5 和 6.25 呢。因为这两个状态向右走的策略是：先往右走一次，然后一直往左走。</p><p>Q 函数的目的是找寻回报最大化的动作，在状态 2 中，12.5 明显比 2.5 大，所以迂回的走法比一直向右走看起来更好，状态 3 同理。</p><p>此外，misstep_prob 这个参数详情，请看 2.3 小节，随机环境。</p><h3 id="_2-2-贝尔曼方程-bellman-equation" tabindex="-1"><a class="header-anchor" href="#_2-2-贝尔曼方程-bellman-equation"><span>2.2 贝尔曼方程（Bellman Equation）</span></a></h3><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">Q(s, a)=R(s)+\\gamma\\cdot{\\max{Q(s&#39;, a&#39;)}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord"><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></span></p><p>贝尔曼方程简单的来说，就是告诉我们，当前状态下该动作的回报，是由（1）当前状态的奖励，也称作即时奖励；（2）折扣因子 × 下一个状态的回报最大的动作；两个部分组成。它其实可以看作是对回报的拆分：</p>',12)),a[23]||(a[23]=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("mrow",null,[s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},"]")])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"γ"),s("mo",null,"⋅"),s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡"),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")])])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"},"\\begin{align} Return &= R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots \\\\ &= R_{1}+\\gamma{[R_{2}+\\gamma{R_{3}}+\\cdots]} \\\\ &= R(s)+\\gamma\\cdot{\\max{Q(s', a')}} \\end{align} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"4.5241em","vertical-align":"-2.0121em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n")])]),s("span",{style:{top:"-3.1479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-1.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯")])]),s("span",{style:{top:"-3.1479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},"]")])])]),s("span",{style:{top:"-1.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"max"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.5121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-3.0121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-1.5121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])])])])])],-1)),a[24]||(a[24]=t('<figure><img src="'+b+'" alt="11.8 贝尔曼方程" width="560" tabindex="0" loading="lazy"><figcaption>11.8 贝尔曼方程</figcaption></figure><p>图 11.8 中举了两个例子，从状态 2 往右走，计算出来 12.5 就是它的最大回报；从状态 4 往左走，12.5 是它的最大回报。</p><h3 id="_2-3-随机环境" tabindex="-1"><a class="header-anchor" href="#_2-3-随机环境"><span>2.3 随机环境</span></a></h3><p>在实践中，由于刮风、偏离航线、车轮打滑等等原因，许多机器人没有办法完全按照你的要求去做，所以结果并不会总是可靠。</p><p>比如，在火星探测器向左行驶的途中，可能会遇见岩石滑坡，或者地面真的很滑，导致它滑向了错误的方向。</p><p>我们可以模拟它出现错误的概率，比如 90%的概率会正常运行，10%的概率会遭遇意外情况。比如：</p><ul><li>从状态 3 向左走，没有出错：[0, 0, 100]</li><li>从状态 3 向左走，在状态 2 时打滑了一次，回到了状态 3：[0, 0, 0, 0, 100]</li></ul><p>我们会发现，加入概率之后啊，回报就不是一个准确的公式，而是无数个公式的集合，我们需要取它的平均值，或者说是期望，来重新测定每个状态，往左或往右走的回报。</p>',8)),a[25]||(a[25]=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"E"),s("mi",null,"x"),s("mi",null,"p"),s("mi",null,"e"),s("mi",null,"c"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"d"),s("mi",{mathvariant:"normal"},"_"),s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"A"),s("mi",null,"v"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"a"),s("mi",null,"g"),s("mi",null,"e"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},")")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"E"),s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},"]")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"},"\\begin{align} Expected\\_Return &= Average(R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots) \\\\ &= E[R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots] \\end{align} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.0482em","vertical-align":"-1.2741em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mord mathnormal"},"ec"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord",style:{"margin-right":"0.02778em"}},"_"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n")])]),s("span",{style:{top:"-2.3859em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"er"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.3859em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},"]")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.7741em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-2.25em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])])])])])],-1)),a[26]||(a[26]=t('<p>可以修改 2.1 小节中代码参数 misstep_prob，做对比观察。同理，对于贝尔曼方程，我们也需要改写为期望的形式。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">Q(s, a) = R(s)+\\gamma\\cdot{E[\\max{Q(s&#39;, a&#39;)}]} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mclose">]</span></span></span></span></span></span></p><h2 id="_3-连续的状态空间" tabindex="-1"><a class="header-anchor" href="#_3-连续的状态空间"><span>3. 连续的状态空间</span></a></h2><p>我们使用的简化版火星探测器，是一组离散的状态，它意味着探测器只可能处于 6 个位置中的一个。</p><p>但事实上，它可以处于大量连续位置中的任何一个。比如，一条横向的 6 公里长的直线，我们以米作为单位，向左或向右走时，[0, 6000]m 以内的任何数字都是有效的。</p><figure><img src="'+x+'" alt="11.9 连续的状态空间" width="560" tabindex="0" loading="lazy"><figcaption>11.9 连续的状态空间</figcaption></figure><p>我们再举一个例子，比如正在行驶的卡车（玩具车），它需要考虑的就不只是一个状态了，比如，前后方向的位置 x，左右方向的位置 y，卡车行驶的方向 θ，以及前后方向的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\\dot{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span>，左右方向的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\\dot{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8623em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>，行驶方向/角度变化的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>o</mi><mi>t</mi><mi>θ</mi></mrow><annotation encoding="application/x-tex">dot{\\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></span>。</p><p>所以卡车的状态将包含由这 6 个符号组成的向量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \\theta, \\dot{x}, \\dot{y}, \\dot{\\theta}]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>，并且这些符号中的任何一个，都可以采用有效范围内的任何值。比如方向/角度的范围为 0 到 360°。</p><h3 id="_3-1-登月器" tabindex="-1"><a class="header-anchor" href="#_3-1-登月器"><span>3.1 登月器</span></a></h3><figure><img src="'+w+'" alt="11.10 登月器" width="560" tabindex="0" loading="lazy"><figcaption>11.10 登月器</figcaption></figure><p>这是一个很有意思的模拟月球着陆的程序，每个时间点你可以有四种操作：</p><ol><li>什么都不做，让惯性和重力将着陆器拉向月球表面。</li><li>启动左侧推进器，将着陆器推向右边移动。</li><li>启动右侧推进器，将着陆器推向左边移动。</li><li>启动底部的主推进器，减缓下降的速度。</li></ol><p>你的任务就是随着时间的推移，不断地选择行动，让着陆器安全的降落在两个黄旗中间的位置。那么它的状态向量都包含些什么呢？</p><ul><li>x 和 y 表示在水平方向和垂直方向的位置</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mtext>和</mtext><mover accent="true"><mi>y</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\\dot{x}和\\dot{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 表示在横轴和纵轴上的移动速度</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 表示着陆器的角度，也就是机身的倾斜程度</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\\dot{\\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9313em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span> 表示倾斜的速度，或者说角速度</li><li>l 和 r 是两个布尔类型的变量，对应：左腿是否着地、右腿是否着地</li></ul><p>它的奖励函数也很有趣，之前的火星探测器，只有两个状态存在奖励，而这次的着陆器有 7 种奖励，并且包括负奖励：</p><figure><img src="'+f+'" alt="11.11 登月器的奖励函数" width="560" tabindex="0" loading="lazy"><figcaption>11.11 登月器的奖励函数</figcaption></figure><ol><li>假设两根黄旗中间有一个垫子，着陆器正在设法降落在上面，我们根据降落途中的飞行情况，给 100~140 的奖励；</li><li>并且有一个额外的奖励，离垫子中心越近，奖励越高，离垫子中心越远，奖励越低；</li><li>如果坠毁，奖励-100；</li><li>软着陆成功，奖励+100；</li><li>每条腿落地，都会奖励+10；</li><li>假设我们鼓励它节省燃料，所以每次启动主引擎（主推进器）时，奖励-0.3；</li><li>每次触发左侧或右侧推进器时，奖励-0.03。</li></ol><p>这是一个中等复杂程度的奖励函数，设计者对真正你想要的行为进行了一些思考，并将其编入奖励函数中，激励更多你想要的行为。</p><p>当你自己构建一个强化学习应用程序时，通常你会花些心思来准确的指定你想要什么，你不想要什么，以及将其编入奖励函数。</p><p>总结一下，着陆器程序的任务是：在给定状态向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>r</mi><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \\dot{x}, \\dot{y}, \\theta, \\dot{\\theta}, l, r]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span> 的情况下，让决策 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> 选择一个最佳的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>π</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a=\\pi(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>，使得回报最大化，折扣因子选定为 Gamma=0.985。</p><h3 id="_3-2-强化学习中的神经网络" tabindex="-1"><a class="header-anchor" href="#_3-2-强化学习中的神经网络"><span>3.2 强化学习中的神经网络</span></a></h3><p>用强化学习来解决登月器或者其它问题的一个关键思想是，我们要训练一个神经网络来计算或近似 state，action 的状态动作价值函数 Q。这反过来又会让我们选择一个好的行动。</p><figure><img src="'+c+'" alt="11.12 强化学习中的神经网络" width="560" tabindex="0" loading="lazy"><figcaption>11.12 强化学习中的神经网络</figcaption></figure><p>神经网络的输入包含了所有的状态和动作，状态向量已经写过了：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>r</mi><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \\dot{x}, \\dot{y}, \\theta, \\dot{\\theta}, l, r]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>；4 个动作我们可以通过 one-hot 进行编码：</p><ul><li>nothing，什么都不做，[1, 0, 0, 0]</li><li>left，启动左侧推进器，[0, 1, 0, 0]</li><li>main，启动主推进器，[0, 0, 1, 0]</li><li>right，启动右侧推进器，[0, 0, 0, 1]</li></ul>',25)),s("p",null,[a[11]||(a[11]=n("所以这个由 12 个数字组成的列表或者说向量（8 个状态，4 个动作），我们将其写作神经网络的输入 ",-1)),s("span",T,[a[10]||(a[10]=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{x}")])])],-1)),s("span",S,[s("span",B,[a[9]||(a[9]=s("span",{class:"strut",style:{height:"0.714em"}},null,-1)),s("span",N,[s("span",D,[s("span",P,[s("span",A,[a[8]||(a[8]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1)),s("span",G,[a[7]||(a[7]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",V,[s("span",j,[(p(),l("svg",I,a[6]||(a[6]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])])])])]),a[12]||(a[12]=n("。",-1))]),a[27]||(a[27]=s("p",null,"需要注意的是，我们并不是输入状态就直接让它输出动作（纯粹的监督学习），而是让它输出 Q 函数。神经网络在这里只是强化学习的一个部分。",-1)),a[28]||(a[28]=s("p",null,"对于 Q 函数而言，这种方式的效果很好。那么到这里，问题就变成了：如何训练一个神经网络来输出 Q(s, a) 函数？",-1)),a[29]||(a[29]=s("h3",{id:"_3-3-构建训练集",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_3-3-构建训练集"},[s("span",null,"3.3 构建训练集")])],-1)),s("p",null,[a[18]||(a[18]=n("首先，该方法将使用贝尔曼方程，来创建包含大量示例（x，y）的训练集，然后使用监督学习中的神经网络做模型训练，将 state-action（",-1)),s("span",H,[a[17]||(a[17]=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{x}")])])],-1)),s("span",O,[s("span",Y,[a[16]||(a[16]=s("span",{class:"strut",style:{height:"0.714em"}},null,-1)),s("span",C,[s("span",J,[s("span",U,[s("span",Z,[a[15]||(a[15]=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1)),s("span",F,[a[14]||(a[14]=s("span",{class:"pstrut",style:{height:"3em"}},null,-1)),s("span",K,[s("span",W,[(p(),l("svg",X,a[13]||(a[13]=[s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1)])))])])])])])])])])])]),a[19]||(a[19]=n("）映射到目标值 Q(s, a)（y）。",-1))]),a[30]||(a[30]=t('<figure><img src="'+_+'" alt="11.13 通过贝尔曼方程构建训练集" width="560" tabindex="0" loading="lazy"><figcaption>11.13 通过贝尔曼方程构建训练集</figcaption></figure><p>我们将贝尔曼方程切分为两个部分，等式左边就是输入向量 x，等式右边就是输出 y。</p><p>问题的关键是，我们并不知道什么才是最佳的 Q 函数，能够将回报最大化的下一个状态和动作是什么我们不清楚。</p><p>没关系，我们可以取随机值，来构建一个，比如包含 1 万个数据的训练集。</p><h3 id="_3-4-deep-q-network-dqn" tabindex="-1"><a class="header-anchor" href="#_3-4-deep-q-network-dqn"><span>3.4 Deep Q-Network（DQN）</span></a></h3><p>通过前面几个小节，我们可以概括出神经网络构建的全过程：</p><p><strong>1. 初始化神经网络，随机的猜测 Q(s, a)。</strong></p><p>这就有点像训练线性回归模型时，随机的初始化所有参数，然后使用梯度下降一步一步完善。所以重要的其实是，算法能不能慢慢的改进参数，以获得更好的估计。</p><p><strong>2. 反复执行以下操作：</strong></p><p>2.1 在着陆期间，执行任何的操作，无论是好的还是坏的，你会获得多个这样的元组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s, a, R(s), s&#39;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>2.2 重放缓冲区（Replay Buffer）：储存最新的 1 万个元组数据。</p><p>2.3 训练神经网络：将这 1 万个元组数据，通过贝尔曼方程构建成数据集。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">maxQ(s&#39;, a&#39;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 最开始是随机初始化的，没关系，通过训练慢慢就会变成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mrow><mo>≈</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">Q_{new}(s, a)=R(s)+\\gamma\\cdot{\\max{Q(s&#39;, a&#39;)}} \\approx{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord"><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span></p><p>2.4 让 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q=Q_{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>我们在反复执行训练神经网路的步骤中，Q(s, a) 是会继承上一次的训练结果的，所以每一次迭代，它都会变成更好的估计。</p><p>所以理论上来讲，只要你迭代的次数够多，训练的时间足够长，这个模拟着陆程序中的 DQN 就会变得足够好。</p><h2 id="_4-算法改进" tabindex="-1"><a class="header-anchor" href="#_4-算法改进"><span>4. 算法改进</span></a></h2><h3 id="_4-1-神经网络架构改进" tabindex="-1"><a class="header-anchor" href="#_4-1-神经网络架构改进"><span>4.1 神经网络架构改进</span></a></h3><figure><img src="'+c+'" alt="11.12 强化学习中的神经网络" width="560" tabindex="0" loading="lazy"><figcaption>11.12 强化学习中的神经网络</figcaption></figure><p>这是原本的神经网络模型，我们需要在每个状态上，分别对四个动作进行推理。也就是一个状态就要运行四次神经网络，或者说每个动作都对应一个神经网络，这是非常低效的。</p><figure><img src="'+k+'" alt="11.14 神经网络架构改进" width="560" tabindex="0" loading="lazy"><figcaption>11.14 神经网络架构改进</figcaption></figure><p>事实证明，在一个神经网络上同时计算并输出四个动作所对应的 Q 函数，效果会比原本的更好。因为通过贝尔曼方程，对比四个动作的回报，一次就可以知道在该状态下，做什么动作是最好的。</p><h3 id="_4-2-ε-贪婪策略-epsilon-greedy-policy" tabindex="-1"><a class="header-anchor" href="#_4-2-ε-贪婪策略-epsilon-greedy-policy"><span>4.2 ε-贪婪策略（Epsilon-greedy policy）</span></a></h3><p>当你处于某些状态时，可能并不想完全随机的采取行动，因为那样通常可能会是一个糟糕的结果。</p><p>我们原本的选项是：（1）选择一个动作 a，尽可能的最大化 Q(s, a)。即使它可能不尽人意，但是算法会尽力的使用我们当前对 Q(s, a)的猜测，并最大化它的收益。</p><p>而现在的选项是：<strong>（1）0.95 的概率，选择一个能最大化 Q(s, a)的动作 a。（2）0.05 的概率，随机选择一个动作 a。</strong></p><p>这么做的原因是，假设在随机初始化 Q(s ,a)的时候，出现了一些不好的情况，比如 Q(s, a)始终都很低，这可能导致该启动主推进器时，一直不启动的类似问题。</p><p>引入一个 0.05 的概率，神经网络可以学会克服自己的先入之见，也许自己之前坚持的才是错的呢？</p><p>这种随机选择动作的想法有时被称为探索步骤（Exploration Step）。还有一个很神奇的地方是，贪婪指的是 0.95 的概率，寻求 Q(s, a)最大化的部分，0.05 的随机探索才是不贪婪的。</p><p>一般来说，ε 的值是从大到小变化的。最初，你可能采取较多的随机行动，因为本身也不知道哪个好，哪个不好；</p><p>随着时间的推移，Q(s, a)迭代很多次后，已经有了很多好的推理，你可能会更倾向于用新的 Q(s, a)来估计和选择行动，所以随机行动就降低了。</p><h3 id="_4-3-超参数的敏感性" tabindex="-1"><a class="header-anchor" href="#_4-3-超参数的敏感性"><span>4.3 超参数的敏感性</span></a></h3><p>在监督学习中，超参数是不那么敏感的，比如，学习率选择的不好，可能也就是会让训练量或者说训练时间翻个两三倍。</p><p>但是强化学习中，超参数是很敏感的，假设你的 ε-贪婪策略中，epsilon 的值选的不够好，训练量可能会翻个 10 倍、100 倍。这非常恐怖。</p><p>吴恩达教授觉得，这可能是因为强化学习算法本身还不够完善导致的。目前，对于一个新项目而言，还需要我们自己试错。</p><h3 id="_4-4-小批量处理-mini-batch" tabindex="-1"><a class="header-anchor" href="#_4-4-小批量处理-mini-batch"><span>4.4 小批量处理（mini-batch）</span></a></h3><p>小批量处理可以加速强化学习和监督学习的训练速度，但是前提是你的训练集真的非常大，我们从监督学习的线性回归说起：</p><figure><img src="'+z+'" alt="11.15 小批量处理1" width="560" tabindex="0" loading="lazy"><figcaption>11.15 小批量处理1</figcaption></figure><p>这是最初的房价预测的线性回归模型，但是假设有 1 亿个训练样本，本来在梯度下降时，更新参数 w 和 b 就要循环迭代很多次，再乘一个 1 亿的样本基数，训练时间会大到难以想想。</p><p><mark>小批量处理要做的事情就是，将其划分为不同的集合，一个集合中 1000 个样本、5000 个样本……<strong>然后在进行成本函数计算时，第一次用集合 1 的样本，第二次用集合 2 的样本，依次类推</strong>。</mark></p><figure><img src="'+R+'" alt="11.16 小批量处理2" width="560" tabindex="0" loading="lazy"><figcaption>11.16 小批量处理2</figcaption></figure><p>一次性处理（Batch learning）的结果是，梯度会直接的向最小的地方前进，但是数据量太大了，计算时间会非常长。</p><p>小批量处理（Mini-Batch learning）的优势在于，计算成本要低得多，所以当数据集很大的时候，它是一个更快的算法。一般会和别的算法一起用，比如 adam。</p><p>缺点也很明显，可能会因为不同集合的样本走歪路，虽然它也会最终趋向于全局最优化，但是它不是很可靠，并且会有噪点。</p><figure><img src="'+M+'" alt="11.17 小批量处理3" width="560" tabindex="0" loading="lazy"><figcaption>11.17 小批量处理3</figcaption></figure><p>回到强化学习中来，我们可以在训练神经网络模型的时候，使用小批量处理，将 1 万个数据，切分成 1000 个数据的不同集合。循环使用不同的集合来训练参数。</p><h3 id="_4-5-软更新" tabindex="-1"><a class="header-anchor" href="#_4-5-软更新"><span>4.5 软更新</span></a></h3><p>软更新可以帮助你的强化学习算法更好的收敛到一个好的解决方案。</p><p>在登月器的最后一步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q=Q_{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中，有一个隐患，假如遇到了像小批量处理时，数据集不好的情况下，新的 Q 值可能会更糟糕。</p><figure><img src="'+Q+'" alt="11.18 软更新" width="560" tabindex="0" loading="lazy"><figcaption>11.18 软更新</figcaption></figure><p>我们可以给新的参数乘一个 0.01，旧的参数乘一个 0.99，这就是软更新，因为我们只会接受一点点的新值，所以出现错误的可能性大大降低，并且收敛性也会变得更佳。</p>',50))])}const ns=o(L,[["render",$]]),ts=JSON.parse('{"path":"/series/MachineLearning/MachineLearning/11_reinforcement_learning.html","title":"3-3 强化学习","lang":"en-US","frontmatter":{"title":"3-3 强化学习","order":11,"author":"AOSAI","date":"2024-08-28T00:00:00.000Z","category":["机器学习"],"tag":["强化学习"]},"headers":[{"level":2,"title":"1. 强化学习概述","slug":"_1-强化学习概述","link":"#_1-强化学习概述","children":[{"level":3,"title":"1.1 什么是强化学习","slug":"_1-1-什么是强化学习","link":"#_1-1-什么是强化学习","children":[]},{"level":3,"title":"1.2 形式（火星探测器）","slug":"_1-2-形式-火星探测器","link":"#_1-2-形式-火星探测器","children":[]},{"level":3,"title":"1.3 回报（火星探测器）","slug":"_1-3-回报-火星探测器","link":"#_1-3-回报-火星探测器","children":[]},{"level":3,"title":"1.4 决策（火星探测器）","slug":"_1-4-决策-火星探测器","link":"#_1-4-决策-火星探测器","children":[]},{"level":3,"title":"1.5 回顾总结","slug":"_1-5-回顾总结","link":"#_1-5-回顾总结","children":[]}]},{"level":2,"title":"2. 状态-动作价值函数","slug":"_2-状态-动作价值函数","link":"#_2-状态-动作价值函数","children":[{"level":3,"title":"2.1 代码示例","slug":"_2-1-代码示例","link":"#_2-1-代码示例","children":[]},{"level":3,"title":"2.2 贝尔曼方程（Bellman Equation）","slug":"_2-2-贝尔曼方程-bellman-equation","link":"#_2-2-贝尔曼方程-bellman-equation","children":[]},{"level":3,"title":"2.3 随机环境","slug":"_2-3-随机环境","link":"#_2-3-随机环境","children":[]}]},{"level":2,"title":"3. 连续的状态空间","slug":"_3-连续的状态空间","link":"#_3-连续的状态空间","children":[{"level":3,"title":"3.1 登月器","slug":"_3-1-登月器","link":"#_3-1-登月器","children":[]},{"level":3,"title":"3.2 强化学习中的神经网络","slug":"_3-2-强化学习中的神经网络","link":"#_3-2-强化学习中的神经网络","children":[]},{"level":3,"title":"3.3 构建训练集","slug":"_3-3-构建训练集","link":"#_3-3-构建训练集","children":[]},{"level":3,"title":"3.4 Deep Q-Network（DQN）","slug":"_3-4-deep-q-network-dqn","link":"#_3-4-deep-q-network-dqn","children":[]}]},{"level":2,"title":"4. 算法改进","slug":"_4-算法改进","link":"#_4-算法改进","children":[{"level":3,"title":"4.1 神经网络架构改进","slug":"_4-1-神经网络架构改进","link":"#_4-1-神经网络架构改进","children":[]},{"level":3,"title":"4.2 ε-贪婪策略（Epsilon-greedy policy）","slug":"_4-2-ε-贪婪策略-epsilon-greedy-policy","link":"#_4-2-ε-贪婪策略-epsilon-greedy-policy","children":[]},{"level":3,"title":"4.3 超参数的敏感性","slug":"_4-3-超参数的敏感性","link":"#_4-3-超参数的敏感性","children":[]},{"level":3,"title":"4.4 小批量处理（mini-batch）","slug":"_4-4-小批量处理-mini-batch","link":"#_4-4-小批量处理-mini-batch","children":[]},{"level":3,"title":"4.5 软更新","slug":"_4-5-软更新","link":"#_4-5-软更新","children":[]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"filePathRelative":"series/MachineLearning/MachineLearning/11_reinforcement_learning.md"}');export{ns as comp,ts as data};
