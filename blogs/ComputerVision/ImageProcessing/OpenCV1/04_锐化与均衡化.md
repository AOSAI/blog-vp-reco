---
title: 04-锐化与均衡化
date: 2025/10/13
categories:
  - OpenCV
tags:
  - 图像处理
  - 图像增强
---

## 1. 锐化

==锐化 (Sharpening)== 是指强化图像的边缘和细节。通过增强高频分量突出边缘，从而**提升图像的清晰度**。常见的应用有：卫星图像增强、工业检测图像、摄影后期增强等等。它是 **空间域** 上的操作，旨在增强亮度在空间上的变化率（梯度）。

### 1.1 非锐化掩模（线性）

==非锐化掩模（Unsharp Masking，USM）== 这个名字也许听起来比较矛盾，你又要锐化，又用非锐化的掩膜，这是在干嘛？别着急，它的思想很有意思，它不是直接对边缘进行操作，而是用一种间接的、非常巧妙的方法，反其道而行之：

1. 使用模糊滤波器（比如高斯模糊）将图像模糊化。
2. 用原始图像减去模糊图像，就得到了图像中缺失的“细节”和“边缘”信息，称之为 “掩膜”图像。
3. 将“掩膜”图像乘以一个增益系数 K，然后将结果加回原始图像中，边缘信息就得到了增强。

是不是很有意思？它的 **掩膜图像** 是通过两个非锐化的图像相减得到的，所以叫做**非锐化掩膜**。我们将这三个步骤合并，可以得到一个完整的公式（f 代表原始图像，$\bar{f}$ 表示模糊图像，k 表示增益系数）：

$$
g(x,y)=f(x,y)+k\cdot{(f(x,y)-\bar{f}(x,y))}=(1+k)f-k\bar{f}
$$

在实践之前，我们先回忆一下高斯滤波器的内容。窗口大小和标准差一般是对应的，经验公式为 $kernel\_size\approx{6\sigma +1}$。也就是说标准差为 1 时，核大小约为 7，标准差为 1.5 时，核大小约为 10，因为要用奇数核，所以 1.5 对应 (9, 9)。

对不对应问题其实不大，==cv2.GaussianBlur()== 函数内部会自动匹配标准差，窗口大小只是截断，所以不怎么影响效果。那么标准差是怎么影响锐化效果的呢？

| 参数变化         | 结果变化                             | 适用场景                     |
| ---------------- | ------------------------------------ | ---------------------------- |
| 小 σ (0.5~1.0)   | 细节增强明显，容易出现噪声或纹理过锐 | 人脸、精细纹理               |
| 中等 σ (1.0~2.0) | 边缘清晰但不过度，最常用范围         | 风景、建筑、通用图像         |
| 大 σ (3.0~5.0)   | 模糊范围大，强化大尺度轮廓，丢失细节 | 大面积对比度调整、艺术风格化 |

这个参数范围其实用在 K 值上也是有效的，但一般都在 [0, 2] 之间。0 的话就是原图，自然图像和人像推荐在 [0.3, 1.2] 之间，风景/建筑/文档 推荐在 [1.0, 2.0] 之间。好了，写一写代码：

:::: code-group
::: code-group-item 基本写法

```py
import cv2
import matplotlib.pyplot as plt

def show_img_by_plt(img, title, pos):
    ax = plt.subplot(1, 3, pos)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def simple_unsharp_mask(image, kernel_size=(5,5), sigma=1.0, k=1.0):
    blurred = cv2.GaussianBlur(image, kernel_size, sigma)
    # 公式: (1+k)*original - k*blurred
    sharpened = cv2.addWeighted(image, 1.0 + k, blurred, -k, 0)
    return sharpened

if __name__ == "__main__":
    img = cv2.imread('01_luna.png')
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    sharpened_img1 = simple_unsharp_mask(img_rgb, kernel_size=(5,5), sigma=1.0, k=1.0)
    sharpened_img2 = simple_unsharp_mask(img_rgb, kernel_size=(5,5), sigma=1.0, k=5.0)

    plt.figure(figsize=(14, 8))
    show_img_by_plt(img_rgb, "Orignal Image", 1)
    show_img_by_plt(sharpened_img1, "Unsharp Masking k=1", 2)
    show_img_by_plt(sharpened_img2, "Unsharp Masking k=5", 3)
    plt.show()
```

:::
::: code-group-item 扩展：手动实现，并增加锐化阈值

```py
def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):
    """
    image: 输入图像
    kernel_size: 高斯模糊核的大小，必须是正奇数，例如 (5,5)
    sigma: 高斯核的标准差
    amount: 锐化强度（对应增益系数）
    threshold: 锐化阈值，仅对差异大于该值的像素进行锐化
    """
    # 步骤1：创建模糊版本（使用高斯模糊）
    blurred = cv2.GaussianBlur(image, kernel_size, sigma)

    # 步骤2：创建掩模（原始图像 - 模糊图像）
    # 为了避免负数，我们使用有符号整数或浮点数计算
    if image.dtype == np.uint8:
        image_float = image.astype(np.float32)
        blurred_float = blurred.astype(np.float32)
    else:
        image_float = image
        blurred_float = blurred

    mask = cv2.subtract(image_float, blurred_float)

    # 步骤3：增强和叠加（根据阈值条件）
    # 创建一个条件矩阵，决定哪些像素需要锐化
    if threshold > 0:
        # 计算掩模的绝对值，判断是否超过阈值
        low_contrast_mask = np.abs(mask) < threshold
        # 对于低对比度区域，不进行增强（amount=0）
        sharpened = np.where(low_contrast_mask, image_float, image_float + amount * mask)
    else:
        # 如果没有阈值，对所有区域进行增强
        sharpened = image_float + amount * mask

    # 确保值在合法范围内并转换回原数据类型
    if image.dtype == np.uint8:
        sharpened = np.clip(sharpened, 0, 255)
    else:
        sharpened = np.clip(sharpened, 0, 1.0) # 对于浮点图像，假设范围是[0,1]

    return sharpened.astype(np.uint8)
```

:::
::::

为了让对比更明显，我设置了 k=1 和 k=5。从结果看，第二张已经能看出来有一些锐化的效果了，第三张图虽然锐化的超级明显，但是放大了看，出现了很多的噪点。

![1.1 不同 k 值的非锐化掩膜](/cv/ImageProcessing/04_xxx/10_unsharp_mask1.png)

最后补充说明一下 ==cv2.addWeighted()== 函数。它是 OpenCV 里最常用、最实用的图像算术函数之一，不仅用于图像混合，也经常被用来实现锐化、对比度增强、HDR 合成等操作。它的公式写作：

$$
dst(x,y)=src1(x,y)\cdot{\alpha}+src2(x,y)\cdot{\beta}+\gamma
$$

```py
dst = cv2.addWeighted(src1, alpha, src2, beta, gamma)

# 公式: (1+k)*original - k*blurred
sharpened = cv2.addWeighted(image, 1.0 + k, blurred, -k, 0)
```

### 1.2 锐化卷积核（线性）

对于锐化，我们还可以通过特定的卷积核，配合 ==cv2.filter2D()== 函数实现。锐化卷积核它也不是凭空出现的，而是通过 USM 的思想，以及它的公式推导出来的。假设我们有一个 3x3 的均值模糊核 M，均值模糊就是一个卷积操作，可以写为 $\bar{f}=f\cdot{M}$。带入到 USM 的公式里：

$$
g=(1+k)f-(k\cdot{M})f=((1+k)-(k\cdot{M}))f \\[1em]
K_{shape}=(1+k)I-k\cdot{M}
$$

$K_{shape}$ 就是我们要求的 **锐化卷积核**。一个“单位核”与原图卷积会得到原图本身。单位核（Identity Kernel）在 3x3 情况下，就是中心为 1，周围为 0 的核。均值核就不多说了。

- **单位核 I**: [[0,0,0], [0,1,0], [0,0,0]]
- **均值核 M**: [[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]]

我们取一个经典的强度 k = 1 来计算锐化卷积核：

$$
K_{shape}=2I-M=
\begin{bmatrix}
-\frac{1}{9} & -\frac{1}{9} & -\frac{1}{9} \\[0.8em]
-\frac{1}{9} & \frac{17}{9} & -\frac{1}{9} \\[0.8em]
-\frac{1}{9} & -\frac{1}{9} & -\frac{1}{9}
\end{bmatrix}=
\frac{1}{9}\begin{bmatrix}
-1 & -1 & -1 \\[0.8em]
-1 & 17 & -1 \\[0.8em]
-1 & -1 & -1
\end{bmatrix}
$$

OK，截止目前，我们已经得到了一个非常具体的锐化核。虽然它不像后面提到的那些核那样“标准”，但它完美地诠释了从 USM 到卷积核的推导过程。

基于上述原理，人们设计出了多种多样的锐化核，它们在强度和特性上略有不同。==标准锐化核 (Common Sharpening Kernel)== 是最常见的一个，它强化了中心像素，同时轻微削弱周围像素：

$$
\text{标准锐化核}=
\begin{bmatrix} 0 & -1 & 0 \\[0.5em] -1 & 5 & -1 \\[0.5em] 0 & -1 & 0 \end{bmatrix}
$$

如果觉得标准锐化不够，可以继续增加中心权重，甚至更极端一点。这些核的周围负值权重更大，意味着在增强中心的同时，对周围的抑制更强，从而产生更强烈的边缘对比，但也更容易产生“过冲”光晕。

$$
\text{强锐化核}=
\begin{bmatrix} 0 & -2 & 0 \\[0.5em] -2 & 9 & -2 \\[0.5em] 0 & -2 & 0 \end{bmatrix} \quad
\text{极端锐化核}=
\begin{bmatrix} -1 & -1 & -1 \\[0.5em] -1 & 9 & -1 \\[0.5em] -1 & -1 & -1 \end{bmatrix}
$$

### 1.3 拉普拉斯算子（线性）

==拉普拉斯算子 (Laplacian Operator)== 是卷积锐化中非常重要和特殊的一员。它的核心思想是，从一阶到二阶微分：

- **一阶微分（梯度）**：测量的是图像亮度变化的速率（斜率）。在边缘处会产生一个峰值。
- **二阶微分（拉普拉斯）**：测量的是图像亮度变化速率的变化速率（曲率）。在边缘处会产生一个**过零点**（从正到负或从负到正的跨越），同时在边缘两侧分别产生一个正峰和一个负谷。

![1.2 拉普拉斯算子 - 数学上的直观理解](/cv/ImageProcessing/04_xxx/12_Laplacian2.png)

这个**特性**让拉普拉斯算子对边缘非常敏感，并且是各向同性的 --> 对任意方向的边缘都有相同的响应。并且强调细节，对细线和孤立点特别敏感；简单高效，只需一个卷积操作就能完成。

但它也有**缺点**：对噪声敏感，会同时增强图像中的噪声；产生双边缘，在边缘两侧都会产生响应；可能过度锐化，强度参数设置过高会产生不自然的光晕效应。

在二维图像中，拉普拉斯算子定义为：

$$
\triangledown^{2}f=\frac{\partial^{2}f}{\partial{x^{2}}}+\frac{\partial^{2}f}{\partial{y^{2}}}
$$

我们需要将像素点离散化才能用于数字图像。通过对二阶偏导进行近似，我们得到最常见的拉普拉斯卷积核：==4-邻域拉普拉斯核（不考虑对角线）==、==8-邻域拉普拉斯核（考虑对角线）==。

$$
\text{4-邻域}=
\begin{bmatrix} 0 & 1 & 0 \\[0.5em] 1 & -4 & 1 \\[0.5em] 0 & 1 & 0 \end{bmatrix} \quad
\text{8-邻域}=
\begin{bmatrix} 1 & 1 & 1 \\[0.5em] 1 & -8 & 1 \\[0.5em] 1 & 1 & 1 \end{bmatrix}
$$

拉普拉斯算子提取的是图像的高频成分，$\triangledown^{2}f$ 就表示边缘信息，再根据 USM 的思想，我们可以推导出**拉普拉斯的锐化公式**：

$$
g=f+k\cdot{\text{高频细节}}=f-(k\cdot{\triangledown^{2}f})
$$

注意这里是减号，因为拉普拉斯核的中心是负值，$\triangledown^{2}f$ 计算出的结果在边缘处是负响应，我们需要减去这个"模糊量"。拉普拉斯核 与 锐化核 在公式上看其实是有一些联系的，以 4-邻域拉普拉斯为例：**当 k = -1 时，标准锐化核 = 单位核 - k × 拉普拉斯核**。

==cv2.filter2D()== 函数是实现卷积锐化的通用方法，很灵活，可以自定义核。==cv2.Laplacian()== 虽然是 OpenCV 给的拉普拉斯算子接口，但它返回的是拉普拉斯算子的计算结果，而不是锐化后的图像，需要手动完成锐化。我们将这两种方式都做一个实现：

:::: code-group
::: code-group-item Laplacian 专用写法

```py
import cv2
import numpy as np
import matplotlib.pyplot as plt

def show_img_by_plt(img, title, pos):
    ax = plt.subplot(1, 3, pos)
    plt.imshow(img, cmap="gray")
    plt.title(title)
    plt.axis('off')

def laplacian_sharpen_cv2(image, ksize=1, k=1.0):
    laplacian = cv2.Laplacian(image, cv2.CV_32F, ksize=ksize)  # 浮点数保留负值
    sharpened = image.astype(np.float32) - k * laplacian  # 应用锐化公式
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)  # 转换回uint8
    return sharpened, laplacian

img = cv2.imread('01_luna.png', cv2.IMREAD_GRAYSCALE)

if img is not None:
    # 使用 OpenCV 的 Laplacian 函数
    sharpened_img, laplacian_result = laplacian_sharpen_cv2(img, ksize=3, k=0.8)

    plt.figure(figsize=(14, 8))
    show_img_by_plt(img, "Original Image", 1)
    # uint8 无法表示负数，而 laplacian_result 既有正值也有负值，所以需要取绝对值来显示
    show_img_by_plt(cv2.convertScaleAbs(laplacian_result), "Laplacian Result", 2)
    show_img_by_plt(sharpened_img, "Sharpened (cv2.Laplacian)", 3)
    plt.show()
```

:::
::: code-group-item filter2D 通用写法

```py
import cv2
import numpy as np
import matplotlib.pyplot as plt

def show_img_by_plt(img, title, pos):
    ax = plt.subplot(1, 3, pos)
    plt.imshow(img, cmap="gray")
    plt.title(title)
    plt.axis('off')

def laplacian_sharpen(image, k=1.0):
    # 4-邻域拉普拉斯核
    laplacian_kernel = np.array([[0,  1, 0],
                                 [1, -4, 1],
                                 [0,  1, 0]], dtype=np.float32)

    # 先计算拉普拉斯二阶导数，后计算拉普拉斯锐化
    laplacian = cv2.filter2D(image.astype(np.float32), -1, laplacian_kernel)
    sharpened = image.astype(np.float32) - k * laplacian

    return sharpened.astype(np.uint8), laplacian

# 使用示例
if __name__ == "__main__":
    img = cv2.imread('01_luna.png', cv2.IMREAD_GRAYSCALE)  # 读取灰度图像
    sharpened_img, laplacian_result = laplacian_sharpen(img, k=1.0)

    plt.figure(figsize=(14, 8))
    show_img_by_plt(img, "Original Image", 1)
    # uint8 无法表示负数，而 laplacian_result 既有正值也有负值，所以需要取绝对值来显示
    show_img_by_plt(cv2.convertScaleAbs(laplacian_result), "Laplacian Result", 2)
    show_img_by_plt(sharpened_img, "Sharpened (cv2.Laplacian)", 3)
    plt.show()
```

:::
::: code-group-item 扩展：数学上的直观理解

```py
import numpy as np
import matplotlib.pyplot as plt

# 创建一个简单的一维边缘信号来演示
def demonstrate_1d_edge():
    # 设置支持中文的字体, 用来正常显示中文标签
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

    # 创建平滑的边缘信号（类似于真实图像中的边缘）
    x = np.linspace(0, 10, 100)
    edge_signal = 1 / (1 + np.exp(-(x - 5)))  # sigmoid函数

    first_deriv = np.gradient(edge_signal)  # 计算一阶导数
    second_deriv = np.gradient(first_deriv)  # 计算二阶导数

    # 绘制结果
    plt.figure(figsize=(12, 8))

    # 原始信号
    plt.subplot(1, 3, 1)
    plt.plot(x, edge_signal, 'b-', linewidth=3)
    plt.title('原始边缘信号')
    plt.ylabel('亮度')
    plt.grid(True)

    # 一阶导数（梯度）
    plt.subplot(1, 3, 2)
    plt.plot(x, first_deriv, 'r-', linewidth=3)
    plt.axvline(x=5, color='gray', linestyle='--', alpha=0.5)
    plt.title('一阶微分（梯度）- 在边缘中心产生峰值')
    plt.ylabel('梯度值')
    plt.grid(True)

    # 二阶导数（拉普拉斯）
    plt.subplot(1, 3, 3)
    plt.plot(x, second_deriv, 'purple', linewidth=3)
    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    plt.axvline(x=5, color='gray', linestyle='--', alpha=0.5)

    # 标记正负区域
    zero_cross = np.where(np.diff(np.sign(second_deriv)))[0][0]
    plt.axvspan(x[0], x[zero_cross], alpha=0.2, color='red', label='负响应')
    plt.axvspan(x[zero_cross], x[-1], alpha=0.2, color='blue', label='正响应')

    plt.title('二阶微分（拉普拉斯）- 在边缘中心过零点，两侧正负峰')
    plt.xlabel('位置')
    plt.ylabel('拉普拉斯值')
    plt.legend()
    plt.grid(True)

    plt.show()

demonstrate_1d_edge()
```

:::
::::

![1.3 灰度图像下的拉普拉斯锐化](/cv/ImageProcessing/04_xxx/11_Laplacian1.png)

```py
cv2.Laplacian(src, ddepth, ksize=1, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)
```

==cv2.Laplacian()的必须参数==：**ddepth** 表示输出图像的深度，通常用 cv2.CV_32F 或 cv2.CV_64F 来保留负值。**ksize** 表示拉普拉斯算子的核大小，必须是正奇数，通常为 1, 3, 5；为 1 时，使用最简单的 3x3 拉普拉斯核，为其他值时 OpenCV 使用 Sobel 算子的派生形式来计算拉普拉斯，效果更好。

**可选参数**：**scale** 可选的缩放因子。**delta** 可选的加到结果上的值。**borderType** 边界填充方式。

==cv2.convertScaleAbs()== 函数做了两件事，先是取绝对值 abs_value = |x|，然后缩放并转换为 uint8，result = min(255, max(0, abs_value)).astype(np.uint8)。

```py
cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]])
```

==cv2.filter2D 的必须参数==：**ddepth** 同样表示输出图像的深度，常用 -1 保持原深度，cv2.CV_32F 保留小数。**kernel** 表示卷积核，必须为 np.float32 浮点型矩阵。

### 1.4 高提升滤波（线性）

==高提升滤波（High-Boost Filtering）== 是 Unsharp Masking 的推广和增强版本。它的核心思想是：**在增强高频细节（边缘）的同时，保留甚至增强原始图像的低频信息（平坦区域）**。简单来说，就是比普通的锐化"更狠"，但比直接放大高频分量更可控。

回忆一下 USM，f 代表原始图像；$\bar{f}$ 表示模糊图像；k 表示增益系数，控制**高频细节**的增强程度。HBF 引入了一个新的参数 A（放大因子），用来控制**原始信号**的增强程度：

**当 A=1 时**，就是标准的 Unsharp Masking；**当 A>1 时**，在锐化的同时增强整体对比度；**当 A<1 时**，在锐化的同时减弱整体亮度。我们从公式的角度来看一下，同样用 M 表示 3x3 的均值卷积核，$\bar{f}=f\cdot{M}$：

$$
g=A\cdot{f}+k\cdot{(f-\bar{f})} \\[1em]
g=(A+k)\cdot{f}-k\cdot{\bar{f}} \\[1em]
g=(A+k)\cdot{f}-k\cdot{(f*M)} \\[1em]
g=f*[(A+k)\cdot{I}-k\cdot{M}]
$$

通过推导，高提升滤波核可以写为：==$kernel_{hb}=(A+k)\cdot{I}-k\cdot{M}$==，我们手动计算一下，假设 A = 2.0，k = 1.2 时：

$$
kernel_{hb}=3.2\cdot{I}-1.2\cdot{M}=
\begin{bmatrix}
-0.1333 & -0.1333 & -0.1333 \\[0.8em]
-0.1333 & 3.0667 & -0.1333 \\[0.8em]
-0.1333 & -0.1333 & -0.1333
\end{bmatrix}
$$

:::: code-group
::: code-group-item 公式法与卷积核法的实现

```py
import cv2
import numpy as np
import matplotlib.pyplot as plt

def high_boost_filter(image, kernel_size=(5, 5), sigma=1.0, A=1.0, k=1.0):
    image_float = image.astype(np.float32)  # 转化为浮点图像
    blurred = cv2.GaussianBlur(image_float, kernel_size, sigma)  # 创建模糊图像
    # 正确的高提升公式：g = A·f + k·(f - f_bar)
    sharpened = A * image_float + k * (image_float - blurred)
    sharpened = np.clip(sharpened, 0, 255)  # 限制范围
    return sharpened.astype(image.dtype)

# 使用卷积核的实现方式
def high_boost_filter_kernel(image, A=1.0, k=1.0):
    # 定义 5x5高斯核 与 5x5单位核
    kernel_5x5 = cv2.getGaussianKernel(5, 1)  # 高斯一维核
    gaussian_2d = kernel_5x5 @ kernel_5x5.T  # 高斯二维核
    gaussian_kernel = gaussian_2d / gaussian_2d.sum()  # 归一化处理
    identity_kernel = np.zeros((5, 5), dtype=np.float32)
    identity_kernel[2, 2] = 1.0  # 单位核

    # 计算高提升滤波核：K = (A+k)·I - k·M
    high_boost_kernel = (A + k) * identity_kernel - k * gaussian_kernel

    # 应用卷积，限制范围
    sharpened = cv2.filter2D(image.astype(np.float32), -1, high_boost_kernel)
    sharpened = np.clip(sharpened, 0, 255)
    return sharpened.astype(np.uint8)
```

:::
::: code-group-item 调用并显示

```py
def show_img_by_plt(img, title, pos):
    ax = plt.subplot(1, 3, pos)
    plt.imshow(img, cmap="gray")
    plt.title(title)
    plt.axis('off')

img = cv2.imread('01_luna.png', cv2.IMREAD_GRAYSCALE)  # 读取图像

# 应用不同滤波，卷积核 与 公式实现 结果是一样的
hb_result1 = high_boost_filter(img, A=1.0, k=1.5)  # 高提升 (A=1.0)
hb_result2 = high_boost_filter(img, A=1.5, k=1.5)  # 高提升 (A=1.5)
# hb_result3 = high_boost_filter_kernel(img, A=1.0, k=1.5)  # 高提升 (A=1.0)
# hb_result4 = high_boost_filter_kernel(img, A=1.5, k=1.5)  # 高提升 (A=1.5)

plt.figure(figsize=(14, 8))
show_img_by_plt(img, "Original Image", 1)
show_img_by_plt(hb_result1, "High Boost Filter A=1.0", 2)
show_img_by_plt(hb_result2, "High Boost Filter A=1.5", 3)
plt.show()
```

:::
::::

![1.4 高提升滤波的锐化](/cv/ImageProcessing/04_xxx/13_HBF.png)

### 1.5 基于梯度（非线性）

线性锐化那一套只是「锐化的半壁江山」而已，虽然简单快速，但容易放大噪声。==非线性锐化== 强调局部结构自适应、保边性强、抑噪效果好。**基于梯度的非线性锐化** 是根据局部梯度强度决定锐化幅度。OpenCV 中有一些接口可以组合起来：

- **Sobel / Scharr** → 提取边缘强度（梯度）
- **edgePreservingFilter** → 抑制非边缘区域的噪声和平滑背景
- 两者结合 → 在“知道哪里是边缘”的前提下“只锐化该增强的部分”。

先来说 ==cv2.Sobel()== 函数，Sobel 是一阶梯度算子，计算图像的一阶导数（梯度），提取边缘方向变化。数学原理基于卷积，一个水平梯度，一个垂直梯度：

$$
G_{x}=\begin{bmatrix}
-1 & 0 & +1 \\[0.5em] -2 & 0 & +2 \\[0.5em] -1 & 0 & +1
\end{bmatrix}*f, \quad
G_{y}=\begin{bmatrix}
-1 & -2 & -1 \\[0.5em] 0 & 0 & 0 \\[0.5em] +1 & +2 & +1
\end{bmatrix}*f
$$

两个方向的梯度通常是组合起来使用的：$G=\sqrt{G_{x}^{2}+G_{y}^{2}}$

再说 ==cv2.Scharr()== 函数，Scharr 是改进型 Sobel，因为 Sobel 在小尺寸核时导数近似误差较大（数值偏斜），Scharr 核通过调整权重系数改善了这一点：

$$
G_{x}=\begin{bmatrix}
-3 & 0 & +3 \\[0.5em] -10 & 0 & +10 \\[0.5em] -3 & 0 & +3
\end{bmatrix}*f, \quad
G_{y}=\begin{bmatrix}
-3 & -10 & -3 \\[0.5em] 0 & 0 & 0 \\[0.5em] +3 & +10 & +3
\end{bmatrix}*f
$$

使用方式上基本是一致的，但是 Scharr 没有 ksize 参数，固定为 3x3：

```py
gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)
gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)
grad = cv2.magnitude(gx, gy)

gx = cv2.Scharr(img, cv2.CV_32F, 1, 0)
gy = cv2.Scharr(img, cv2.CV_32F, 0, 1)
grad = cv2.magnitude(gx, gy)
```

==cv2.edgePreservingFilter()== 是边缘感知滤波器，非线性滤波，平滑图像时保留显著边缘。

```py
cv2.edgePreservingFilter(src, flags=1, sigma_s=60, sigma_r=0.4)
```

- **flags**：模型选择（1:递归滤波，2:标准滤波）。通常为 1。
- **sigma_s**：空间平滑参数，越大越模糊。一般在 40~80 之间。
- **sigma_r**：灰度域参数，控制边缘保留程度。一般在 0.2~0.6 之间。

这是组合起来的实现函数，实现的公式可以写为：

$$g=f+a\cdot{w(x,y)}\cdot{f-\bar{f}}$$

```py
def nonlinear_gradient_sharpen(img, alpha=2.0, sigma_s=60, sigma_r=0.4):
    img_f = img.astype(np.float32)

    # 1. 边缘保持平滑
    smooth = cv2.edgePreservingFilter(img_f, flags=1, sigma_s=sigma_s, sigma_r=sigma_r)

    # 2. 计算梯度幅值 (用 Scharr 比 Sobel 更精确)
    gx = cv2.Scharr(img_f, cv2.CV_32F, 1, 0)
    gy = cv2.Scharr(img_f, cv2.CV_32F, 0, 1)
    grad = cv2.magnitude(gx, gy)

    # 3. 归一化梯度幅值，构造权重图
    weight = cv2.normalize(grad, None, 0, 1, cv2.NORM_MINMAX)

    # 4. 自适应锐化
    sharpened = img_f + alpha * weight * (img_f - smooth)
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    return sharpened
```

不知道有没有人和我一样的疑问：👉 为什么看上去还是线性运算，却被称为“非线性锐化”？从公式的形式上来看确实很像线性，但是权重 w(weight) 是非线性的，小梯度接近于 0，大梯度接近于 1；平滑图像 $\bar{f}$ 也是非线性的。在数学层面上，不满足叠加性与齐次性，所以它是非线性锐化。

### 1.6 形态学梯度（非线性）

==基于形态学梯度（Morphological Gradient）的锐化== 是利用形态学操作（膨胀/腐蚀）提取边缘，再将结果叠加回原图。**对强边缘敏感，不依赖导数计算，可用结构元素控制尺度**。常用于灰度图锐化、古画修复、医学影像。

形态学梯度是基于膨胀 (dilation) 与腐蚀 (erosion) 的差实现的。$f\oplus{B}$ 表示膨胀操作，取局部最大值；$f\ominus{B}$ 表示腐蚀操作，取局部最小值。二者之差表示局部灰度变化强度，即边缘。

我们可以通过两个接口来完成这个锐化过程，首先是 ==cv2.getStructuringElement()== 函数，用来定义结构元素，也就是形态学操作的“模板”（根据自己图像的类型，来选择形状，通用就用椭圆）：

```py
kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(3,3))
```

- **cv2.MORPH_RECT**：矩形。一般性边缘检测
- **cv2.MORPH_ELLIPSE**：椭圆。图像平滑自然
- **cv2.MORPH_CROSS**：十字。细线、轮廓结构

其次是 ==cv2.morphologyEx()== 函数，形态学通用接口。参数 **op** 有很多定义，我们需要用于边缘检测的形态学梯度，也就是膨胀减去腐蚀，所以用 **cv2.MORPH_GRADIENT**。

```py
morph_gradient = cv2.morphologyEx(src, op=cv2.MORPH_GRADIENT, kernel)
```

形态学梯度的锐化公式可以写作（原图 + 系数 \* 形态学梯度）：

$$
G=f+\alpha\cdot{[(f\oplus{B})-(f\ominus{B})]}
$$

```py
def morphological_gradient_sharpen(image, kernel_size=3, alpha=1.0):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if image.ndim == 3 else image.copy()

    # 定义结构元素（结构元可选椭圆/矩形/十字），计算形态学梯度：dilate - erode
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    morph_gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)

    # 转换为浮点增强；锐化：原图 + α × 形态学梯度
    img_f = gray.astype(np.float32)
    grad_f = morph_gradient.astype(np.float32)
    sharpened = img_f + alpha * grad_f

    # 限制范围并返回
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    return sharpened, morph_gradient
```

![1.5 基于形态学梯度的锐化](/cv/ImageProcessing/04_xxx/14_MG.png)

上一小节没有放图是因为跟之前线性的结果是一致的，这里我们看是明显不同的，感觉上就像是整体亮度提升了，并且有一点奶油化的质感，发糊、发腻、像美颜滤镜。

前者的原因是，膨胀会让亮区扩散、腐蚀会让暗区扩散，所以我们叠加到原图时，如果亮区被增强的更多，整体亮度确实就上升了。后者，是因为在强化边缘的同时，也模糊了纹理结构。高频细节被抑制，边缘区域的低频能量增加，所以画面看着既“更锐”又“更糊”，这种悖论正是“奶油感”。

### 1.7 双边滤波（非线性）

双边滤波没什么要说的，在《噪声与滤波》章节已经讲的很清楚了，用它来做锐化，和 USM 差不多，就是用双边滤波代替了高斯滤波。**是摄影类锐化中比较实用的一类**。==双边滤波锐化== 的公式可以写为：

$$
G=f+\alpha\cdot{(f-B(f))}
$$

这里的锐化系数 alpha 通常取值为 1.0~2.0，这是函数的实现形式（结果差不多，所以就不上图了）：

```py
def bilateral_sharpen(image, d=9, sigmaColor=75, sigmaSpace=75, alpha=1.5):
    img_f = image.astype(np.float32)
    smooth = cv2.bilateralFilter(img_f, d, sigmaColor, sigmaSpace)
    sharpened = img_f + alpha * (img_f - smooth)
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)
    return sharpened
```

### 1.8 导向滤波（非线性）

==基于导向滤波（Guided Filter）的锐化== 是更高级版本，用导向滤波器代替双边核，在 HDR、细节增强、图像增强中非常常见。**不仅可以大范围平滑、不产生光晕（halo）、速度还远快于双边滤波**。我们可以通过 ==cv2.ximgproc.guidedFilter()== 函数实现导向滤波锐化：

```py
cv2.ximgproc.guidedFilter(guide, src, radius, eps)
```

- **guide**：导向图（Guidance Image），控制平滑的边缘位置。通常用原图或者灰度图。
- **src**：待滤波图（Source Image），想平滑或锐化的目标。可以是灰度或彩色
- **radius**：局部窗口半径，控制局部线性模型的范围。窗口越大 → 平滑效果越明显 [4, 16]
- **eps**：正则化参数（epsilon），防止局部方差为 0。越大，平滑更多；越小，保留更多细节 [1e-4, 1e-1]

```py
def guided_sharpen(image, radius=8, eps=1e-2, alpha=1.5):
    img_f = image.astype(np.float32) / 255.0
    guide = img_f  # 可以用其他引导图

    smooth = cv2.ximgproc.guidedFilter(guide, img_f, radius, eps)
    sharpened = img_f + alpha * (img_f - smooth)
    sharpened = np.clip(sharpened * 255, 0, 255).astype(np.uint8)
    return sharpened
```

![1.6 线性滤波与导向滤波的比较](/cv/ImageProcessing/04_xxx/15_BSGB.png)

需要说明的是，没有一个方法的参数，是有绝对的最佳值的。就跟摄像一样，我们需要在不同的环境下，设置不同的参数。最后补充一个和导向滤波比较相似的方法，叫做 ==各向异性扩散锐化==，可以通过 ==cv2.ximgproc.anisotropicDiffusion()== 函数来实现。

```py
def anisotropic_diffusion_sharpen(image, alpha=0.15, K=30, niters=20, beta=1.0):
    # 进行各向异性扩散平滑（edge-preserving）
    diffused = cv2.ximgproc.anisotropicDiffusion(image, alpha, K, niters)

    # 非线性锐化：反向增强边缘
    img_f = image.astype(np.float32)
    sharpened = img_f + beta * (img_f - diffused.astype(np.float32))
    sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)

    return sharpened, diffused
```

![1.7 各向异性扩散锐化](/cv/ImageProcessing/04_xxx/16_test.png)

参数和原理就不解释了，想了解的可以去查一查。在实现上有两点需要说明，首先是 **cv2.ximgproc.anisotropicDiffusion()** 函数只接受两种类型的输入：

1. 二维灰度图 → shape (H, W)，dtype=np.uint8
2. 彩色三通道图 → shape (H, W, 3)，dtype=np.uint8

像 OpenCV 直接转化为灰度图，shape 会变成 (H, W, 1)，这样也是不被允许的，如果需要用灰度图做对比，请对 shape 做一个重构。第二个要说的是，这两个在 ==ximgproc== 路径下的接口，是需要 OpenCV 的扩展包的（两者的版本要对应）：

```py
pip install opencv-python  # 基本包
pip install opencv-contrib-python  # 扩展包
```

## 2. 均衡化

==直方图均衡化 (Histogram Equalization)== 是指调整图像的灰度分布，使直方图更均匀。用于 **提高图像对比度**，提升细节可见性。常见的应用有：医学图像增强（如 X 光片）、低光环境图像处理、工业检测、文档图像增强等等。它是 **强度域（或称为统计域）** 的操作，旨在重新分布亮度的概率密度。

### 2.1 什么是直方图

==图像直方图== 是反应图像色调分布的直方图，它会绘制 **每个色调值的像素数**（也称为频率，frequency）。比如灰度图像也是 256 个像素强度值，直方图的横坐标就是 256 个数值，它的纵坐标取决于像素数，最大值就是总的像素数。所以直方图中每个矩形的高度可以定义为：

$$
h(i)=\text{number of pixels with intensity i, }(i\in{[0, 255]})
$$

例如，h(80) 就是强度为 80 的所有像素数。为了更好的理解它，我们构建一个，由 7 个不同灰度级的方块组成的图形，并将其可视化。灰度值分别为：30、60、90、120、150、180、210。

:::: code-group
::: code-group-item 1. 生成正/反两组像素块

```py
import numpy as np
import matplotlib.pyplot as plt
import cv2

def build_sample_image():
    # 定义不同的灰度值：60，90，120，150，180，210
    tones = np.arange(start=60, stop=210, step=30)
    # 使用灰度值 30 初始化第一个 60 x 60 的方块像素图像
    result = np.ones((60, 60, 3), dtype="uint8") * 30
    # 将剩余的灰度方块依次拼接到右侧
    for tone in tones:
        block = np.ones((60, 60, 3), dtype="uint8") * tone
        result = np.concatenate((result, block), axis=1)

    return result.astype('uint8')

def build_sample_image_2():
    # 翻转构建的灰度图像
    img = np.fliplr(build_sample_image())
    return img.astype('uint8')
```

:::

::: code-group-item 2. plt 子图构造函数

```py
def show_img_with_matplotlib(color_img, title, pos):
    img_RGB = color_img[:, :, ::-1]

    ax = plt.subplot(2, 2, pos)
    plt.imshow(img_RGB)
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_gray(hist, title, pos, color):
    ax = plt.subplot(2, 2, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([0, 256])
    plt.plot(hist, color=color)
```

:::

::: code-group-item 3. 建立画布并可视化

```py
plt.figure(figsize=(14, 10))
plt.suptitle("Grayscale histograms introduction", fontsize=14, fontweight='bold')

# 构建图像并转换为灰度图像
image = build_sample_image()
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
image_2 = build_sample_image_2()
gray_image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)

# 构建直方图
hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])
hist_2 = cv2.calcHist([gray_image_2], [0], None, [256], [0, 256])

# 绘制灰度图像及直方图
show_img_with_matplotlib(cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR), "image with 60 x 60 regions of different tones of gray", 1)
show_hist_with_matplotlib_gray(hist, "grayscale histogram", 2, 'm')
show_img_with_matplotlib(cv2.cvtColor(gray_image_2, cv2.COLOR_GRAY2BGR), "image with 60 x 60 regions of different tones of gray", 3)
show_hist_with_matplotlib_gray(hist_2, "grayscale histogram", 4, 'm')

plt.show()
```

:::
::::

右侧的直方图，显示出了图像中每个色调值出现的频率。由于左侧中的每个方块都是 60 x 60 = 3600，所以所有的灰度值也都是 3600，其他值则为零。

![2.1 图像直方图的理解](/cv/ImageProcessing/04_xxx/01_HC.png =560x)

总结：我们可以使用 ==cv2.calcHist()== 函数来计算一个或者多个图像的直方图。这里对其参数做一个说明：

```py
cv2.calcHist(images, channels, mask, histSize, ranges)
cv2.calcHist([image], [0], None, [256], [0, 256])
```

| 参数     | 解释                                                                                                                                |
| -------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| images   | 以列表形式提供的 uint8 或 float32 类型的源图像                                                                                      |
| channels | 以列表形式计算直方图的通道的索引(例如，灰度图像中使用 [0]，或多通道图像中 [0]，[1]，[2] 分别计算第一个、第二个或第三个通道的直方图) |
| mask     | 蒙版图像，用于计算蒙版定义的图像特定区域的直方图，如果此参数等于 None，则将在没有蒙版的情况下使用完整图像计算直方图                 |
| histSize | 它表示作为列表提供的 bin 数量，如 [256]。每一个色调值都为一个 bin，常见值包括 8、16、32、64、128、256。                             |
| range    | 要测量的强度值的范围，如 [0,256]                                                                                                    |

### 2.2 灰度直方图

通过 2.1 小节的案例可见，只要不改变图像像素总量的操作，都不会影响直方图的统计。除非是直接 resize 变形了，或者裁剪了图像，像素数量发生了变化，才会导致直方图改变。我们用一张真实照片来实践一下：

```py
import matplotlib.pyplot as plt
import cv2

# 构建图像并转换为灰度图像, 构建直方图
image = cv2.imread("./02_HC.jpg", 0)
hist = cv2.calcHist([image], [0], None, [256], [0, 256])

plt.figure(figsize=(14, 5))
plt.suptitle("Grayscale histograms introduction", fontsize=14, fontweight='bold')

ax = plt.subplot(1, 2, 1)
plt.imshow(image, cmap="gray")
plt.title("Nature Image")
plt.axis('off')

ax = plt.subplot(1, 2, 2)
plt.title("grayscale histogram")
plt.xlabel("bins")
plt.ylabel("number of pixels")
plt.xlim([0, 256])
plt.plot(hist, color='m')

plt.show()
```

![2.2 灰度直方图](/cv/ImageProcessing/04_xxx/02_HC.png)

灰度图像的亮度可以定义为图像所有像素的平均强度，可以写作如下公式：

$$
Brightness=\frac{1}{m\cdot{n}}\sum_{x=1}^{m}\sum_{y=1}^{n}I(x,y)
$$

m 和 n 表示的是图像的宽高，用来归一化或者说是平均。I(x,y) 是指图像中像素点的色调值。如果图像的**平均色调较高**，意味着绝大多数像素将非常接近黑色；相反，如果图像的**平均色调较低**，大多数像素非常接近白色。我们可以对灰度图像做一个加减法，修改图像中每个像素的强度，从而观察直方图如何变化：

:::: code-group
::: code-group-item plt 子图定义函数

```py
import matplotlib.pyplot as plt
import cv2
import numpy as np

def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(2, 3, pos)
    plt.imshow(img, cmap='gray')
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_gray(hist, title, pos, color):
    ax = plt.subplot(2, 3, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    plt.plot(hist, color=color)

plt.figure(figsize=(14, 10))
plt.suptitle("Grayscale histograms introduction", fontsize=14, fontweight='bold')
```

:::

::: code-group-item 灰度图加减法与直方图

```py
# 用灰度模式加载图像，定义像素值
image = cv2.imread("./02_HC.jpg", 0)
M = np.ones(image.shape, dtype="uint8") * 50
image_add = cv2.add(image, M)
image_sub = cv2.subtract(image, M)

# 构建直方图
hist = cv2.calcHist([image], [0], None, [256], [0, 256])
hist_add = cv2.calcHist([image_add], [0], None, [256], [0, 256])
hist_sub = cv2.calcHist([image_sub], [0], None, [256], [0, 256])

# 绘制灰度图像及直方图
show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_gray(hist, "grayscale histogram", 4, 'm')
show_img_with_matplotlib(image_add, "Nature Image Add", 2)
show_hist_with_matplotlib_gray(hist_add, "grayscale histogram", 5, 'm')
show_img_with_matplotlib(image_sub, "Nature Image Sub", 3)
show_hist_with_matplotlib_gray(hist_sub, "grayscale histogram", 6, 'm')

plt.show()
```

:::
::::

![2.3 灰度直方图对比](/cv/ImageProcessing/04_xxx/03_gray2.png)

### 2.3 彩色直方图

彩色直方图与灰度本质上并没有什么不同。需要注意的是，灰度图是单通道，而彩色图是三通道，所以需要循环的去获取每个通道的直方图，并循环的绘制在同一张图上。完整版代码如下：

:::: code-group
::: code-group-item plt 子图定义函数

```py
import matplotlib.pyplot as plt
import cv2
import numpy as np

def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(2, 3, pos)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_rgb(hist, title, pos, color):
    ax = plt.subplot(2, 3, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    for (h, c) in zip(hist, color):
        plt.plot(h, color=c)

plt.figure(figsize=(14, 10))
plt.suptitle("Color histograms introduction", fontsize=14, fontweight='bold')

def hist_color_img(img):
    histr = []
    histr.append(cv2.calcHist([img], [0], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [1], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [2], None, [256], [0, 256]))
    return histr
```

:::

::: code-group-item 彩色图加减法与直方图

```py
# 用彩色模式加载图像，BGR 转 RGB，定义像素值
img = cv2.imread("./02_HC.jpg", 1)
image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
M = np.ones(image.shape, dtype="uint8") * 20
image_add = cv2.add(image, M)
image_sub = cv2.subtract(image, M)

# 构建直方图
hist = hist_color_img(image)
hist_add = hist_color_img(image_add)
hist_sub = hist_color_img(image_sub)

# 绘制灰度图像及直方图
show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_rgb(hist, "Color histogram 1", 4, ["r", "g", "b"])
show_img_with_matplotlib(image_add, "Nature Image Add", 2)
show_hist_with_matplotlib_rgb(hist_add, "grayscale histogram 2", 5, ["r", "g", "b"])
show_img_with_matplotlib(image_sub, "Nature Image Sub", 3)
show_hist_with_matplotlib_rgb(hist_sub, "grayscale histogram 3", 6, ["r", "g", "b"])

plt.show()
```

:::
::::

![2.4 彩色直方图对比](/cv/ImageProcessing/04_xxx/04_color1.png)

### 2.4 全局直方图均衡化

==cv2.equalizeHist()== 是 OpenCV 内置的一个函数，本质上是一个 **全局直方图均衡化（Global HE）** 的实现。它是将原始图像的直方图"拉伸"到整个亮度范围 [0, 255]，通过 ==累积分布函数 CDF== 重新映射像素值，从而实现增强对比度。

特别是对于整体偏暗或偏亮的图像效果很好。用于灰度图像的情况较多，因为该函数期望单通道输入，而灰度图天然表示的就是亮度。

![2.5 灰度-全局直方图均衡化](/cv/ImageProcessing/04_xxx/05_gray_eq.png)

如果对 RGB 图像直接均衡化，需要先分离三个通道分别做均衡化，然后合并。这样必然会导致色彩发生偏移，因为它本质是对亮度做拉伸的，而 RGB 的每一个通道，数值不仅包含亮度，还包括色彩信息。

如果一定要用在彩色图像上，建议转为 HSV (v 亮度通道) / Lab (L 亮度通道)，仅对亮度通道做均衡化。从图 2.6 可以看到，经过 HSV 变换之后，并没有发生色彩偏移，直方图和原本的也很对应。

![2.6 彩色-全局直方图均衡化](/cv/ImageProcessing/04_xxx/06_color_eq1.png)

:::: code-group
::: code-group-item 灰度-全局均衡化

```py
import matplotlib.pyplot as plt
import cv2

def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(2, 2, pos)
    plt.imshow(img, cmap='gray')
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_gray(hist, title, pos, color):
    ax = plt.subplot(2, 2, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    plt.plot(hist, color=color)

plt.figure(figsize=(14, 10))
plt.suptitle("Gray Histograms Equalization", fontsize=14, fontweight='bold')

# 用灰度模式加载图像，构建直方图
image = cv2.imread("./02_HC.jpg", 0)
image_eq = cv2.equalizeHist(image)
hist = cv2.calcHist([image], [0], None, [256], [0, 256])
hist_eq = cv2.calcHist([image_eq], [0], None, [256], [0, 256])

# 绘制灰度图像及直方图
show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_gray(hist, "Histograms", 2, "m")
show_img_with_matplotlib(image_eq, "Nature Image Equalization", 3)
show_hist_with_matplotlib_gray(hist_eq, "Histograms Equalization", 4, "m")

plt.show()
```

:::

::: code-group-item 彩色-全局均衡化 1

```py
import matplotlib.pyplot as plt
import cv2

def hist_color_img(img):
    histr = []
    histr.append(cv2.calcHist([img], [0], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [1], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [2], None, [256], [0, 256]))
    return histr

# 分别对 RGB 的每个通道均衡化
def equalize_color_image_channels(image):
    channels = cv2.split(image)
    equalized_channels = []

    for channel in channels:
        equalized_channels.append(cv2.equalizeHist(channel))
    return cv2.merge(equalized_channels)

# 转换到 HSV 色彩空间, 对亮度通道(V)均衡化
def equalize_color_image_hsv(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv[:, :, 2] = cv2.equalizeHist(hsv[:, :, 2])
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

# 用彩色模式加载图像，BGR 转 RGB，定义像素值
img = cv2.imread("./02_HC.jpg", 1)
image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
image_eq = equalize_color_image_channels(image)
image_eq_hsv = equalize_color_image_hsv(image)

# 构建直方图
hist = hist_color_img(image)
hist_eq = hist_color_img(image_eq)
hist_eq_hsv = hist_color_img(image_eq_hsv)
```

:::

::: code-group-item 彩色-全局均衡化 2

```py
def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(2, 3, pos)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_rgb(hist, title, pos, color):
    ax = plt.subplot(2, 3, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    for (h, c) in zip(hist, color):
        plt.plot(h, color=c)

# 绘制灰度图像及直方图
plt.figure(figsize=(14, 10))
plt.suptitle("Color histograms Equalization", fontsize=14, fontweight='bold')

show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_rgb(hist, "Color histogram 1", 4, ["r", "g", "b"])
show_img_with_matplotlib(image_eq, "Equalization RGB", 2)
show_hist_with_matplotlib_rgb(hist_eq, "Color histogram 2", 5, ["r", "g", "b"])
show_img_with_matplotlib(image_eq_hsv, "Equalization HSV for v", 3)
show_hist_with_matplotlib_rgb(hist_eq_hsv, "Color histogram 3", 6, ["r", "g", "b"])

plt.show()
```

:::
::::

### 2.5 AHE 算法

==AHE== 的全称叫做 **自适应直方图均衡化（Adaptive Histogram Equalization）**，核心思想是，将图像分成多个小区域（瓷砖），对每个区域独立进行直方图均衡化。在 OpenCV 中并没有 AHE 的调用函数，因为它有以下的问题：

1. **过度放大噪声**：在均匀区域，小的噪声会被显著增强（小瓷砖：如 8x8, 16x16, 32x32）
2. **边界伪影**：瓷砖边界处可能出现不连续（小瓷砖）
3. **计算量大**：每个小区域都要单独计算直方图和 CDF（小瓷砖）
4. **局部适应性差**：只能处理大范围的对比度变化（大瓷砖：如 64x64, 128x128, 256x256）
5. **细节增强有限**：小区域的纹理可能被忽略（大瓷砖）

不过没有关系，我们可以手写一下，模拟 AHE 的算法过程，直方图均衡化仍旧可以通过 cv2.equalizeHist() 函数来计算，最主要的是对图像进行分块，可以通过循环来解决：

:::: code-group
::: code-group-item AHE 原始 1

```py
import matplotlib.pyplot as plt
import cv2
import numpy as np

def hist_color_img(img):
    histr = []
    histr.append(cv2.calcHist([img], [0], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [1], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [2], None, [256], [0, 256]))
    return histr

def AHE_opencv(image, tile_size=64):
    """ 使用 OpenCV 函数手动实现 AHE """
    height, width = image.shape  # 获取图像尺寸
    result = np.zeros_like(image)  # 创建一个空图像用于存放结果

    for i in range(0, height, tile_size):
        for j in range(0, width, tile_size):
            roi = image[i:i+tile_size, j:j+tile_size]  # 提取瓷砖区域
            equalized_roi = cv2.equalizeHist(roi)  # Golbal HE
            result[i:i+tile_size, j:j+tile_size] = equalized_roi  # 结果存入新图

    return result

# 转换到 HSV 色彩空间, 对亮度通道(V)均衡化
def equalize_HSV_AHE(image, size_ahe):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv[:, :, 2] = AHE_opencv(hsv[:, :, 2], tile_size=size_ahe)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
```

:::
::: code-group-item AHE 原始 2

```py
# 用彩色模式加载图像，BGR 转 RGB，定义像素值
img = cv2.imread("./02_HC.jpg", 1)
image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
image_eq_hsv1 = equalize_HSV_AHE(image, 32)
image_eq_hsv2 = equalize_HSV_AHE(image, 64)

# 构建直方图
hist = hist_color_img(image)
hist_eq_hsv1 = hist_color_img(image_eq_hsv1)
hist_eq_hsv2 = hist_color_img(image_eq_hsv2)

def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(2, 3, pos)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_rgb(hist, title, pos, color):
    ax = plt.subplot(2, 3, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    for (h, c) in zip(hist, color):
        plt.plot(h, color=c)

# 绘制灰度图像及直方图
plt.figure(figsize=(14, 10))
plt.suptitle("Color Adaptive Histograms Equalization", fontsize=14, fontweight='bold')

show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_rgb(hist, "Color histogram 1", 4, ["r", "g", "b"])
show_img_with_matplotlib(image_eq_hsv1, "Nature Image AHE 32", 2)
show_hist_with_matplotlib_rgb(hist_eq_hsv1, "Color histogram 2", 5, ["r", "g", "b"])
show_img_with_matplotlib(image_eq_hsv2, "Nature Image AHE 64", 3)
show_hist_with_matplotlib_rgb(hist_eq_hsv2, "Color histogram 3", 6, ["r", "g", "b"])

plt.show()
```

:::
::::

通过结果我们可以看到，在暗部的草坪，32 小瓷砖时被均衡化的过量了，看起来几乎都平了，64 的大瓷砖明显好了很多，还保留着原本的形态。但是这个边界伪影实在是太严重了，由于每个瓷砖完全独立处理，相邻瓷砖的映射函数不同，导致边界处亮度跳跃。

![2.7 彩色-自适应直方图均衡化-未优化](/cv/ImageProcessing/04_xxx/07_color_AHE1.png)

1980 年代，AHE 的概念出现，在 1980 年代中期，提出了使用插值方法减少伪影的概念。在 OpenCV 中并没有封装双线性插值的方法，所以我们还是需要手写一下。

先明确一点：AHE 插值 ≠ 改变 tile 内统计。插值不是修改直方图，而是在输出像素值上做空间平滑。它的逻辑是：

1. 每个 tile 独立统计灰度分布 → 独立生成 CDF → 独立映射表。
2. 插值阶段只是根据像素相对于 tile 的位置，用空间权重在 4 个邻域的映射结果之间做加权平均。

:::: code-group
::: code-group-item 双线性插值版本 AHE

```py
def AHE_with_interpolation(image, tile_size=64):
    """ 使用双线性插值减少边界伪影的AHE """
    height, width = image.shape
    result = np.zeros_like(image, dtype=np.float32)

    # 1.为每个瓷砖预先计算映射表
    mapping_tables = []
    for i in range(0, height, tile_size):
        row_mappings = []
        for j in range(0, width, tile_size):
            # 1.1 计算当前瓷砖的全局直方图均衡化结果
            tile = image[i:i+tile_size, j:j+tile_size]
            hist = cv2.calcHist([tile], [0], None, [256], [0, 256])
            # 1.2 计算 CDF，创建像素值映射表
            cdf = hist.cumsum()
            cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())
            row_mappings.append(cdf_normalized)
        mapping_tables.append(row_mappings)

    # 2. 使用双线性插值
    for y in range(height):
        for x in range(width):
            result[y, x] = bilinear_interpolate_pixel(
                y, x, image, mapping_tables, tile_size, height, width
            )

    return result.astype(np.uint8)
```

:::
::: code-group-item 双线性插值函数封装

```py
def bilinear_interpolate_pixel(y, x, image, mapping_tables, tile_size, height, width):
    """双线性插值单个像素（更精确的边界处理）"""
    # 当前像素所在的 tile 索引
    tile_i = int(y // tile_size)
    tile_j = int(x // tile_size)

    # 获取 tile 边界索引（右下方向 clamp）
    tile_i1 = min(tile_i + 1, len(mapping_tables) - 1)
    tile_j1 = min(tile_j + 1, len(mapping_tables[0]) - 1)

    # 当前 tile 的物理坐标范围
    y0 = tile_i * tile_size
    y1 = min((tile_i + 1) * tile_size, height)
    x0 = tile_j * tile_size
    x1 = min((tile_j + 1) * tile_size, width)

    # 防止除以零
    dy = 0 if y1 == y0 else (y - y0) / (y1 - y0)
    dx = 0 if x1 == x0 else (x - x0) / (x1 - x0)

    pixel_val = int(image[y, x])

    # 获取四个邻域映射
    m00 = mapping_tables[tile_i][tile_j][pixel_val]     # top-left
    m10 = mapping_tables[tile_i][tile_j1][pixel_val]    # top-right
    m01 = mapping_tables[tile_i1][tile_j][pixel_val]    # bottom-left
    m11 = mapping_tables[tile_i1][tile_j1][pixel_val]   # bottom-right

    # 双线性插值
    interp_val = (
        (1 - dx) * (1 - dy) * m00 +
        dx * (1 - dy) * m10 +
        (1 - dx) * dy * m01 +
        dx * dy * m11
    )

    return np.clip(interp_val, 0, 255)
```

:::
::::

![2.8 彩色-自适应直方图均衡化-双线性插值优化](/cv/ImageProcessing/04_xxx/08_color_AHE2.png)

### 2.6 CLAHE 算法

==CLAHE== 非常经典，它的全称是 **对比度受限的自适应直方图均衡化（Contrast Limited Adaptive Histogram Equalization）**。在《基础操作》章节的 “2.4 Lab 色彩空间” 中，我们已经讲过了它的用法，在这里我们对其原理再进行一个探究。

```py
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))  # 初始化 CLAHE
L_eq = clahe.apply(L)  # 对 Lab 色彩空间的 L 通道应用，赋值给 L_eq
```

==tileGridSize== 参数就是 AHE 中所说的瓷砖，但要注意的是，这里的 8 x 8 不是说像素，而是说 8 x 8 个 tile。假设图像是 512 x 512 的，那么 512 / 8 = 64 像素，每一个 tile 都是 64 x 64 的区域。

在原始 CLAHE 论文（Zuiderveld, 1994）中，==clipLimit== 表示每个直方图 bin 的最大计数（像素数上限）。举一个例子，若一个 tile 有 N 个像素，直方图有 L 个灰度级（通常 256）；那么每个 bin 的理想平均计数为 N / L；作者将 clipLimitActual 定义为：

$$
clipLimitActual=clipFactor\cdot{\frac{N}{L}}
$$

其中，$clipFactor\in{[1,4]}$，论文中写的通常 1~4 最佳，我们来做一个计算：

假设 tile 是 64 x 64，那么它包含 4069 个像素，L 为 256，所以平均计数 N/L = 16，假设此时 clipFactor = clipLimitActual 就为 32。在同一块 tile 中的 bin，大于平均计数 2 倍（32） 的都会被 “削顶”，然后平均给其它的 bin。

OpenCV 允许 clipLimit 取更大的数值，它的默认值是 40。从算法的角度理解，它和 clipFactor 两者本质上是线性等价的，来看看公式：

$$
clipLimitActual=max(clipLimit\cdot{\frac{N}{L}}, 1)
$$

```py
import matplotlib.pyplot as plt
import cv2

def hist_color_img(img):
    histr = []
    histr.append(cv2.calcHist([img], [0], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [1], None, [256], [0, 256]))
    histr.append(cv2.calcHist([img], [2], None, [256], [0, 256]))
    return histr

# 转换到 HSV 色彩空间, 对亮度通道(V)均衡化
def equalize_HSV(image, clipLimit, tileGridSize):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)
    hsv[:, :, 2] = clahe.apply(hsv[:, :, 2])
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)

def show_img_with_matplotlib(img, title, pos):
    ax = plt.subplot(3, 4, pos)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

def show_hist_with_matplotlib_rgb(hist, title, pos, color):
    ax = plt.subplot(3, 4, pos)
    plt.title(title)
    plt.xlabel("bins")
    plt.ylabel("number of pixels")
    plt.xlim([-10, 266])
    for (h, c) in zip(hist, color):
        plt.plot(h, color=c)

# 绘制灰度图像及直方图
plt.figure(figsize=(14, 10))
plt.suptitle("Contrast Limited Adaptive Histogram Equalization", fontsize=14, fontweight='bold')

img = cv2.imread("./02_HC.jpg", 1)
image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
hist = hist_color_img(image)
prams = [[1.0, (8,8)], [2.0, (8,8)], [3.0, (8,8)], [4.0, (8,8)], [40.0, (8,8)]]
show_img_with_matplotlib(image, "Nature Image", 1)
show_hist_with_matplotlib_rgb(hist, "Color histogram 1", 2, ["r", "g", "b"])

for i in range(len(prams)):
    image_CLAHE = equalize_HSV(image, prams[i][0], prams[i][1])
    hist_eq_hsv = hist_color_img(image_CLAHE)
    img_name = "CLAHE " + str(prams[i][0]) + " " + str(prams[i][1])
    hist_name = "Color histogram " + str(i + 2)
    index = (i*2 + 1) + 2
    show_img_with_matplotlib(image_CLAHE, img_name, index)
    show_hist_with_matplotlib_rgb(hist_eq_hsv, hist_name, index+1, ["r", "g", "b"])

plt.show()
```

![2.9 彩色-CLAHE- clipLimit 参数对比](/cv/ImageProcessing/04_xxx/09_color_CLAHE.png)

最后，**clipLimit 的取值范围的经验值一般还是在 [1,4]**，超过 40 的话，基本就和 AHE 没有什么差别了。
