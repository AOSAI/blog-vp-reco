---
title: 02-基础操作
date: 2025/09/03
categories:
  - OpenCV
tags:
  - 图像处理
  - 格式转换
  - 几何空间变换
  - 色彩空间变换
---

## 1. Hello, OpenCV!

### 1.1 读取写入

```py
import cv2
import numpy as np

# ------------ 英文路径读写 ------------
img1 = cv2.imread("./input_dir/en.jpg", flags)
cv2.imwrite("./output_dir/en.jpg", img1)

# ------------ 中文路径读写 ------------
img2 = cv2.imdecode(np.fromfile("测试图片.jpg", dtype=np.uint8), -1)
cv2.imencode(".jpg", img2)[1].tofile("输出图片.jpg")
```

**1. 英文路径读写（正常）：**

第一个参数都是字符串类型，通过==相对路径==或者==绝对路径==的方式来读取、存储图像数据。第二个参数 flags 是一个可选参数，表示读取图像的方式，默认为 1：

- cv2.IMREAD_COLOR(1)：加载一张三通道彩色图，通道顺序为 BGR，忽视透明度（默认值）。
- cv2.IMREAD_GRAYSCALE(0)：加载一张单通道灰度图。
- cv2.IMREAD_UNCHANGED(-1)：原样读取，包含 Alpha 通道（透明度）也能读取到。

**2. 中文路径读写（特殊）：**

OpenCV 的 cv2.imread / cv2.imwrite 底层调用的是 C/C++ 的标准文件 I/O，它对中文（或非 ASCII 字符）路径支持不好，所以直接读写中文路径文件会报错或返回 None。解决办法是：

- 读：先用 np.fromfile 把文件按二进制形式读入，再用 cv2.imdecode 解码成图像。
- 写：先用 cv2.imencode 把图像编码成二进制数据，再用 .tofile 保存为中文路径文件。

这种方式绕过了 OpenCV 的路径解析，直接用 Python 和 Numpy 处理文件的二进制数据，再交给 OpenCV 做解码/编码。

imdecode 中的第二个参数 -1，和 imread 中的 flags 是一致的。imencode 返回的是一个数组，[success_flag, encoded_img]，encoded_img 是二进制图像数据；success_flag 是布尔值，False 的话 encoded_img 为空。

### 1.2 数据类型

图像在读取过程中，可以大致分为==整型==和==浮点型==两种。在不同的编程语言下，写法是不一样的。

|     C++类型     | Python 类型（Numpy） |                 说明                  |
| :-------------: | :------------------: | :-----------------------------------: |
| CV_8U / CV_8UC1 |       np.uint8       | 单通道 8 位无符号整数图像（灰度图像） |
|     CV_8UC3     |       np.uint8       | 三通道 8 位无符号整数图像（彩色图像） |
|     CV_32F      |      np.float32      |         单通道 32 位浮点图像          |
|    CV_32FC3     |      np.float32      |         三通道 32 位浮点图像          |
|    CV_32FC2     |     np.complex64     |          双通道复数浮点图像           |

我们日常使用的图像读写，走的都是默认的 unit8。一些简单的图像运算、滤波、几何变换，也许内部会转换为浮点类型，但处理完还是 unit8，它会自动处理。

在目前的图像处理中，浮点图像的像素值一般都在 [0,1] 或者 [-1,1] 的范围内。比如深度学习（神经网络）处理前要对图像数据进行归一化。在保存（imwrite）的过程中，浮点类型也会强制要求转换为 uint8 格式，否则保存的图片可能不能正常显示。

```py
float_img = np.clip(float_img, 0, 1)  # 假设限制范围在 [0,1]
uint8_img = (float_img * 255).astype(np.uint8)  # 缩放至 [0,255]，转换为整型
cv2.imwrite('output.jpg', uint8_img)  # 写入
```

复数数据 complex64 在光学、信号处理类任务中比较常见，因为傅里叶变换（DFT / FFT）的结果是复数，需要双通道保存实部和虚部。但是一般的入门图像处理中，很难见到，包括这些高精度图像 unit16（float64）：

- 医学影像 CT/MRI（像素值范围远大于 0~255）。
- HDR 图像（高动态范围，亮度可能大于 255）。

### 1.3 显示方式

**1. OpenCV 自带窗口 (cv2.imshow)**

```py
import cv2

img = cv2.imread("test.jpg")
cv2.imshow("image", img)  # 默认使用 BGR 通道顺序，色彩正常
cv2.waitKey(0)  # 等待按键（毫秒），0 表示无限等待，时间太短会一闪而过
cv2.destroyAllWindows()  # 可选操作，手动释放占用的内存
```

cv2.imshow()的过程中，整型和浮点类型都可以显示，但是需要注意像素值的区间，整型为 [0, 255]，浮点型为 [0.0, 1.0]。如果超出范围，是不能被正常显示的。

**2. Matplotlib (plt.imshow)**

```py
import cv2
import matplotlib.pyplot as plt

img = cv2.imread("test.jpg")
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # 通道顺序从 BGR 转换成 RGB
plt.imshow(img_rgb)  # 获取图像的数据和格式
plt.axis("off")  # 将坐标轴等信息都关闭，保留空白画布
plt.show()  # 显示图像
```

plt.imshow()只是能获取图像的数据和格式，要显示还需要 plt.show()。与 cv2.imshow()一致，整形和浮点类型都能显示。

根据广大网友(博客帖子)的经验，OpenCV 的显示适用于，后续还有对原图的其他操作，并且要展示出来的情况；Matplotlib 不需要展示原始图像，而是绘制一张新的图像，只对当前这个结果进行显示和处理。

### 1.4 格式转换

图像格式种类很多，但根据应用场景，大致分三类：

- **栅格图像类型**：JPG、PNG、GIF、BMP、TIFF
- **新兴网络格式**：WebP、HEIF
- **专业格式**：RAW、PSD、SVG

1. 常见栅格图像格式

- ==JPG/JPEG== 是最常见的格式，相机拍摄、网络传输等使用的很多。特点是无透明通道，有损压缩（压缩多次会画质下降），但体积较小。
- ==PNG== 是无损压缩，支持透明通道。适合图标、UI、插画，但文件体积通常大于 JPG。
- ==BMP== 无压缩，体积大，读写速度快。曾经在 Windows/游戏里很常见，但现在基本被 PNG/JPG 取代。
- ==GIF== 支持动图（帧序列），但最多 256 色。
- ==TIFF== 支持无损和有损压缩，兼容高位深（16 位、32 位）。多用于科研、医学成像、扫描。

2. 新兴网络格式（主要面向网络和移动设备）

- ==WebP== 是 Google 推出的，压缩比更高，比 JPG/PNG 体积小。支持无损和透明度，也支持动图。目前 Chrome、Firefox、Edge 等浏览器都支持显示。
- ==HEIF / HEIC== 在苹果生态(IOS)里常见，相比 JPEG 体积更小，画质更好，但多平台的兼容性较差。

3. 专业格式

- ==RAW== 是相机拍摄的原始图像数据，未经过压缩或轻度压缩。体积非常大，需要专门软件（Lightroom、Photoshop）处理。优点是后期调色空间更大。
- ==PSD== 是 Photoshop 的专用格式，带有图层、蒙版等信息。虽然是图像文件，但更多是「项目文件」，不属于通用图像格式。
- ==SVG/AI/EPS== 等格式是基于 XML 的矢量图格式，常用于网页图标、插画。特点是无论放多大都不失真。

回顾一下，《综述》中有说过，Pillow 支持更多格式，所以格式转换用 Pillow 的更多。==OpenCV 仅支持 JPEG(.jpg, .jpeg)，PNG，BMP(.bmp, .dib)，TIFF(.tif, .tiff)==，这些常见格式，转换的方法也十分简单，OpenCV 本身不关心「文件格式」，它读进来的就是 矩阵（numpy 数组），格式转换的本质就是重新保存：

```py
import cv2
img = cv2.imread("test.jpg")  # 读入原图

cv2.imwrite("output.png", img)  # 转 PNG
cv2.imwrite("output.bmp", img)  # 转 BMP
cv2.imwrite("output.tiff", img)  # 转 TIFF
```

## 2. 色彩空间变换

在数字图像处理中，**色彩空间（Color Space）** 描述了图像中颜色的表示方式。不同的色彩空间具有不同的特点和适用场景，例如有些色彩空间强调视觉直观性，有些则方便图像处理或颜色分析。常用的色彩空间包括 RGB、Grayscale、HSV、Lab、YUV、CMYK 等，各自适用于显示、图像分析、视频编码或打印等任务。

| 色彩空间    | 特点                 | 典型应用               |
| ----------- | -------------------- | ---------------------- |
| RGB         | 最常用，直观但不独立 | 图像显示、简单处理     |
| Grayscale   | 简化为单通道         | 特征检测、边缘检测     |
| HSV / HLS   | 色调和饱和度独立     | 目标检测、颜色过滤     |
| YUV / YCbCr | 分离亮度和色度       | 视频编码、人脸检测     |
| Lab         | 与人眼感知接近       | 图像增强、颜色分割     |
| CMYK        | 针对打印优化         | 图像输出到打印设备     |
| XYZ / LUV   | 高精度颜色管理和分析 | 专业颜色匹配、颜色测量 |

### 2.1 cv2.cvtColor()

在 cv2.imread() 读取图像时，可以使用 flags(-1,0,1) 来决定灰度图/彩色图。除此之外，还可以用 cvtColor 函数进行两者之间的转化。

```py
img1 = cv2.imread("test.jpg", 1)  # 读取 BGR 彩色图像
img2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)  # 彩色 BGR 转灰度
```

命名理解起来还是挺简单的，并且挺有意思：两个颜色中间的 2 就是 to 的谐音，2 前是当前颜色空间，2 后是目标颜色空间。

需要注意的是，灰度图像无法恢复原始彩色信息。灰度图像只保留亮度信息，当转换为三通道图像时，通常只是将灰度值复制到 R、G、B 三个通道上，形成“伪彩色图像”。OpenCV 中的加权方式大概是这样：

$$Gray = 0.114×B + 0.587×G + 0.299×R$$

该函数的参数一共有四个，我们一般用的都是前两个：src 是一个 numpy 数组，表示读取到的图像数据；code 就是转换代码，决定输入和输出色彩空间，例如 COLOR_BGR2GRAY。

```py
cv2.cvtColor(src, code, dst=None, dstCn=0)  # 全部参数
```

dst 表示输出图像，Python 中基本用不到，这个接口是留给 C++用的。dstCn 表示输出图像的通道数，默认值 0 表示自动匹配，可以手动指定。

OpenCV 的转换代码（code）超过 150 种，但我们常用的真的不多，按照类别可以整理成这样：

1. ==通道变换==：BGR ↔ RGB ↔ RGBA
2. ==灰度变换==：BGR，RGB，RGBA ↔ GRAY
3. ==HSV/Lab 等==：BGR，RGB，RGBA ↔ HSV，HLS，Lab，Luv，YCrCb
4. ==浮点型/高精度==：BGR，RGB，RGBA ↔ XYZ

双箭头(↔)两边的值都是可以相互转换的，但要注意的是，HSV 等色彩空间都是 3 通道，没有 alpha 通道，从 RGBA 转换为 HSV 时，透明度信息会直接丢弃，如果要从 HSV 转换会 RGBA，需要手动拼接 alpha 通道。

```py
import cv2
import numpy as np

# 1. 读取带透明通道的 PNG 图像，打印形状
img_rgba = cv2.imread("image.png", -1)  # shape: H x W x 4
print("Original shape:", img_rgba.shape)

# 2. 分离 alpha 通道，转换成 HSV
rgb = img_rgba[:, :, :3]    # RGB，通道索引 [0，1，2]
alpha = img_rgba[:, :, 3]   # alpha，通道索引 [3]
hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)  # RGB -> HSV

# 3. 处理 HSV 图像
# ------------ 对 HSV 进行处理 ------------

# 4. 从 HSV 转换回 RGB，拼接 alpha 通道
rgb_result = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)  # HSV -> RGB
rgba_result = cv2.merge([rgb_result, alpha])  # 合并 alpha 通道

# 5. 保存结果，打印形状
cv2.imwrite("image_hsv_processed.png", rgba_result)
print("Processed image saved, shape:", rgba_result.shape)
```

### 2.2 RGB 色彩空间

#### 2.2.1 使用 cv2.split() 分离 RGB 通道

```py
import cv2
import numpy as np
import matplotlib.pyplot as plt

img = cv2.imread('img_process_0/lena.png')
b, g, r = cv2.split(img)  # 分离通道
```

cv2.split(img)：将 RGB 图像拆分为 3 个单通道图像，分别对应 B、G、R 通道。要注意的是，因为单通道的原因，这三个图像都是灰度图像，直接 cv2.imshow()的话，每个通道显示的是其强度值（0-255）：

- R 通道（G 通道、B 通道）： 红色通道（绿色通道、蓝色通道）的强度值显示为白色，其他地方为黑色。

```py
cv2.imshow('Red Channel', r)   # 红色通道
cv2.imshow('Green Channel', g) # 绿色通道
cv2.imshow('Blue Channel', b)  # 蓝色通道
cv2.waitKey(0)
```

这种分离方式只是直观地表示每个通道的像素强度，而不是实际的颜色，强度值越高看着越亮，反之看着越暗。单看代码和解释肯定很懵逼，到了经典的 lena 时刻：

<div class="layout">

![2.1 Red通道](/cv/ImageProcessing/02_xxx/13_lena_R.png =240x)

![2.2 Green通道](/cv/ImageProcessing/02_xxx/14_lena_G.png =240x)

![2.3 Blue通道](/cv/ImageProcessing/02_xxx/15_lena_B.png =240x)

</div>

#### 2.2.2 合并通道显示特定色相

通过 cv2.merge() 可以将某个通道的值保留，同时将其他通道设置为 0，重新组合成新的 RGB 图像。种方式可以直观展示某一颜色成分的空间分布。与单通道灰度显示相比，更容易理解图像的颜色结构。

```py
zero_channel = np.zeros(img.shape[:2], dtype='uint8')  # 创建空白通道

blue = cv2.merge([img[:, :, 0], zero_channel, zero_channel]) # 只保留蓝色
green = cv2.merge([zero_channel, img[:, :, 1], zero_channel]) # 只保留绿色
red = cv2.merge([zero_channel, zero_channel, img[:, :, 2]])  # 只保留红色

cv2.imshow('Blue', blue)
cv2.imshow('Green', green)
cv2.imshow('Red', red)
cv2.waitKey(0)
```

<div class="layout">

![2.4 Red合并通道](/cv/ImageProcessing/02_xxx/16_lena_R.png =240x)

![2.5 Green合并通道](/cv/ImageProcessing/02_xxx/17_lena_G.png =240x)

![2.6 Blue合并通道](/cv/ImageProcessing/02_xxx/18_lena_B.png =240x)

</div>

#### 2.2.3 Matplotlib 中的 cmap 映射

plt 的自动颜色映射（cmap="XXX"），可以直接显示出对应通道的色相，原理和上一小节的“合并通道”是一样的，只不过 plt 内部自动执行了。

```py
plt.figure(figsize=(10, 5))
plt.subplot(131), plt.imshow(b, cmap="Blues"), plt.title('Blue Channel')
plt.subplot(132), plt.imshow(g, cmap="Greens"), plt.title('Green Channel')
plt.subplot(133), plt.imshow(r, cmap="Reds"), plt.title('Red Channel')
plt.show()
```

但是这个结果，让我感觉锐化很严重。Chat-gpt 告诉我，这是因为梯度颜色映射会放大像素之间的细微差异，从而使边缘和纹理更明显，看起来像是经过了“锐化处理”。我更偏爱 imshow 的视觉观感。

![2.7 plt中显示单通道-1](/cv/ImageProcessing/02_xxx/19_plt1.png =560x)

如果要显示单通道像素的颜色强度值，我们只需要把 cmap 的值全部改为 gray 就可以了。

![2.8 plt中显示单通道-2](/cv/ImageProcessing/02_xxx/20_plt2.png =560x)

### 2.3 HSV 色彩空间

#### 2.3.1 什么是 HSV 色彩空间？

HSV（Hue, Saturation, Value）是基于人类视觉感知的色彩模型，比 RGB 色彩空间更适合处理颜色检测和分割任务。

- ==Hue(色调)==: 表示颜色的类型，以角度(0°-360°)表示，例如：红色为 0°，绿色为 120°，蓝色为 240°。
- ==Saturation(饱和度)==: 表示颜色的纯度，范围为 0%到 100%。
- ==Value(亮度)==: 表示颜色的亮度，范围为 0%到 100%。

<div class="layout">

![2.9 HSV图解1](/cv/ImageProcessing/02_xxx/21_hsv.webp =240x)

![2.10 HSV图解2](/cv/ImageProcessing/02_xxx/22_hsv1.png =240x)

</div>

#### 2.3.2 RGB 与 HSV 的对比

```py
import cv2
import numpy as np
import matplotlib.pyplot as plt

# 读取图像并转换为HSV
img = cv2.imread('img_process_0/lena.png')
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
```

```py
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# 显示图像
plt.figure(figsize=(10, 5))
plt.subplot(121), plt.imshow(img_rgb), plt.title('Original RGB')
plt.subplot(122), plt.imshow(hsv), plt.title('HSV')
plt.show()
```

![2.11 plt 中 RGB 和 HSV 的对比](/cv/ImageProcessing/02_xxx/23_hsv1.png =560x)

#### 2.3.3 常见颜色 HSV 范围参考表

| 颜色          | H (色调)  | S (饱和度) | V (亮度)  |
| ------------- | --------- | ---------- | --------- |
| 红色 (低范围) | 0 - 10    | 100 - 255  | 100 - 255 |
| 红色 (高范围) | 160 - 180 | 100 - 255  | 100 - 255 |
| 橙色          | 11 - 25   | 100 - 255  | 100 - 255 |
| 黄色          | 26 - 35   | 100 - 255  | 100 - 255 |
| 绿色          | 36 - 85   | 100 - 255  | 100 - 255 |
| 青色          | 86 - 100  | 100 - 255  | 100 - 255 |
| 蓝色          | 101 - 130 | 100 - 255  | 100 - 255 |
| 紫色          | 131 - 160 | 100 - 255  | 100 - 255 |

红色是一个比较特殊的范围，虽然我们看色环的时候，是收尾相接的，但是在 HSV 中并不能，如果需要同时提取高范围和低范围的红色，需要写两次范围分别提取。

另外，饱和度和亮度在实际的计算中取的是百分比，就比如 120/255=47%，中等程度的饱和度。之所以写的是 100 - 255，而不是 0 - 255，是因为我们在处理色彩提取的时候，通常只关心高饱和度和高亮度的范围。

#### 2.3.4 提取特定颜色范围

```py
# 定义紫色的HSV范围
lower_red = np.array([131, 120, 70])
upper_red = np.array([160, 255, 255])

# 提取紫色区域
mask = cv2.inRange(hsv, lower_red, upper_red)
result = cv2.bitwise_and(img, img, mask=mask)

# 显示结果
cv2.imshow('Original', img)
cv2.imshow('Mask', mask)
cv2.imshow('Result', result)
cv2.waitKey(0)
```

- cv2.inRange() 生成掩码，将 HSV 图像中特定范围的颜色提取出来。
- cv2.bitwise_and() 按位操作提取掩码指定的区域。

<div class="layout">

![2.12 HSV提取特定颜色 Mask](/cv/ImageProcessing/02_xxx/24_lena1.png =240x)

![2.13 HSV提取特定颜色 Result](/cv/ImageProcessing/02_xxx/24_lena2.png =240x)

</div>

#### 2.3.5 HSV 色彩通道可视化

```py
h, s, v = cv2.split(hsv)  # 分离HSV通道

# 显示各通道
plt.figure(figsize=(12, 4))
plt.subplot(131), plt.imshow(h, cmap='hsv'), plt.title('Hue')
plt.subplot(132), plt.imshow(s, cmap='gray'), plt.title('Saturation')
plt.subplot(133), plt.imshow(v, cmap='gray'), plt.title('Value')
plt.show()
```

- Hue 通道显示色相信息，颜色范围对应色谱环。
- Saturation 和 Value 通道使用灰度显示数值强度。

![2.14 HSV三通道可视化](/cv/ImageProcessing/02_xxx/25_hsv.png =560x)

### 2.4 Lab 色彩空间

#### 2.4.1 什么是 Lab 色彩空间？

Lab 色彩空间是由国际照明委员会（CIE）提出的一种感知均匀的颜色空间。与 RGB 不同，RGB 是设备相关空间，三原色混合表示颜色，亮度和颜色混合在一起；Lab 将亮度和色彩分离，更符合人眼感知。

- **L**：亮度（Lightness），范围 0–100
- **a**：绿色到红色轴（-128 → +127）
- **b**：蓝色到黄色轴（-128 → +127）

Lab 的显示与设备无关（Device Independent），可以在不同显示设备间保持一致性。常用于颜色校正、图像增强、颜色分析、印刷、摄影后处理等。

#### 2.4.2 RBG 与 Lab 的直观对比

```py
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread('lena.png')
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
```

对比思路：用同一张图像，同时在 RGB 空间和 Lab 空间做一些调整亮度或颜色的操作。输出图像做对比。

```py
# ---------------- RGB 空间亮度/对比度增强 ----------------
img_rgb_bright = cv2.convertScaleAbs(img_rgb, alpha=1.0, beta=120)
# img_rgb_bright = cv2.convertScaleAbs(img_rgb, alpha=1.6, beta=0)

# ---------------- Lab 空间亮度/对比度增强 ----------------
img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
L, a, b = cv2.split(img_lab)

# 只增强亮度通道 L
L = cv2.convertScaleAbs(L, alpha=1.0, beta=120)
# L = cv2.convertScaleAbs(L, alpha=1.6, beta=0)
img_lab_bright = cv2.merge([L, a, b])
img_lab_bright = cv2.cvtColor(img_lab_bright, cv2.COLOR_LAB2RGB)

# ---------------- matplotlib 显示 ----------------
plt.figure(figsize=(12,6))

plt.subplot(1,3,1), plt.imshow(img_rgb, vmin=0, vmax=255)
plt.title('Original Image'), plt.axis('off')

plt.subplot(1,3,2), plt.imshow(img_rgb_bright, vmin=0, vmax=255)
plt.title('RGB Enhance'), plt.axis('off')

plt.subplot(1,3,3), plt.imshow(img_lab_bright, vmin=0, vmax=255)
plt.title('Lab Enhance'), plt.axis('off')

plt.show()
```

1. cv2.convertScaleAbs()函数，用来调整图像亮度和对比度，同时保证输出为 8 位无符号整数 (unit8)。
2. Matplotlib 显示时，plt.imshow() 会自动做 色彩归一化（尤其是整数类型的图像），或者进行 gamma 校正，这可能让亮度增强的差异看起来被压平了，所以需要用 vmin/vmax 调参。

```py
# src 表示 输入图像（可以是灰度或者彩色）
# alpha 表示 缩放系数，作用类似“对比度”调整，默认 1.0。数值越大，对比越强。
# beta 表示 偏移量，作用类似“亮度”调整，默认 0。数值越大，图像整体越亮。
dst = cv2.convertScaleAbs(src, alpha=1.0, beta=0)

# vmin=0, vmax=255，保证像素值按原始强度显示，不会被自动归一化。
plt.imshow(img_rgb_bright, vmin=0, vmax=255)
```

第一个结果是==仅亮度增强(beta=120)==，可以很明显的看出，Lab 空间调整亮度时颜色不变，而 RGB 空间亮度调整让颜色偏移了。

![2.15 RGB 与 Lab 亮度调整对比](/cv/ImageProcessing/02_xxx/26_lena1.png =560x)

第二个结果是==仅对比度增强(alpha=1.6)==，Lab 调对比度比 RGB 更稳定，对颜色偏移不敏感；RGB 调对比度可能影响颜色，尤其在高饱和区域更明显。

这是由于 Lab 的 L 通道是感知均匀亮度，对比度增强更符合人眼对亮度的线性感知。RGB 通道混合了亮度和色彩信息，增强对比时会同时改变颜色分量。

![2.16 RGB 与 Lab 对比度调整对比](/cv/ImageProcessing/02_xxx/26_lena2.png =560x)

#### 2.4.3 CLAHE 直方图均衡化算法

CLAHE 是一种非常经典的直方图均衡化算法，英文全称是 Contrast Limited Adaptive Histogram Equalization，该算法源于 1994 年发表的论文。如今几乎所有的图像处理软件，包括 OpenCV，ImageJ，Matlab 等都支持 CLAHE 算法。它的主要作用在于增强图像的对比度同时能够抑制噪声。

```py
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))  # 初始化 CLAHE
L_eq = clahe.apply(L)  # 对 L 通道应用，赋值给 L_eq
```

- clipLimit [1,4]。值越小，对比度变化越温和；值越大，对比度增强越明显，但可能引入噪点。
- tileGridSize 小块网格大小。小块越多，增强局部细节，轮廓更明显；小块越少，类似全局均衡化，局部差异不明显。

```py
# 转为 Lab 空间，CLAHE 对 L 通道做亮度均衡化
img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
L, a, b = cv2.split(img_lab)
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
L_eq = clahe.apply(L)

# 合并回 Lab 再转回 RGB
img_lab_eq = cv2.merge([L_eq, a, b])
img_lab_eq = cv2.cvtColor(img_lab_eq, cv2.COLOR_LAB2RGB)

# 显示对比
plt.figure(figsize=(10,5))
plt.subplot(1,2,1), plt.imshow(img_rgb), plt.title('Original Image'), plt.axis('off')
plt.subplot(1,2,2), plt.imshow(img_lab_eq), plt.title('CLAHE'), plt.axis('off')
plt.show()
```

从结果可以看出，CLAHE 后的图像层次更丰富，阴影更清晰，轮廓更明显。看起来比单纯线性 alpha/beta 更“立体”，特别适合后期增强和细节分析。cv2.convertScaleAbs()的线性对比度增强，视觉效果上来说，图像整体变亮或整体对比增加，但阴影、暗部轮廓增强不明显。

![2.17 CHALE - Lab 亮度直方图均衡化](/cv/ImageProcessing/02_xxx/27_Lab_clahe.png =560x)

#### 2.4.4 Lab 色彩通道可视化

```py
# 读取图像，转换格式，分离通道
img = cv2.imread("01_lena.png")
lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
L, a, b = cv2.split(lab)

# 可视化
plt.figure(figsize=(12, 6))

# L 通道（亮度）
plt.subplot(1, 3, 1), plt.imshow(L, cmap="gray")
plt.title("L channel (Lightness)"), plt.axis("off")

# a 通道（绿色 ↔ 洋红），cmap 的红绿映射 "RdYlGn"
plt.subplot(1, 3, 2), plt.imshow(a, cmap="gray")
plt.title("a channel (Green <-> Magenta)"), plt.axis("off")

# b 通道（蓝色 ↔ 黄色），camp 的蓝黄映射 "coolwarm"
plt.subplot(1, 3, 3), plt.imshow(b, cmap="gray")
plt.title("b channel (Blue <-> Yellow)"), plt.axis("off")

plt.tight_layout()
plt.show()
```

首先要说明一下灰度图，L 通道是灰度图很好理解，亮度信息嘛，只有明暗的变化，[0,100]的范围是 OpenCV 在内部对 [0,255]缩放得到的。

而 a、b 通道本身不是「颜色」的强度，而是「颜色倾向的偏移量」。[-128,127]这是数学上的定义，中心点为 0。OpenCV 将中心点放在了 128 这个值上，范围是 RGB 色域范围 [0,255]。越亮就代表数值越高。

![2.18 Lab 色彩通道分离1 灰度图](/cv/ImageProcessing/02_xxx/28_lab_ch1.png =560x)

从更为清晰的彩色映射上来看：

- a 通道：大于 128 偏红；小于 128 偏绿。
- b 通道：大于 128 偏黄；小于 128 偏蓝。

![2.19 Lab 色彩通道分离2 彩色图](/cv/ImageProcessing/02_xxx/28_lab_ch2.png =560x)

## 3. 几何空间变换

### 3.1 调整图像大小

#### 3.1.1 cv2.resize()函数的基本参数

```py
cv2.resize(src, dsize, fx, fy, interpolation)
```

- src：输入图像。
- dsize：输出图像的尺寸 (width, height)。如果指定了它，则忽略 fx 和 fy。
- fx, fy：沿水平方向和垂直方向的缩放因子（浮点数）。
- interpolation：插值算法的选择，最核心的参数。

在 OpenCV 里内置的插值方法 一共有 8 种，==最常用的缩小方法==是 cv2.INTER_AREA 和 cv2.INTER_LINEAR（默认），==最常见的放大方式==为 cv2.INTER_CUBIC 和 cv2.INTER_LANCZOS4 ：

| 插值方式       | 宏定义                     | 特点与应用                                         |
| -------------- | -------------------------- | -------------------------------------------------- |
| 最近邻插值     | cv2.INTER_NEAREST(0)       | 速度最快，效果最差，像素风格或掩膜常用             |
| 双线性插值     | cv2.INTER_LINEAR(1)        | 常用，速度与质量均衡，适合缩小或一般放大           |
| 双三次插值     | cv2.INTER_CUBIC(2)         | 考虑 4×4 区域，质量比线性好，放大时效果更自然      |
| 区域插值       | cv2.INTER_AREA(3)          | 缩小时效果最好，相当于做像素区域重采样，避免摩尔纹 |
| Lanczos 插值   | cv2.INTER_LANCZOS4(4)      | 使用 sinc 函数，锐度高，放大时细节保留最好         |
| 最近邻向下取整 | cv2.INTER_LINEAR_EXACT(5)  | 类似 LINEAR，但计算更精确，OpenCV 3.4+ 才有        |
| 自动选择       | cv2.INTER_NEAREST_EXACT(6) | OpenCV 4.5.0 引入的新选项，比 0 好用点             |
| 自动选择       | cv2.INTER_MAX(7)           | 保留最大值（仅部分函数支持，内部用，不常用）       |

#### 3.1.2 按比例/固定尺寸 缩放

```py
import cv2

image = cv2.imread('img_process_0/lena.png')  # 替换你的图像路径
```

1. ==按比例缩放 (Scale Factor)==：直接通过比例因子（坐标轴百分比）调整图像大小，不关心具体像素大小。

```py
scale_x = 0.5  # 宽度缩小为 50%
scale_y = 0.5  # 高度缩小为 50%
resized = cv2.resize(image, None, fx=scale_x, fy=scale_y, interpolation=1)

original_height, original_width = image.shape[:2]  # 假设 Original Size: 512x512
print(f"Original Size: {original_width}x{original_height}")
resized_height, resized_width = resized.shape[:2]  # 则 Resized Size: 256x256
print(f"Resized Size: {resized_width}x{resized_height}")
```

在 OpenCV 中，==img.shape== 函数返回一个三元组：（高度，宽度，通道数）。因此，可以使用切片 [:2] 的方法，直接对高度、宽度进行赋值。

- shape[0]：表示图像的高度（rows，即行数）。
- shape[1]：表示图像的宽度（columns，即列数）。
- shape[2]：表示图像的通道数（例如 RGB 图像有 3 个通道）。

2. ==固定尺寸调整 (Fixed Size)==：直接设置目标尺寸。

这种情况可能会导致图像变形，如果长宽比没有保持一致。就比如，还是 lena 图像，原本 512\*512px，缩放到 300\*200px。

```py
resized = cv2.resize(image, (300, 200), interpolation=1)
cv2.imshow('Scaled Image', resized)
cv2.waitKey(0)
```

![3.1 固定尺寸缩放，长宽比不一致时](/cv/ImageProcessing/02_xxx/11_lena_scale.png =240x)

#### 3.1.3 中心裁剪与边缘填充

在图像类的神经网络（深度学习）算法中，通常我们都会对图像数据集进行预处理。最常见的就是中心裁剪/边缘填充，因为很多算法需要正方形的图像，而我们收集到的数据很可能是矩形。

如果直接对矩形进行固定尺寸缩放，导致图像变形，会影响到神经网络的训练质量。那么，我们首先要做的就是**固定一条边的尺寸，等比例缩放**。

==如果是中心裁剪，固定短边的尺寸==：

```py
# 固定短边尺寸进行等比例缩放
original_height, original_width = image.shape[:2]  # 原始图像的 高宽

width = 1000  # 假设是一张竖着的长图，短边为 width，设置目标大小为 1000
height = width * original_height / original_width  # 根据 width 计算目标长边 height
resized = cv2.resize(image, (width, height), interpolation=3)  # 进行缩放

# 中心裁剪（固定短边 → 正方形）
center_x, center_y = new_width // 2, new_height // 2
half = width // 2
cropped = resized[center_y - half:center_y + half, center_x - half:center_x + half]

# 显示或保存
cv2.imshow("Cropped", cropped)
cv2.imwrite("test.png", cropped)
```

==如果是边缘填充，固定长边尺寸==：

```py
target_long = 1000  # 固定长边尺寸为 1000

top = bottom = (target_long - height) // 2 if height < target_long else 0
left = right = (target_long - width) // 2 if width < target_long else 0
padded = cv2.copyMakeBorder(
    resized, top, bottom, left, right,
    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0]  # 黑边填充，可改为[255,255,255]
)
```

<div class="layout">

![3.2 中心裁剪](/cv/ImageProcessing/02_xxx/10_crop.jpeg =240x)

![3.3 边缘填充](/cv/ImageProcessing/02_xxx/12_padding.jpeg =240x)

</div>

```py
cropped = resized[center_y - half:center_y + half, center_x - half:center_x + half]
```

中心裁剪很好理解，OpenCV 读取到的图像数据，会转化为 Numpy 数组的格式，裁剪仅仅是对这个数组中的数据进行筛选。resized 对象是上一步进行缩放后得到的，找到 resized 的中心点，然后以短边为半径进行截取，就得到了中心裁剪后的图像。

```py
padded = cv2.copyMakeBorder(
    src, top, bottom, left, right,
    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0]  # 黑边填充，可改为[255,255,255]
)
```

cv2.copyMakeBorder 函数的参数解析：

1. src：表示需要被处理的图像对象，是一个 Numpy 数组；
2. top, bottom, left, right：分别表示上下左右需要增加的像素值；
3. borderType：表示指定的边框类型；常见的有以下几种：

   - cv2.BORDER_CONSTANT(0): 添加常数值的边框，value 参数指定边框颜色或灰度值。
   - cv2.BORDER_REPLICATE(1): 复制图像中，最边缘的像素填充边界。
   - cv2.BORDER_REFLECT(2): 镜像反射边缘（不包括边缘像素本身）。
   - cv2.BORDER_WRAP(3): 用图像另一侧的像素填充边界（环绕）。
   - cv2.BORDER_REFLECT_101(4): 镜像反射边缘，包括边缘像素。

4. value：指定边框的颜色或填充值，仅当 borderType 为 cv2.BORDER_CONSTANT 时有效。

Padding 的默认填充方式 0 我们已经见过了，下面是 1、2、3 三种填充方式的视觉表示：

<div class="layout">

![3.4 边缘填充-1](/cv/ImageProcessing/02_xxx/12_padding_1.jpeg =240x)

![3.5 边缘填充-2](/cv/ImageProcessing/02_xxx/12_padding_2.jpeg =240x)

![3.6 边缘填充-3](/cv/ImageProcessing/02_xxx/12_padding_3.jpeg =240x)

</div>

#### 3.1.4 超分：计算机视觉的课题之一 “超分辨率”

OpenCV 包括 Pillow 的 resize 方法，本质上是 插值预测，并没有真正恢复细节。深度学习的 超分辨率（Super-Resolution, SR） 则通过训练模型，从低分辨率预测高分辨率的真实纹理。

缩小的方法，一般都用的是 resize 的方法。放大的话，如果分辨率差别不大，或者不需要很精细，也可以用差值算法，但是如果是 4 倍、8 倍的放大，建议使用超分算法。

### 3.2 旋转和仿射变换

#### 3.2.1 ==cv2.rotate== 函数：90 度角倍数的旋转。

```py
import cv2

img = cv2.imread("img_process_0/lena.png");
rotated_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
rotated_180 = cv2.rotate(img, cv2.ROTATE_180)
rotated_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)

cv2.imshow('Original', img)
cv2.imshow('Rotated 90', rotated_90)
cv2.imshow('Rotated 180', rotated_180)
cv2.imshow('Rotated 270', rotated_270)
cv2.waitKey(0)
```

在编程中，大多数参数的英文命名都是直译的，比如 CLOCKWISE 就代表顺时针，加上 ROTATE_90\_，就代表顺时针方向旋转 90 度；而 COUNTERCLOCKWISE 表示逆时针，顺时针旋转 270 度，就等于逆时针旋转 90 度，一个意思。

<div class="layout">

![3.7 旋转90度](/cv/ImageProcessing/02_xxx/02_lena_ro90.png =240x)

![3.8 旋转180度](/cv/ImageProcessing/02_xxx/03_lena_ro180.png =240x)

![3.9 旋转270度](/cv/ImageProcessing/02_xxx/04_lena_ro270.png =240x)

</div>

#### 3.2.2 ==cv2.getRotationMatrix2D== 和 ==cv2.warpAffine== 函数：任意角度的旋转。

```py
import cv2
import numpy as np

img = cv2.imread("01_lena.png");
(h, w) = img.shape[:2]  # 获取图像宽高

center = (w // 2, h // 2)  # 获取图像中心坐标，“//”是整除运算，向下取整
angle = 45  # 旋转度数设定
scale = 1.0  # 缩放比例设定
M = cv2.getRotationMatrix2D(center, angle, scale)  # 生成旋转矩阵
M1 = cv2.getRotationMatrix2D(center, 200, 0.7)
M2 = cv2.getRotationMatrix2D(center, angle, scale)

# 对旋转矩阵进行仿射变换，输出旋转后的图像
rotated = cv2.warpAffine(img, M, (w, h))
rotated1 = cv2.warpAffine(img, M1, (w, h))

# 调整旋转后的图像边界大小，np.abs()：取绝对值，确保结果为正数。
cos = np.abs(M[0, 0])  # M[0, 0] 对应旋转矩阵中的 cos(θ)
sin = np.abs(M[0, 1])  # M[0, 1] 对应旋转矩阵中的 sin(θ)
new_w = int((h * sin) + (w * cos))
new_h = int((h * cos) + (w * sin))

# 调整旋转矩阵，由于旋转后图像的尺寸变大，原来的中心点需要平移到新的图像中心。
# M[0, 2] 和 M[1, 2] 是仿射变换矩阵中的 平移项。
M[0, 2] += (new_w / 2) - center[0]
M[1, 2] += (new_h / 2) - center[1]
rotated2 = cv2.warpAffine(img, M, (new_w, new_h))  # 仿射变换

cv2.imshow('Original', img)
cv2.imshow('Rotated', rotated)
cv2.imshow('Rotated1', rotated1)
cv2.imshow('Rotated2', rotated2)
cv2.waitKey(0)
```

<div class="layout">

![3.10 旋转45度，无缩放](/cv/ImageProcessing/02_xxx/05_lena_45.png =240x)

![3.11 旋转200度，缩放0.7](/cv/ImageProcessing/02_xxx/06_lena_200.png =240x)

![3.12 旋转45度，边界调整](/cv/ImageProcessing/02_xxx/05_lena_45_1.png =240x)

</div>

代码给出了两种保留完整图像的方式，rotated1 是对旋转后的图像进行了缩小，而 rotated2 是对旋转后的图像扩展了边界。

==cv2.getRotationMatrix2D== 的作用是，生成一个二维旋转的仿射变换矩阵（2×3）。它本身并不会改变图像内容。==cv2.warpAffine== 的作用是，对图像应用仿射变换（包括旋转、缩放、平移等）。这里才真正执行变换，把原图像按照矩阵 M 进行旋转/缩放/平移。

### 3.3 镜像翻转

在 OpenCV 中，可以使用 ==cv2.flip== 函数对图像进行 **镜像翻转** 操作。cv2.flip 支持以下三种翻转方式：

- 水平翻转（左右镜像）：flipCode = 1
- 垂直翻转（上下镜像）：flipCode = 0
- 水平 + 垂直翻转（180° 翻转）：flipCode = -1

```py
import cv2

img = cv2.imread("img_process_0/lena.png")

flipped_h = cv2.flip(img, 1)
flipped_v = cv2.flip(img, 0)
flipped_hv = cv2.flip(img, -1)

cv2.imshow('Original', img)
cv2.imshow('Horizontal Flip', flipped_h)
cv2.imshow('Vertical Flip', flipped_v)
cv2.imshow('Both Flip', flipped_hv)
cv2.waitKey(0)
```

<div class="layout">

![3.13 水平翻转](/cv/ImageProcessing/02_xxx/07_lena_flip_h.png =240x)

![3.14 垂直翻转](/cv/ImageProcessing/02_xxx/08_lena_flip_v.png =240x)

![3.15 水平+垂直翻转](/cv/ImageProcessing/02_xxx/09_lena_flip_hv.png =240x)

</div>

### 3.4 透视变换

透视变换（Perspective Transform）是一种常见的图像几何变换，可以模拟摄像机视角变化、斜拍、投影等效果。与仿射变换相比，透视变换不仅能实现平移、旋转、缩放，还能让图像发生“倾斜”、“拉伸”，比如将矩形变成梯形。它在文档矫正、车道线检测、AR 增强现实等场景中非常实用。

透视变换的数学基础是单应性矩阵（Homography），即一个 3×3 的变换矩阵。通过指定原图像的四个点和目标图像的四个点，OpenCV 可以自动计算出变换矩阵，并完成图像的投影变换。

```py
import cv2
import numpy as np

img = cv2.imread('poker.jpeg')

# 原图像上的四个点（比如选取一个矩形区域的四个顶点）
pts1 = np.float32([(112, 32), (252, 72), (193, 275), (44, 230)])
# 目标图像上的四个点（变换后的位置，可以是任意四边形）
pts2 = np.float32([[80, 80], [280, 80], [280, 380], [80, 380]])

M = cv2.getPerspectiveTransform(pts1, pts2)  # 计算透视变换矩阵
result = cv2.warpPerspective(img, M, (600, 400))  # 应用透视变换

cv2.imshow('Original', img)
cv2.imshow('Perspective Transform', result)
cv2.waitKey(0)
```

<div class="layout">

![3.16 透视变换-原图](/cv/ImageProcessing/02_xxx/29_poker1.webp =240x)

![3.17 透视变换-新图](/cv/ImageProcessing/02_xxx/29_poker2.jpeg =240x)

</div>
