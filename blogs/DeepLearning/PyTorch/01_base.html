<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.19">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <title>PyTorch基础知识 | AoSaiX</title><meta name="description" content="Blog for study, life and hobby.">
    <link rel="preload" href="/blog-vp-reco/assets/style-CO2hMFE6.css" as="style"><link rel="stylesheet" href="/blog-vp-reco/assets/style-CO2hMFE6.css">
    <link rel="modulepreload" href="/blog-vp-reco/assets/app-CkYqgEgS.js"><link rel="modulepreload" href="/blog-vp-reco/assets/01_base.html-BLqngXnu.js">
    <link rel="prefetch" href="/blog-vp-reco/assets/timeline.html-BmBUTgHe.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/posts.html-CI4W8hf-.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/friendship-link.html-B9HP9khK.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/custom-page.html-BH_a5EiX.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-waI05CeC.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-DjrOAqw9.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DCPtBVjg.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-D3_6I-iV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/3.html-DbtFjr08.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-AynghZXz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CJG6L0bz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BVQFBV45.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-B4y4Az9o.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CgYmwuWP.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BApawDc8.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BMMlMe9W.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CPI2J9FJ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-C_wEy4nC.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-D0Rp9O8J.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-yKoM0bi3.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-ChuHEt9i.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-D3fuX-rV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-0aHlg64C.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BHdRO4_5.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-q48LshFL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/3.html-2slaq1rY.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DQu0RLLI.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-CgTKBhKY.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/3.html-D5HOUw8V.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-J-uEa357.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DkR3A7Aa.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-lg4ds7mY.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DU4BauGk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-B0EBlI5c.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CWNy052E.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DHBa6p58.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-3mLsGx1d.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-jdsphMIk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-ClRI3Jir.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BL14h2f7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CKw9Onmr.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Cc32G9tF.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BK_Qd6vB.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CS3NS-ls.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-HERZuIol.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CeFn8Ija.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DhsGvrIC.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DdxMwKai.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DMf9X8nX.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-ChX6LQ0H.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-UkuIakgO.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-Oc_E4pFE.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-B94NKQSZ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CVDCG-XT.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-vR-Rhdom.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-1WRsFfSs.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DTKakW9D.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CCOQw3X9.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BSAlReAi.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BYoJilFh.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-mUGXFKGk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BW-kE79j.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DT85tFes.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-nEgUI6dd.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-D7s95_hi.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-KXdfDL9b.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-BmbN8R4w.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-vWWbPu8u.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-CuAbJyQP.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/1.html-DKuEZ_6T.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/2.html-BtcnX543.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/3.html-C7y2ptfl.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/4.html-DX4w-3PX.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/5.html-DXHEGRGL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/6.html-BCCG9CyT.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/7.html-4RuDE0ZS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-CZPamI9K.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/update_record.html-BLEPbT20.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/vuepress-recojiaocheng.html-3kdOUqtO.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_compress_photo.html-CFhsPkhT.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_file_packaging.html-CHN4lHcV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_pyqt5_recording.html-BkbhO1ma.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_spider_for_ticket.html--AjUcc-n.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-DCxerK2H.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Introduction.html-By4V-AHL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html-Jrwto47R.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_tuxiangxiufurumen.html-DIm39Mg7.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_xxx.html-CLbzJNed.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Introduction.html-C43FAG3J.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html--DBxVvAy.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_xxx.html-vtHMDiXW.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_xxx.html-B9pLt7FQ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_xxx.html-DmsJCxwy.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_xxx.html-CfbGy3Er.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_bairuzongmen.html-CrM15YF8.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_aolianjingu.html-BOGYM37j.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_project1.html-CU_LRy_b.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_project2.html-D3ZTnlnr.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_project1.html-jtdXKwSa.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/index.html-JZxF2-bS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_fargoing.html-imyzyYks.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_shanxi.html-BRJsE5Dd.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_sichuan.html-Dfaxfocr.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/00.html-z90ODlNN.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01.html-DRNS3VzL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/00_introduction.html-Sm8UlekP.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_recommend_model.html-DC7pYJFH.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_introduction.html-CVu_nDCl.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_linear_regression.html-rIBLm-dr.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_linear_regression.html-DEDaaQ9P.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_classification.html-CwQXD7XM.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/05_deep_learning.html-TrgjbOXu.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/06_tensorflow.html-seWODz8B.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/07_model_evaluation.html-CdZXZtSZ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/08_decision_tree.html-LQe2pNlb.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/09_unsupervised_learning.html-BD5pmdtV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/10_recommendation_system.html-BsStN-Xx.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/11_reinforcement_learning.html-BKIdZzOn.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/ML1.html-CuMdtcbu.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA1.html-BVTXtCEv.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA10.html-NYeRyOWl.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA11.html-BSsZOD2n.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA12.html-DM1l4uLk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA13.html-BbSA7S5H.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA14.html-G-gVDLG5.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA15.html-C2LzYfhO.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA16.html-dUkxC_Vz.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA17.html-SrCsbK4l.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA18.html-pVD16DZV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA19.html-EdttqIQl.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA2.html-BrwDyWzK.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA20.html-e2Bbw-fk.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA3.html-Lo1-tQzj.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA4.html-DRTqPfsb.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA5.html-BNv9k4M0.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA6.html-BDIZ7b8F.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA7.html-DAlfg2AH.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA8.html-76jnmz0r.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/LA9.html-DVLs0AfL.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/20_xinhaoyutuxiang.html-BKkwGTOw.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/30_xinhaoyutuxiang.html-UbvwCzbS.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/01_zongshu.html-C4hzgU2P.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/02_jichucaozuo.html-BDUMF-DK.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/03_zaoshengyulvbo.html-Cm6MnPaV.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/04_ruihuayujunhenghua.html-BqXk4-Gj.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/05_xingtaixueyuyunsuan.html-vern5NzA.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/06_yuzhiyulunkuo.html-CRiSO9UD.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/07_xinhaoyutuxiang.html-DqGoJFij.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/08_shipinliuchuli.html-CnybAPtu.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/09_yasuoyubianma.html-UYZcgSsx.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/10_huizhituxingyuwenben.html-Bd4Byvx8.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/11_tezhengyuARzengqiang.html-DbJRkKei.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/12_guangliuyuyundongfenxi.html-buywWHtO.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/404.html-D_REzjgJ.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/Valine.min-_LyT3bfY.js" as="script"><link rel="prefetch" href="/blog-vp-reco/assets/giscus-aTimukGI-DWEKOTfS.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container show-series show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/blog-vp-reco/logo1.svg" alt="AoSaiX"><a href="/blog-vp-reco/" class="site-name can-hide">AoSaiX</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="机器学习"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="机器学习"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/MachineLearning/MachineLearning/01_introduction" class="link" aria-label="机器学习(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->机器学习(未整理)<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/MachineLearning/recommendationSystem/00_introduction" class="link" aria-label="推荐系统(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->推荐系统(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="数据锻造坊"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->数据锻造坊<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="数据锻造坊"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->数据锻造坊<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DataFoundry/Numpy/01_拜入宗门" class="link" aria-label="Numpy"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Numpy<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DataFoundry/Matplotlib/01_xxx" class="link" aria-label="Matplotlib"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Matplotlib<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="深度学习"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->深度学习<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="深度学习"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->深度学习<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/README.md" class="link" aria-label="PyTorch(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->PyTorch(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="计算机视觉"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->计算机视觉<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="计算机视觉"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->计算机视觉<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/ImageProcessing/OpenCV1/01_综述" class="link" aria-label="图像处理"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->图像处理<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/ImageGeneration/01_综述" class="link" aria-label="图像生成"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->图像生成<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/ComputerVision/TargetDetection/01_综述" class="link" aria-label="目标检测"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->目标检测<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="每日一题"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->每日一题<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="每日一题"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->每日一题<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/CodeExam/AI/Introduction" class="link" aria-label="AI算法篇"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AI算法篇<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="书院二层楼"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->书院二层楼<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="书院二层楼"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->书院二层楼<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><!--[--><h5 class="dropdown-link__subtitle"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Reco内置<!--]--></span></span></h5><ul class="dropdown-link__subcontainer"><!--[--><li class="dropdown-link__subitem"><a href="/blog-vp-reco/timeline" class="link" aria-label="时间轴"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->时间轴<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__subitem"><a href="/blog-vp-reco/friendship-link" class="link" aria-label="友情链接"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->友情链接<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="dropdown-link__item"><!--[--><h5 class="dropdown-link__subtitle"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->个人手札<!--]--></span></span></h5><ul class="dropdown-link__subcontainer"><!--[--><li class="dropdown-link__subitem"><a href="/blog-vp-reco/docs/update_record" class="link" aria-label="更新日志"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->更新日志<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__subitem"><a href="/blog-vp-reco/docs/desktop_app/README.md" class="link" aria-label="桌面软件开发(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->桌面软件开发(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="逐趣成章"><span class="xicon-container left title"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->逐趣成章<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="逐趣成章"><span class="title"><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->逐趣成章<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/Hobbies/mahjong/01_fargoing" class="link" aria-label="雀神之路(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->雀神之路(未整理)<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/blog-vp-reco/blogs/Hobbies/musictheroy/00" class="link" aria-label="音乐科学(未整理)"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->音乐科学(未整理)<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--><!----><span class="xicon-container btn-toggle-dark-mode btn--dark-mode navbar-links__item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><ul class="social-links navbar-links__item"><!--[--><li class="social-item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:25px;height:25px;"><path d="M16 2a14 14 0 0 0-4.43 27.28c.7.13 1-.3 1-.67v-2.38c-3.89.84-4.71-1.88-4.71-1.88a3.71 3.71 0 0 0-1.62-2.05c-1.27-.86.1-.85.1-.85a2.94 2.94 0 0 1 2.14 1.45a3 3 0 0 0 4.08 1.16a2.93 2.93 0 0 1 .88-1.87c-3.1-.36-6.37-1.56-6.37-6.92a5.4 5.4 0 0 1 1.44-3.76a5 5 0 0 1 .14-3.7s1.17-.38 3.85 1.43a13.3 13.3 0 0 1 7 0c2.67-1.81 3.84-1.43 3.84-1.43a5 5 0 0 1 .14 3.7a5.4 5.4 0 0 1 1.44 3.76c0 5.38-3.27 6.56-6.39 6.91a3.33 3.33 0 0 1 .95 2.59v3.84c0 .46.25.81 1 .67A14 14 0 0 0 16 2z" fill-rule="evenodd" fill="currentColor"></path></svg></li><!--]--></ul></nav><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><header class="sub-navbar-container not-open"><span class="nav-item"><div class="toggle-series-button" aria-expanded="false" role="button" tabindex="0"><span></span><span></span><span></span></div> Series </span></header><!----><!----><div class="theme-main" style=""><aside class="series-container"><!--[--><!--[--><section class="series-group series-item"><h5 class="series-heading series-level-1 active"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:16px;"><!--[-->机器学习<!--]--></span></span><span class="arrow down"></span></h5><ul style="display:block;"><li><!--[--><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html" class="router-link-active router-link-exact-active link router-link-active series-item series-item" aria-label="PyTorch基础知识"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->PyTorch基础知识<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project1.html" class="link series-item series-item" aria-label="实战1-离散分类问题"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战1-离散分类问题<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/02_project2.html" class="link series-item series-item" aria-label="实战1-参考答案"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战1-参考答案<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/03_project1.html" class="link series-item series-item" aria-label="实战2-线性拟合问题"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->实战2-线性拟合问题<!--]--></span></span><!--[--><!--]--></a><!--]--></li><li><!--[--><a href="/blog-vp-reco/blogs/DeepLearning/PyTorch/README.html" class="link series-item series-item" aria-label="/blogs/DeepLearning/PyTorch/README.html"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->/blogs/DeepLearning/PyTorch/README.html<!--]--></span></span><!--[--><!--]--></a><!--]--></li></ul></section><!--]--><!--]--></aside><!--[--><main class="page-container"><div class="page-content"><h1 class="page-title">PyTorch基础知识</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->AoSaiX<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2024-09-13<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/blog-vp-reco/categories/PyTorch/1.html" class="">PyTorch</a><!--]--><!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M10 14a4 4 0 1 1 4-4a4.005 4.005 0 0 1-4 4zm0-6a2 2 0 1 0 1.998 2.004A2.002 2.002 0 0 0 10 8z" fill="currentColor"></path><path d="M16.644 29.415L2.586 15.354A2 2 0 0 1 2 13.941V4a2 2 0 0 1 2-2h9.941a2 2 0 0 1 1.414.586l14.06 14.058a2 2 0 0 1 0 2.828l-9.943 9.943a2 2 0 0 1-2.829 0zM4 4v9.942L18.058 28L28 18.058L13.942 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><!--[--><a href="/blog-vp-reco/tags/PyTorchjichu/1.html" class="">PyTorch基础</a><!--]--><!--]--></span></span><!----></div><div class="theme-reco-md-content"><div><h2 id="_1-tensor-张量" tabindex="-1"><a class="header-anchor" href="#_1-tensor-张量"><span>1. Tensor（张量）</span></a></h2><p>张量是一种特殊的数据结构，不管是 PyTorch 还是 Tensorflow 都是使用张量进行运算，因为它可以在 GPU 或其它硬件加速器上使用，并且针对自动微分进行了优化。</p><p>它有点类似 Numpy 的 ndarray，并且很多张量 API 的使用方式都是相同的，如果你熟悉 Numpy，你会发现 torch 使用起来也会非常顺手，而且它两是可以相互转化的。</p><h3 id="_1-1-初始化" tabindex="-1"><a class="header-anchor" href="#_1-1-初始化"><span>1.1 初始化</span></a></h3><p>PyTorch 创建张量的 API 很多，这里只写一些比较常见的方式，想要了解的更详细，请看相关链接。首先，导入 torch 和 numpy：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol><li><strong>直接从 Python 数据初始化</strong>，数据类型 torch 会自动推断。</li><li><strong>从 Numpy 数组初始化</strong>，Numpy 的 ndarray 可以和 PyTorch 的 Tensor 相互转化。</li><li><strong>从另一个张量初始化</strong>，除非显示覆盖，否则新张量将保留参数张量的属性（形状、数据类型）。</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 初始化一个名叫 data 的 python 列表，并转化为张量形式</span></span>
<span class="line">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span></span>
<span class="line">x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 将 data 转化为 ndarray，再将 ndarray 转化为 tensor</span></span>
<span class="line">np_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span></span>
<span class="line">x_np <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_array<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 以 x_data 的形式，创建一个全为 1 的张量</span></span>
<span class="line">x_ones <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 以 x_data 的形式，创建一个由随机数组成的张量</span></span>
<span class="line">x_rand <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>x_data<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>x_rand<span class="token punctuation">}</span></span><span class="token string"> \n&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li><strong>使用随机值或常量值等</strong>，shape 是一个张量维度的元组，也就是上面所说的张量的形状属性。</li></ol><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 定义一个二维的，2行3列 的张量形状</span></span>
<span class="line">shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 以这个张量形状，别分创建由 随机数、全为1、全为0 组成的张量</span></span>
<span class="line">rand_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>shape<span class="token punctuation">)</span></span>
<span class="line">ones_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span></span>
<span class="line">zeros_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Random Tensor: \n </span><span class="token interpolation"><span class="token punctuation">{</span>rand_tensor<span class="token punctuation">}</span></span><span class="token string"> \n&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://pytorch.ac.cn/docs/stable/torch.html#creation-ops" target="_blank" rel="noopener noreferrer">《PyTorch 中文文档 - 张量创建相关 API》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/tensorqs_tutorial.html" target="_blank" rel="noopener noreferrer">《PyTorch 中文文档 - 张量简介》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_1-2-维度及属性" tabindex="-1"><a class="header-anchor" href="#_1-2-维度及属性"><span>1.2 维度及属性</span></a></h3><ul><li>0 维：scalar（数值、标量）</li><li>1 维：vector（向量、一维向量）</li><li>2 维：matrix（矩阵、二维向量）</li><li>n 维：n-dimensional tensor（n 维向量）</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">x0 <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token number">42.</span><span class="token punctuation">)</span></span>
<span class="line">x1 <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.1</span><span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">1.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">x2 <span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.1</span><span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">1.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.1</span><span class="token punctuation">,</span> <span class="token number">2.2</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>张量的属性有很多，只列举一部分。但是支持初始化时传参的，仅有前三个：</p><ol><li>init：仅在 init 初始化构造器中使用，支持传入 initializer 的子类</li><li>形状（shape）：是一个由数字组成的元组（tuple）</li><li>数据类型（dtype）：double、float、long、boolean 等</li></ol><ul><li>转置（T）：线性代数里有讲</li><li>单个元素大小（itemsize）：整数，代表每一个元素占用的字节数</li><li>总的字节数量（nbytes）：整数，代表 Tensor 占用的总字节数</li><li>维度数量（ndim）：整数，代表 Tensor 的秩，=len(tensor.shape)</li><li>元素个数（size）：整数，表示一共有多少个元素</li><li>每一维度步长（strides）：元组（tuple），每一个维度所需要的字节数</li><li>储存张量的设备（device）：cpu、gpu</li></ul><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">x1<span class="token punctuation">.</span>ndim   <span class="token comment"># 1</span></span>
<span class="line">x1<span class="token punctuation">.</span>shape  <span class="token comment"># (1, )</span></span>
<span class="line">x2<span class="token punctuation">.</span>T      <span class="token comment"># [[1.1, 2.1], [1.2, 2.2], [1.3, 2.3]]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-3-张量上的操作" tabindex="-1"><a class="header-anchor" href="#_1-3-张量上的操作"><span>1.3 张量上的操作</span></a></h3><p>张量上的操作超过了 100 种，包括算数、线性代数、矩阵操作、采样等等。这些操作都可以运行在 GPU 上，通常比 CPU 上的速度更快。</p><p>但是默认情况下张量是在 CPU 上创建的，我们需要通过 .to 的方法将张量显式的转移到 GPU 上去。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 如果 GPU 可用</span></span>
<span class="line"><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_availabel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">  <span class="token comment"># 将数据发送给 GPU，并重新赋值</span></span>
<span class="line">  tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 也可以通过 device() 指定设备</span></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 如果 GPU 可用选择 GPU，否则选择 CPU</span></span>
<span class="line">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_availabel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span></span>
<span class="line">tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>索引和切片操作</strong>，与 Numpy、Python 并无不同：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;First row: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;First column: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">, 0]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Last column: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line">tensor<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>张量连接操作</strong>，可以使用 torch.cat 和 torch.stack 对张量进行连接：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span></span>
<span class="line">t1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>单元素张量（数值）</strong>，比如你做了求和操作，可以使用 item() 函数将其从张量数据转化为 Python 数据：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span></span>
<span class="line">agg <span class="token operator">=</span> tensor<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">agg_item <span class="token operator">=</span> agg<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>agg_item<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>agg_item<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://pytorch.ac.cn/docs/stable/torch.html#indexing-slicing-joining-mutating-ops" target="_blank" rel="noopener noreferrer">《PyTorch 中文文档 - 张量操作及运算 API》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://blog.csdn.net/Ethan_Rich/article/details/134799695" target="_blank" rel="noopener noreferrer">《Pytorch 指定设备》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/tensorqs_tutorial.html#operations-on-tensors" target="_blank" rel="noopener noreferrer">《PyTorch 中文文档 - 张量上的操作》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_1-4-数学运算" tabindex="-1"><a class="header-anchor" href="#_1-4-数学运算"><span>1.4 数学运算</span></a></h3><p>Tensor 里简单的运算，比如加减乘除、取余（%）、整除（//），可以使用 Python 中的运算符，也可以使用封装好的运算函数。</p><p><strong>逐点运算</strong>：这些基本运算都是对数值的运算，放在 1 维以上的维度中，就是相同位置元素之间的运算，所以两个张量的形状必须一样。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span> <span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line">y <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">z1 <span class="token operator">=</span> x <span class="token operator">+</span> y</span>
<span class="line">z2 <span class="token operator">=</span> x <span class="token operator">-</span> y</span>
<span class="line">z3 <span class="token operator">=</span> x <span class="token operator">*</span> y</span>
<span class="line">z4 <span class="token operator">=</span> x <span class="token operator">/</span> y</span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> z1<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> z2<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> z3<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> z4<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">m1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span></span>
<span class="line">m2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span></span>
<span class="line">m3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span></span>
<span class="line">m4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>m1<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> m2<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> m3<span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">,</span> m4<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>矩阵运算</strong>：在线性代数中，最常用的就是矩阵（向量）的乘法、转置、求逆等操作：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span><span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 向量默认都是竖向量</span></span>
<span class="line">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span><span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>   <span class="token comment"># 通过 view 变换成横向量</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 二维矩阵中的矩阵乘法有这 3 种形式</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>a @ b<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 假如参与运算的是一个多维张量，那么只有torch.matmul()可以使用</span></span>
<span class="line"><span class="token comment"># 并且在多维张量中，参与矩阵运算的只有后两个维度，前面的维度就像是索引一样</span></span>
<span class="line">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://pytorch.ac.cn/docs/stable/torch.html#math-operations" target="_blank" rel="noopener noreferrer">《PyTorch 中文文档 - 数学运算 API》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://blog.csdn.net/qq_40728667/article/details/134013899" target="_blank" rel="noopener noreferrer">《PyTorch 中的常见运算》<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_1-5-与-numpy-的桥梁" tabindex="-1"><a class="header-anchor" href="#_1-5-与-numpy-的桥梁"><span>1.5 与 Numpy 的桥梁</span></a></h3><p><strong>torch 张量变换为 Numpy 数组：</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">t <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></span>
<span class="line">n <span class="token operator">=</span> t<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">\nn: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 此时如果操作张量 t，numpy 数组同样也会变化</span></span>
<span class="line">t<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;t: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">\nn: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Numpy 数组变换为 torch 张量：</strong></p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">n <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span></span>
<span class="line">t <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>n<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">\nt: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 此时如果操作 numpy 数组，张量 t 同样也会变化</span></span>
<span class="line">np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> out<span class="token operator">=</span>n<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;n: </span><span class="token interpolation"><span class="token punctuation">{</span>n<span class="token punctuation">}</span></span><span class="token string">\nt: </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-pytorch-常用封装" tabindex="-1"><a class="header-anchor" href="#_2-pytorch-常用封装"><span>2. PyTorch 常用封装</span></a></h2><p>这里列举了一些，做模型训练时经常会用到的函数，或者说 API。仅仅只是介绍一下，有个印象，具体的用法和实例我会在每一个部分都添加几个比较易懂的博文。</p><h3 id="_2-1-数据加载器-数据集" tabindex="-1"><a class="header-anchor" href="#_2-1-数据加载器-数据集"><span>2.1 数据加载器（数据集）</span></a></h3><p>处理数据样本的代码可能会变得混乱且难以维护，理想的情况下，我们希望数据集代码与模型训练代码分离开来，让其可以方便的模块化、以及提高可读性。</p><p>所以 PyTorch 给我们提供了两个处理数据集的 API：</p><ul><li><p>torch.utils.data.Dataset：用于处理单个训练样本，读取数据特征、size、标签等，并且包括数据转换等；</p></li><li><p>torch.utils.data.DataLoader：DataLoader 在 Dataset 周围重载一个可迭代对象，以便轻松访问样本。</p></li></ul><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/weixin_47748259/article/details/135611161" target="_blank" rel="noopener noreferrer">Dataset 与 DataLoader 使用、构建自定义数据集<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/data_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 数据集 &amp; 数据加载器<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_2-2-数据变换" tabindex="-1"><a class="header-anchor" href="#_2-2-数据变换"><span>2.2 数据变换</span></a></h3><p>一般情况下，预加载的数据集或自己构造的数据集并不能直接用于训练机器学习算法，为了将其转换为训练模型所需的最终形式，我们可以使用 torchvision.transforms 对数据进行处理，以使其适合训练。</p><p>从包名我们就可以看出来，这是一个专门为了计算机视觉（图像）处理而写的 API，不做 CV 的人可以跳过。</p><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/weixin_41936775/article/details/117160981" target="_blank" rel="noopener noreferrer">Pytorch(三)：数据变换 Transforms<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/transforms_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 变换<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_2-3-神经网络模型构建" tabindex="-1"><a class="header-anchor" href="#_2-3-神经网络模型构建"><span>2.3 神经网络模型构建</span></a></h3><p>怎么说呢，就是一些简单的机器学习的问题，比如线性回归、逻辑回归等，都可以使用神经网络的形式去进行解决，并且实现层面也比较简单，所以推荐直接从神经网络开始上手。如果有原理什么不懂的，可以查看我的《机器学习》的博文，或者百度。</p><p>PyTorch 里面，neural network 直接被简写成 nn，非常的简洁。 torch.nn 命名空间提供了构建您自己的神经网络所需的所有构建块。PyTorch 中的每个模块都是 nn.Module 的子类。神经网络本身就是一个模块，它由其他模块（层）组成。这种嵌套结构允许轻松构建和管理复杂的架构。</p><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/AI_dataloads/article/details/133144350" target="_blank" rel="noopener noreferrer">神经网络模型（最细的手写字识别案例）<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/buildmodel_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 构建神经网络<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_2-4-自动微分-求导" tabindex="-1"><a class="header-anchor" href="#_2-4-自动微分-求导"><span>2.4 自动微分（求导）</span></a></h3><p>第一次跟着 b 站博主写鸢尾花分类问题的代码时，我还不太理解为什么会有<strong>反向传播</strong>这个操作，而且每次都要做，每一个迭代还都要清零一次。</p><p>我们知道神经网络，是从输入层，到隐藏层（1 to n），再到输出层，这是一步一步向前走的，叫做<strong>向前传播</strong>，在继承 nn.Module 的类时，必须要重写的一个类函数就是它，def forward(self)这样子。</p><p><strong>反向传播</strong>顾名思义，就是从后往前走，主要是<a href="https://aosai.github.io/blog-pages/zh/intelligence/MachineLearning/02_linear_regression.html#_3-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-gradient-descent" target="_blank" rel="noopener noreferrer">梯度下降<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>时需要用到。为了计算这些梯度，PyTorch 有一个内置的微分引擎，称为 torch.autograd。它支持自动计算任何计算图的梯度。只需要在张量初始化的时候，加入一个属性：requires_grad=True 即可。</p><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/qq_35812205/article/details/120814447" target="_blank" rel="noopener noreferrer">【PyTorch 基础教程 4】反向传播与计算图（学不会来打我啊）<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/autogradqs_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 使用 torch.autograd 进行自动微分<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_2-5-参数优化" tabindex="-1"><a class="header-anchor" href="#_2-5-参数优化"><span>2.5 参数优化</span></a></h3><p>这里的参数优化主要是指<strong>超参数</strong>，它是可调整的参数，允许您控制模型优化过程。不同的超参数值会影响模型训练和收敛速度。</p><p>经过吴恩达教授的机器学习课程，我们也积累的很多类型的超参数，比如：</p><ul><li>线性回归里的：学习率 alpha（α）</li><li>逻辑回归里的：正则化参数 lambda（λ）</li><li>神经网络里的：迭代训练次数、批量大小</li><li>......</li></ul><p>PyTorch 内置了很多类型的参数优化器，比如 SGD 优化器，ADAM 优化器，RMSProp 优化器等等，它们适用于不同类型的模型和数据。</p><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/weixin_46649052/article/details/119718582" target="_blank" rel="noopener noreferrer">PyTorch 学习—13.优化器 optimizer 的概念及常用优化器<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/optimization_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 优化模型参数<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol><h3 id="_2-6-模型的保存和加载" tabindex="-1"><a class="header-anchor" href="#_2-6-模型的保存和加载"><span>2.6 模型的保存和加载</span></a></h3><p>保存模型就是为了再次使用，不管我们是在这个保存的数据基础上进一步的训练优化，还是我们去做迁移学习、共享参数，我们都得先把这个训练好的模型记录下来。</p><p><strong>参考文献&amp;相关链接：</strong></p><ol><li><a href="https://blog.csdn.net/m0_52987303/article/details/136509035" target="_blank" rel="noopener noreferrer">PyTorch 中的模型保存：一键保存、两种选择/保存整个模型和保存模型参数<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://blog.csdn.net/qq_39698985/article/details/141823143" target="_blank" rel="noopener noreferrer">pytorch 模型保存及加载参数恢复训练的例子<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://pytorch.ac.cn/tutorials/beginner/basics/saveloadrun_tutorial.html" target="_blank" rel="noopener noreferrer">PyTorch 中文文档 - 保存和加载模型<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol></div></div><footer class="page-meta"><div class="meta-item edit-link"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M2 26h28v2H2z" fill="currentColor"></path><path d="M25.4 9c.8-.8.8-2 0-2.8l-3.6-3.6c-.8-.8-2-.8-2.8 0l-15 15V24h6.4l15-15zm-5-5L24 7.6l-3 3L17.4 7l3-3zM6 22v-3.6l10-10l3.6 3.6l-10 10H6z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Edit this page<!--]--></span></span></div><div class="meta-item last-updated"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Git仓库提交时间 2025/9/22 02:26:38<!--]--></span></span></div></footer><nav class="page-nav"><p class="hasNext inner"><!----><span class="page-nav-item next">实战1-离散分类问题 → </span></p></nav><!----></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-tensor-张量" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1. Tensor（张量）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1. Tensor（张量）<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-1-初始化" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.1 初始化"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.1 初始化<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-2-维度及属性" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.2 维度及属性"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.2 维度及属性<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-3-张量上的操作" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.3 张量上的操作"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.3 张量上的操作<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-4-数学运算" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.4 数学运算"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.4 数学运算<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_1-5-与-numpy-的桥梁" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.5 与 Numpy 的桥梁"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.5 与 Numpy 的桥梁<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-pytorch-常用封装" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2. PyTorch 常用封装"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2. PyTorch 常用封装<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-1-数据加载器-数据集" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.1 数据加载器（数据集）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.1 数据加载器（数据集）<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-2-数据变换" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.2 数据变换"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.2 数据变换<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-3-神经网络模型构建" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.3 神经网络模型构建"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.3 神经网络模型构建<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-4-自动微分-求导" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.4 自动微分（求导）"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.4 自动微分（求导）<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-5-参数优化" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.5 参数优化"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.5 参数优化<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/blog-vp-reco/blogs/DeepLearning/PyTorch/01_base.html#_2-6-模型的保存和加载" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.6 模型的保存和加载"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.6 模型的保存和加载<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--]--></ul></div></main><!--]--></div></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/blog-vp-reco/assets/app-CkYqgEgS.js" defer></script>
  </body>
</html>
